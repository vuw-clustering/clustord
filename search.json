[{"path":"https://vuw-clustering.github.io/clustord/authors.html","id":null,"dir":"","previous_headings":"","what":"Authors","title":"Authors and Citation","text":"Louise McMillan. Author, maintainer, copyright holder. Daniel Fernández Martínez. Author. Ying Cui. Author. Eleni Matechou. Author.","code":""},{"path":"https://vuw-clustering.github.io/clustord/authors.html","id":"citation","dir":"","previous_headings":"","what":"Citation","title":"Authors and Citation","text":"Fernández, D., Arnold, R., Pledger, S., Liu, ., & Costilla, R. (2019). Finite mixture biclustering discrete type multivariate data. Advances Data Analysis Classification, 13, 117-143.","code":"@Article{,   title = {Finite mixture biclustering of discrete type multivariate data},   author = {Daniel Fern{'a}ndez and Richard Arnold and Shirley Pledger and Ivy Liu and Roy Costilla},   journal = {Advances in Data Analysis and Classification},   publisher = {Springer},   year = {2019},   volume = {13},   pages = {117--143},   url = {https://link.springer.com/article/10.1007/s11634-018-0324-3}, }"},{"path":"https://vuw-clustering.github.io/clustord/index.html","id":"clustord","dir":"","previous_headings":"","what":"Clustering Ordinal Data Using Proportional Odds Model, Ordered Stereotype Model or Binary Model","title":"Clustering Ordinal Data Using Proportional Odds Model, Ordered Stereotype Model or Binary Model","text":"Please install clustord GitHub using devtools::install_github(\"vuw-clustering/clustord\")","code":""},{"path":"https://vuw-clustering.github.io/clustord/index.html","id":"update","dir":"","previous_headings":"","what":"Update","title":"Clustering Ordinal Data Using Proportional Odds Model, Ordered Stereotype Model or Binary Model","text":"Version 1.0 update released! latest version package, version 1.0, major update version 0.1. now capacity fit models including variety covariates, make consistent models can fitted clustglm. Note input arguments output components changed. version backwards compatible, .e. able run scripts v0.1 using v1.0, changes make backwards-compatible mostly stylistic ones avoid using “.” notation. example, input argument constraint.sum.zero now become constraint_sum_zero. avoids potential confusion S3 methods. five top-level functions. main one clustord.fit(), performs clustering, including row clustering, column clustering, biclustering. also auxiliary one, mat2df(), may need run clustord.fit() create input data structure clustord.fit() (see clustord.fit() manual details). final two functions, calc.SE.rowcluster() calc.SE.bicluster(), designed run clustord.fit(), calculate standard errors clustering parameters, needed. calc.cluster.comparisons() can used compare clustering results different runs different models, avoiding label-switching issue. four top-level functions standard R-style manuals explain usage. need help, please email louise.mcmillan@vuw.ac.nz.","code":""},{"path":"https://vuw-clustering.github.io/clustord/index.html","id":"citations","dir":"","previous_headings":"","what":"Citations","title":"Clustering Ordinal Data Using Proportional Odds Model, Ordered Stereotype Model or Binary Model","text":"using OSM methods, please cite: Fernández, D., Arnold, R., & Pledger, S. (2016). Mixture-based clustering ordered stereotype model. Computational Statistics & Data Analysis, 93, 46-75. using POM methods, please cite: Matechou, E., Liu, ., Fernández, D., Farias, M., & Gjelsvik, B. (2016). Biclustering models two-mode ordinal data. psychometrika, 81(3), 611-624. using Binary methods, please cite: Pledger, S., & Arnold, R. (2014). Multivariate methods using mixtures: Correspondence analysis, scaling pattern-detection. Computational Statistics & Data Analysis, 71, 241-261.","code":"@article{fernandez2016mixture,   title={Mixture-based clustering for the ordered stereotype model},   author={Fern{\\'a}ndez, Daniel and Arnold, Richard and Pledger, Shirley},   journal={Computational Statistics \\& Data Analysis},   volume={93},   pages={46--75},   year={2016},   publisher={Elsevier} } @article{matechou2016biclustering,   title={Biclustering models for two-mode ordinal data},   author={Matechou, Eleni and Liu, Ivy and Fern{\\'a}ndez, Daniel and Farias, Miguel and Gjelsvik, Bergljot},   journal={psychometrika},   volume={81},   number={3},   pages={611--624},   year={2016},   publisher={Springer} } @article{pledger2014multivariate,   title={Multivariate methods using mixtures: Correspondence analysis, scaling and pattern-detection},   author={Pledger, Shirley and Arnold, Richard},   journal={Computational Statistics \\& Data Analysis},   volume={71},   pages={241--261},   year={2014},   publisher={Elsevier} }"},{"path":"https://vuw-clustering.github.io/clustord/reference/calc.SE.bicluster.html","id":null,"dir":"Reference","previous_headings":"","what":"Calculate standard errors of clustering parameters. — calc.SE.rowcluster","title":"Calculate standard errors of clustering parameters. — calc.SE.rowcluster","text":"Calculate SE parameters fitted using clustord.fit.","code":""},{"path":"https://vuw-clustering.github.io/clustord/reference/calc.SE.bicluster.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Calculate standard errors of clustering parameters. — calc.SE.rowcluster","text":"","code":"calc.SE.rowcluster(long.df, clust.out, optim.control = default.optim.control())  calc.SE.bicluster(long.df, clust.out, optim.control = default.optim.control())"},{"path":"https://vuw-clustering.github.io/clustord/reference/calc.SE.bicluster.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Calculate standard errors of clustering parameters. — calc.SE.rowcluster","text":"long.df data frame, long format, passed clustord.fit. clust.clustord.fit object. optim.control control list optim call within M step EM algorithm. See control list Details optim manual info.","code":""},{"path":"https://vuw-clustering.github.io/clustord/reference/calc.SE.bicluster.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Calculate standard errors of clustering parameters. — calc.SE.rowcluster","text":"standard errors corresponding elements clust.$outvect.","code":""},{"path":"https://vuw-clustering.github.io/clustord/reference/calc.SE.bicluster.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Calculate standard errors of clustering parameters. — calc.SE.rowcluster","text":"Use calc.SE.rowcluster calculate SE row clustering column clustering, calc.SE.bicluster calculate SE biclustering. Calculates SE running optimHess (see optim) incomplete-data log-likelihood find hessian fitted parameter values clustord.fit. square roots diagonal elements negative inverse hessian standard errors parameters .e. SE <- sqrt(diag(solve(-optim.hess)). Note SE values calculated independent parameters. example, constraint row clustering parameters set constraint_sum_zero = TRUE, last row clustering parameter negative sum parameters, SE values calculated first RG-1 parameters, independent ones. applies similarly individual column effect coefficients, etc. function requires input output clustord.fit, includes component outvect, final vector independent parameter values EM algorithm, correspond subset parameter values parlist..","code":""},{"path":"https://vuw-clustering.github.io/clustord/reference/calc.SE.bicluster.html","id":"functions","dir":"Reference","previous_headings":"","what":"Functions","title":"Calculate standard errors of clustering parameters. — calc.SE.rowcluster","text":"calc.SE.rowcluster(): SE rowclustering calc.SE.bicluster(): SE biclustering","code":""},{"path":"https://vuw-clustering.github.io/clustord/reference/calc.cluster.comparisons.html","id":null,"dir":"Reference","previous_headings":"","what":"Calculate comparison measures between two sets of clustering results — calc.cluster.comparisons","title":"Calculate comparison measures between two sets of clustering results — calc.cluster.comparisons","text":"Given two sets posterior probabilities membership clusters, calculate three measures compare clustering memberships.","code":""},{"path":"https://vuw-clustering.github.io/clustord/reference/calc.cluster.comparisons.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Calculate comparison measures between two sets of clustering results — calc.cluster.comparisons","text":"","code":"calc.cluster.comparisons(ppr1, ppr2)"},{"path":"https://vuw-clustering.github.io/clustord/reference/calc.cluster.comparisons.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Calculate comparison measures between two sets of clustering results — calc.cluster.comparisons","text":"ppr1 Posterior probabilities cluster membership, named ppr_m ppc_m output clustord.fit. performed biclustering, ppr1 clustering results just one dimensions .e. just row clustering results, just column clustering results. rows ppr1 give entries clustered, column corresponds one cluster. ppr2 Posterior probabilities cluster membership different clustering run, compared ppr1.","code":""},{"path":"https://vuw-clustering.github.io/clustord/reference/calc.cluster.comparisons.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Calculate comparison measures between two sets of clustering results — calc.cluster.comparisons","text":"list components:  ARI: Adjusted Rand Index.  NVI: Normalised Variation Information.  NID: Normalised Information Distance.","code":""},{"path":"https://vuw-clustering.github.io/clustord/reference/calc.cluster.comparisons.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Calculate comparison measures between two sets of clustering results — calc.cluster.comparisons","text":"three measures Adjusted Rand Index (ARI), Normalised Variation Information (NVI) Normalised Information Distance (NID). three measures documented ","code":""},{"path":"https://vuw-clustering.github.io/clustord/reference/calc.cluster.comparisons.html","id":"references","dir":"Reference","previous_headings":"","what":"References","title":"Calculate comparison measures between two sets of clustering results — calc.cluster.comparisons","text":"Fernández, D., & Pledger, S. (2016). Categorising count data   ordinal responses application ecological communities. Journal   agricultural, biological, environmental statistics (JABES), 21(2),   348--362.","code":""},{"path":"https://vuw-clustering.github.io/clustord/reference/clustord-package.html","id":null,"dir":"Reference","previous_headings":"","what":"clustord: Clustering Using Proportional Odds Model, Ordered Stereotype Model or Binary Model. — clustord-package","title":"clustord: Clustering Using Proportional Odds Model, Ordered Stereotype Model or Binary Model. — clustord-package","text":"Biclustering, row clustering column clustering using proportional odds model (POM), ordered stereotype model (OSM) binary model ordinal categorical data.","code":""},{"path":"https://vuw-clustering.github.io/clustord/reference/clustord-package.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"clustord: Clustering Using Proportional Odds Model, Ordered Stereotype Model or Binary Model. — clustord-package","text":"clustord package provides five functions: clustord.fit(), mat2df(), calc.SE.rowcluster(), calc.SE.bicluster(), calc.cluster.comparisons().","code":""},{"path":"https://vuw-clustering.github.io/clustord/reference/clustord-package.html","id":"clustering-function","dir":"Reference","previous_headings":"","what":"Clustering function","title":"clustord: Clustering Using Proportional Odds Model, Ordered Stereotype Model or Binary Model. — clustord-package","text":"main function clustord.fit,   fits clustering model data. model fitted using   likelihood-based clustering via EM algorithm. package assumes   started data matrix responses, though need   convert data matrix long-form data frame running   clustord.fit. Every element original data matrix becomes one   row data frame, row column indices data matrix   become columns ROW COL data frame. can perform   clustering rows columns data matrix, biclustering   rows columns simultaneously. can include number covariates   rows covariates columns. Ordinal models used package   Ordered Stereotype Model (OSM), Proportional Odds Model (POM)   dedicated Binary Model binary data.","code":""},{"path":"https://vuw-clustering.github.io/clustord/reference/clustord-package.html","id":"utility-function","dir":"Reference","previous_headings":"","what":"Utility function","title":"clustord: Clustering Using Proportional Odds Model, Ordered Stereotype Model or Binary Model. — clustord-package","text":"mat2df() utility function provided convert data matrix responses long-form data frame format required clustord.fit(), can also attach covariates long-form data frame needed.","code":""},{"path":"https://vuw-clustering.github.io/clustord/reference/clustord-package.html","id":"se-calculation-functions","dir":"Reference","previous_headings":"","what":"SE calculation functions","title":"clustord: Clustering Using Proportional Odds Model, Ordered Stereotype Model or Binary Model. — clustord-package","text":"calc.SE.rowcluster() calc.SE.bicluster() functions run running clustord.fit(), calculate standard errors parameters fitted using clustord.fit().","code":""},{"path":"https://vuw-clustering.github.io/clustord/reference/clustord-package.html","id":"clustering-comparisons","dir":"Reference","previous_headings":"","what":"Clustering comparisons","title":"clustord: Clustering Using Proportional Odds Model, Ordered Stereotype Model or Binary Model. — clustord-package","text":"calc.cluster.comparisons() can used compare assigned cluster memberships rows columns data matrix two different clustering fits, way avoids label-switching problem.","code":""},{"path":"https://vuw-clustering.github.io/clustord/reference/clustord.fit.html","id":null,"dir":"Reference","previous_headings":"","what":"Likelihood-based clustering using Ordered Stereotype Models (OSM), Proportional\nOdds Models (POM) or Binary Models — clustord.fit","title":"Likelihood-based clustering using Ordered Stereotype Models (OSM), Proportional\nOdds Models (POM) or Binary Models — clustord.fit","text":"Likelihood-based clustering parameters fitted using EM algorithm. can perform clustering rows columns data matrix, biclustering rows columns simultaneously. can include number covariates rows covariates columns. Ordinal models used package Ordered Stereotype Model (OSM), Proportional Odds Model (POM) dedicated Binary Model binary data.","code":""},{"path":"https://vuw-clustering.github.io/clustord/reference/clustord.fit.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Likelihood-based clustering using Ordered Stereotype Models (OSM), Proportional\nOdds Models (POM) or Binary Models — clustord.fit","text":"","code":"clustord.fit(   formula,   model,   nclus.row = NULL,   nclus.column = NULL,   long.df,   initvect = NULL,   pi.init = NULL,   kappa.init = NULL,   EM.control = default.EM.control(),   optim.method = \"L-BFGS-B\",   optim.control = default.optim.control(),   constraint_sum_zero = TRUE,   start_from_simple_model = TRUE,   nstarts = 5 )"},{"path":"https://vuw-clustering.github.io/clustord/reference/clustord.fit.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Likelihood-based clustering using Ordered Stereotype Models (OSM), Proportional\nOdds Models (POM) or Binary Models — clustord.fit","text":"formula model formula (see 'Details'). model \"OSM\" Ordered Stereotype Model \"POM\" Proportional Odds Model \"Binary\" binary data model. nclus.row number row clustering groups. nclus.column number column clustering groups. long.df data frame least three columns, Y ROW COL. row data frame corresponds single cell original data matrix; response value cell given Y, row column indices cell matrix given ROW COL. Use mat2df create data frame data matrix responses. mat2df also allows supply data frames row column covariates incorporated long.df. initvect (default NULL) vector starting parameter values model.     Note: user enters initial vector parameter values,     strongly recommend user also check values     parlist.init output object, make sure     constructed parameters expected. NULL, starting parameter values generated automatically. See 'Details' definitions parameters used different models. pi.init (default NULL) starting parameter values proportions     observations different row clusters. NULL, starting values generated automatically. User-specified values pi.init must length (nclus.row-1)     final value automatically calculated     values pi sum 1. kappa.init (default NULL) starting parameter values     proportions observations different column clusters. NULL, starting values generated automatically. User-specified values kappa.init must length     (nclus.column-1) final value automatically     calculated values kappa sum 1. EM.control (default = list(EMcycles=50, EMlikelihoodtol=1e-4,     EMparamtol=1e-2, paramstopping=TRUE, startEMcycles=10, keepallparams=FALSE,     epsilon=1e-6))     list parameters controlling EM algorithm. EMcycles controls many EM iterations main EM algorithm     used fit chosen submodel. EMlikelihoodtol tolerance stopping criterion     log-likelihood EM algorithm. criterion     absolute change incomplete log-likelihood since     previous iteration, scaled size dataset n*p,     n number rows data matrix p     number columns data matrix. scaling applied     incomplete log-likelihood predominantly affected dataset size. EMparamtol tolerance stopping criterion     parameters EM algorithm. tolerance     sum scaled parameter changes last iteration,     .e. tolerance individual parameter sum     changes parameters. Thus default tolerance 1e-2.     individual parameter criteria absolute differences     exponentiated absolute parameter value current timestep     exponentiated absolute parameter value previous timestep,     proportion exponentiated absolute parameter value current     timestep. exponentiation rescale parameter values     close zero. around 5 independent parameter values, point     convergence using default tolerances log-likelihood     parameters, parameter scaled absolute change since     previous iteration 1e-4; 20 30 independent     parameters, scaled aboslute change 1e-6. paramstopping: FALSE, indicates EM algorithm     check convergence based change incomplete-data     log-likelihood, relative current difference     complete-data incomplete-data log-likelihoods, .e.     abs(delta_lli)/abs(llc[iter] - lli[iter]);     TRUE, indicates well checking likelihood     criterion, EM algorithm also check whether relative change     exponentials absolute values current parameters     tolerance EMstoppingpar, see whether parameters     likelihood converged. startEMcycles controls many EM iterations used     fitting simpler submodels get starting values fitting models     interaction. keepallparams: true, keep record parameter values     (including pi_r kappa_c) every EM iteration. columnclustering, parameters saved iteration     converted column clustering format, row     clustering format, alpha     EM.status$params.every.iteration correspond beta_c     pi correspond kappa. epsilon: default 1e-6, small value used adjust values pi,     kappa theta close zero taking logs     create infinite values. optim.method (default \"L-BFGS-B\") method use optim within M step EM algorithm. Must one 'L-BFGS-B', 'BFGS', 'CG' 'Nelder-Mead' (.e. SANN method). optim.control control list optim call within M step EM algorithm. See control list Details optim manual info. constraint_sum_zero (default TRUE) TRUE, use constraints cluster effects sum zero; FALSE, use constraints cluster effect first cluster 0. versions constraints joint row-column cluster effects: effects described matrix parameters gamma_rc, indexed row cluster column cluster indices, constraints final column gamma_rc equal negative sum columns (gamma columns sum zero) first row gamma_rc equal negative sum rows (gamma rows sum zero). start_from_simple_model (default TRUE) TRUE, fit simpler clustering model first use provide starting values parameters model interactions; FALSE, use basic models provide starting values pi.init kappa.init. full model interaction terms, simpler models ones without interactions. model individual row/column effects alongside clusters, simpler models ones without individual row/column effects. full model covariates, simpler models ones without covariates (get starting values cluster parameters), ones covariates clustering (get starting values covariates). nstarts (default 5) number random starts generate, generating random starting points EM algorithm.","code":""},{"path":"https://vuw-clustering.github.io/clustord/reference/clustord.fit.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Likelihood-based clustering using Ordered Stereotype Models (OSM), Proportional\nOdds Models (POM) or Binary Models — clustord.fit","text":"list components:  info: Basic info n, p, q, number parameters, number     row clusters number column clusters, relevant.  model: model used fitting, \"OSM\" Ordered Stereotype     Model, \"POM\" Proportional Odds Model, \"Binary\" Binary model.  EM.status: list containing latest iteration iter,     latest incomplete-data complete-data log-likelihoods new.lli new.llc, best incomplete-data log-likelihood best.lli corresponding complete-data log-likelihood, llc..best.lli,     parameters best incomplete-data log-likelihood,  params..best.lli, indicator whether algorithm converged  converged, user chose keep parameter values     every iteration, also params.every.iteration. Note biclustering, .e. ROWCLUST  COLCLUST included model, incomplete log-likelihood calculated using entropy approximation,     may inaccurate unless algorithm converged close     converging. beware using incomplete log-likelihood     corresponding AIC value unless EM algorithm converged.  criteria: calculated values AIC, BIC,     etc. best incomplete-data log-likelihood.  epsilon: small value (default 1e-6) used adjust values     pi kappa theta close zero, taking logs     produce infinite values. Use EM.control argument     adjust epsilon.  constraints_sum_zero: chosen value constraints_sum_zero.  param_lengths: vector total number parameters/coefficients     part model, labelled names components.     value 0 component included model, e.g.     covariates interacting row clusters  rowc_cov_coef value 0. component included,     value given include dependent parameter/coefficient values,     column clusters included colc_coef value     nclus.column, whereas number independent values  nclus.column - 1.  initvect: initial vector parameter values, either     specified user generated automatically. vector     independent values parameters, full set.  outvect: final vector parameter values, containing     independent parameter values parlist..  parlist.init: initial list parameters, constructed     initial parameter vector initvect. Note initial     vector incorrectly specified, values parlist.init may expected, checked user.  parlist.: fitted values parameters.  pi, kappa: fitted values pi kappa, relevant.  ppr, ppc: posterior probabilities membership     row clusters column clusters, relevant.  rowc_mm, colc_mm, cov_mm: model matrices ,     respectively, covariates interacting row clusters, covariates     interacting column clusters, covariates interacting     row column clusters (.e. covariates constant coefficients).     Note one row model matrix corresponds one row long.df.  RowClusters, ColumnClusters: assigned row column     clusters, relevant, row/column assigned cluster     based maximum posterior probability cluster membership (ppr ppc).","code":""},{"path":"https://vuw-clustering.github.io/clustord/reference/clustord.fit.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Likelihood-based clustering using Ordered Stereotype Models (OSM), Proportional\nOdds Models (POM) or Binary Models — clustord.fit","text":"can select input parameters, starting values generated running kmeans fitting simpler models feeding outputs final model starting values. starting point clustering data matrix response values binary categorical. may also data frame covariates linked rows data matrix, may also data frame covariates linked columns data matrix. example, clustering data fishing trawls, rows trawl events columns species caught, also supply gear covariate linked rows, representing gear used trawl event, additionally supply species covariates linked columns, representing auxiliary information species. requirement provide covariates, can provide row covariates, column covariates. running clustord.fit, need run mat2df convert data matrix long form data frame. data frame needs least three columns, Y ROW COL. row data frame corresponds single cell original data matrix; response value cell given Y, row column indices cell matrix given ROW COL. mat2df also allows supply data frames row column covariates incorporated long.df. , run clustord.fit function, need enter chosen formula model, number clusters want fit. formula model_structure akin glm, restrictions. can include number covariates way multiple regression model, though unlike glm, can include row column covariates. Note , unlike glm, specify family argument; model argument used instead. formula argument details following description different models, Binary model used simplicity giving mathematical descriptions models, can use following models Ordered Stereotype Proportional Odds Models well. formula argument, response must exactly Y. use functions Y response, can include Y terms right hand side formula. Y name clustord.fit response values original data matrix. formula argument 4 special variables: ROWCLUST, COLCLUST, ROW COL. restrictions can used formula, covariates, instead act indicators clustering model_structure want use. variables formula covariates want include model, unrestricted, can used way glm. ROWCLUST COLCLUST used indicate row clustering model_structure want, column clustering model_structure want, respectively. inclusion ROWCLUST single term indicates want include row clustering effect model. simplest row clustering model, Binary data row clustering effects , basic function call clustord.fit(Y ~ ROWCLUST, model=\"Binary\", long.df=long.df) model fitted form: Logit(P(Y = 1)) = mu + rowc_coef_r mu intercept term, rowc_coef_r row cluster effect applied every row original data matrix member row cluster r. inclusion ROWCLUST corresponds inclusion rowc_coef_r. Note using notation involving greek letters, () ran letters different types parameters model (b) many parameters, difficult remember ones . Similarly row clustering, formula Y ~ COLCLUST perform column clustering, model Logit(P(Y = 1)) = mu + colc_coef_c, colc_coef_c column cluster effect applied every column original data matrix member column cluster c. Including ROWCLUST COLCLUST formula indicates want perform biclustering, .e. want cluster rows columns original data matrix simultaneously. included without interaction, terms just correspond including rowc_coef_r colc_coef_c model: formula Y ~ ROWCLUST + COLCLUST simplest possible biclustering model, Logit(P(Y = 1)) = mu + rowc_coef_r + colc_coef_c want include interaction rows columns, .e. want perform block biclustering block corresponds row cluster r column cluster c, model matrix parameters indexed r c. clustord.fit(Y ~ ROWCLUST*COLCLUST, model=\"Binary\", ...) model Logit(P(Y = 1)) = mu + rowc_colc_coef_rc model can instead called using equivalent formula Y ~ ROWCLUST + COLCLUST + ROWCLUST:COLCLUST. can instead use formula Y ~ ROWCLUST:COLCLUST. Mathematically, equivalent previous two. regression, models equivalent clustering, equivalent, number independent parameters overall. include main effects, reduces number independent parameters interaction term compared just use interaction term (see section initvect). include just one main effects alongside interaction term, .e. use Y ~ ROWCLUST + ROWCLUST:COLCLUST Y ~ COLCLUST + ROWCLUST:COLCLUST. simplicity code, avoid confusion interpreting results. However, clustord.fit allows lot flexibility . variables ROW COL used indicate want also include individual row column effects, respectively. example, clustering binary data indicates presence/ absence different species (columns) different trawl events (rows), know one particular species incredibly common, can include column effects model, allow possibility two columns may correspond species different probabilities appearing trawl. can add individual column effects along row clustering, can add individual row effects along column clustering. formula row clustering individual column effects (without interaction) Y ~ ROWCLUST + COL corresponds Binary model Logit(P(Y = 1)) = mu + rowc_coef_r + col_coef_j two cells data matrix row cluster, different columns, probability Y = 1. can also add interaction individual row/column effects clustering effects. still want able see row cluster column effects separately, use Y ~ ROWCLUST*COL Y ~ ROWCLUST + COL + ROWCLUST:COL (), model Logit(P(Y = 1)) = mu + rowc_coef_r + col_coef_j + rowc_col_coef_rj , rowc_coef_r col_coef_j row cluster effects individual column effects, rowc_col_coef_rj interaction terms. Alternatively, can use mathematically-equivalent formula Y ~ ROWCLUST:COL model Logit(P(Y = 1)) = mu + rowc_col_coef_rj row cluster effects individual column effects absorbed matrix rowc_col_coef_rj. models mathematically, differences constrained (see section initvect argument) interpreted. Note using covariates, equivalent leave main effects just use interaction terms, clustering models work quite regression models covariates. Equivalently, want cluster columns, can include individual row effects alongside column clusters, .e. Y ~ COLCLUST + ROW Y ~ COLCLUST + ROW + COLCLUST:ROW, depending whether want interaction terms . able include individual row effects row clusters, include individual column effects column clusters, enough information ordinal binary data fit models. consequence, include individual row column effects biclustering, e.g. Y ~ ROWCLUST + COLCLUST + ROW Y ~ ROwCLUST + COLCLUST + COL permitted. version 1 package, can now also include covariates alongside clustering patterns. basic way include additions clustering model_structure. example, including one row covariate xr row clustering model formula Y ~ ROWCLUST + xr Binary model Logit(P(Y = 1)) = mu + rowc_coef_r + row_coef_1*xr_i row_coef_1 coefficient xr_i, just typical regression model. Additional row covariates can also included, can include interactions , functions , regression models, e.g. Y ~ ROWCLUST + xr1*log(xr2) Binary model Logit(P(Y = 1)) = mu + rowc_coef_r + row_coef1*xr1_i + row_coef2*log(xr2_i) +                          row_coef3*xr1_i*log(xr2_i) instead want add column covariates model, work way added long.df data frame using mat2df, indexed j instead . Simplest model, one single column covariate xc, formula Y ~ ROWCLUST + xc Binary model Logit(P(Y = 1)) = mu + rowc_coef_r + col_coef1*xc_j can use functions interactions column covariates, just row covariates. can similarly add row column covariates column clustering biclustering models. can include interactions covariates ROWCLUST COLCLUST formula. quite interactions covariates. formula Y ~ ROWCLUST*xr xr row covariate, corresponds Binary model Logit(P(Y = 1)) = mu + rowc_coef_r + rowc_row_coef_r1*xr_i means term linear predictor involves row covariate xr (index row covariate), cluster (indexed r) different coefficient covariate (distinct non-interaction covariate models , coefficients covariates regardless cluster row ). different interaction terms involving covariates, two covariates appear multiplied together model shared coefficient term. clustering/covariate interaction, row column clustering pattern controls coefficients rather adding different type covariate. Note pure cluster effect rowc_coef_r also included model automatically, way regression formula Y ~ x1*x2 include individual x1 x2 effects well interaction x1 x2. coefficients row clusters interacting row coefficients named row.cluster.row.coef output clustord.fit can also coefficients interactions row clustering column covariates, column clustering row covariates, column clustering column covariates. Row clustering interacting column covariates look something like Y ~ ROWCLUST*xc Binary model Logit(P(Y = 1)) = mu + rowc_coef_r + rowc_col_coef_r1*xc_j combinations clustering covariates work similarly. rowc_col_coef_rl similar coefficients two indices. first index index cluster, second index index covariate among list covariates interacting direction clustering. two row covariates xr1 xr2 interacting three row clusters, gives 6 coefficients: rowc_col_coef_11, rowc_col_coef_12, rowc_col_coef_21, rowc_col_coef_22, rowc_col_coef_31, rowc_col_coef_32. can also three-way interaction row cluster two covariates, add coefficients rowc_col_coef_r3 xr1:xr2 term. can instead add covariates interact column clusters, parameters colc_row_coef_cm, m indexes just covariates interacting column cluster. covariates interacting row clusters covariates interacting column clusters, parameters rowc_cov_coef_rl colc_cov_coef_cm. example model Y ~ ROWCLUST + xr1 + ROWCLUST:xr1 + xc1 + COLCLUST + COLCLUST:log(xc1) main effects row clusters column clusters, .e. ROWCLUST COLCLUST. also two covariate terms interacting clusters, xr1 xc1. also 1 covariate term interacting row clusters, xr1, coefficients rowc_cov_coef_r1, 1 covariate term interacting column clusters, log(xc1), coefficients colc_cov_coef_c1. Restrictions formula primary restriction formula argument use functions ROW, COL, ROWCLUST COLCLUST, log(ROW) (COLCLUST^2). covariates, manipulated like ; instead, indicators particular elements clustering model_structure. performing biclustering, .e. ROWCLUST COLCLUST model, want include interaction , can use interaction , can include main effects, allowed use just one main effect alongside interaction. , can use Y ~ ROWCLUST + COLCLUST + ROWCLUST:COLCLUST Y ~ ROWCLUST*COLCLUST, can use Y ~ ROWCLUST:COLCLUST, two types biclustering model different parameter constraints (see initvect details), use Y ~ ROWCLUST + ROWCLUST:COLCLUST Y ~ COLCLUST + ROWCLUST:COLCLUST stated , also include individual row effects alongside row clustering, use individual column effects alongside column clustering, .e. ROWCLUST formula, ROW cannnot formula, COLCLUST formula COL formula. including COL ROWCLUST, can include interaction permitted interaction term involves COL, similarly interaction ROW COLCLUST permitted interaction term involves ROW. can include interactions form Y ~ ROWCLUST + COL + ROWCLUST:COL Y ~ ROWCLUST*COL, Y ~ ROWCLUST:COL. permitted uses COL term, equivalent constraints inclusion ROW. stated , can include interactions ROWCLUST COLCLUST covariates, include three-way interactions ROWCLUST, COLCLUST one covariates permitted clustord.fit, mostly prohibitive number parameter values need fitted, difficulty interpreting model. , use formulae Y ~ ROWCLUST*COLCLUST*xr, Binary model Logit(P(Y = 1)) = mu + bi_cluster_row_coef_rc1*xr_i. model argument details three models available clustord.fit Binary model, Bernoulli model equivalent binary model package clustglm, Proportional Odds Model (POM) Ordered Stereotype Model (OSM). Many Binary model examples given , general form logit(P(Y = 1)) = mu + <<linear terms>> linear terms can include row column clustering effects, individual row column effects, row column covariates, without interactions row column clustering. Proportional Odds Model Ordered Stereotype Model model_structure linear terms, overall model equation different. Proportional Odds Model (model = \"POM\") form logit(P(Y <= k)) = log(P(Y <= k)/P(Y > k)) = mu_k - <<linear terms>> simplest POM row clustering logit(P(Y <= k)) = mu_k - rowc_coef_r model including individual column effects interactions logit(P(Y <= k)) = mu_k - rowc_coef_r - col_coef_j Note linear-term coefficients negative signs Proportional Odds Models. row cluster index increases, column index increases, Y likely fall higher values (see Ch4 Agresti, 2010). Ordered Stereotype model (model = \"OSM\") form log(P(Y = k)/P(Y = 1)) = mu_k + phi_k(<<linear terms>>) simplest OSM row clustering log(P(Y = k)/P(Y = 1)) = mu_k + phi_k*rowc_coef_r model including individual column effects interactions log(P(Y = k)/P(Y = 1)) = mu_k + phi_k(rowc_coef_r + col_coef_j) Note OSM cumulative logit model, unlike POM. model describes log kth level relative first level, baseline category, patterns k = 2 may different patterns k = 3. linked, linear terms , may shape. sense, OSM flexible/less restrictive POM. See Anderson (1984) original definition ordered stereotype model, see Fernández et al. (2016) application clustering. phi_k parameters may treated \"score\" parameters. fitting OSM, fitted phi_k values can give indication true separation categories. Even default labelling categories 1 n, mean categories actually equally spaced reality. fitted phi_k values OSM can treated data-derived numerical labels categories. Moreover, two categories similar fitted phi_k values, e.g. phi_2 = 0.11 phi_3 = 0.13, suggests enough information data distinguish categories 2 3, might well merge single category simplify model-fitting process interpretation results. initvect argument details Initvect vector starting values parameters, made sections different type parameter model. Note length section initvect number independent parameter values, overall number parameter values type. want supply vector starting values EM algorithm, need careful many values supply, order include initvect, CHECK output list parameters (full set parameter values, including dependent ones, broken type parameter) check initvect model_structure correct formula specified. example, number mu values always 1 fewer number categories data, remaining value mu dependent q-1 values. OSM data 3 categories, first value mu category 1 0, 2 values mu categories 2 3 independent values mu. POM data 5 categories, first 4 values mu independent values last value mu infinity, probability Y category 5 defined 1 minus sum probabilities 4 levels. q number levels values y, n number rows original data matrix, p number columns original data matrix. Binary, one independent value mu, .e. q = 2. Ignore phi, used Binary model. OSM, starting values mu_k length q-1, model mu_1 = 0 always, initvect values mu become mu_2, mu_3, etc. mu_q. starting values phi_k length q-2. Note starting values phi correspond directly phi, phi restricted increasing 0 1, instead starting values treated elements u[2:q-1] vector u can -Inf +Inf, phi[2] <- expit(u[2]) phi[k] <- expit(u[2] + sum(exp(u[3:k]))) k 3 q-1 (phi[1] = 0 phi[q] = 1). POM, starting values mu_k length q-1, starting values correspond directly mu_k, mu_k restricted increasing, .e. model     mu_1 <= mu_2 <= ... mu_q = +Inf instead using initvect values directly mu_k, 2nd (q-1)th elements initvect used construct mu_k follows: mu_1 <- initvect[1] mu_2 <- initvect[1] + exp(initvect[2]) mu_3 <- initvect[1] + exp(initvect[2]) + exp(initvect[3]) ... mu_{k-1}, mu_k infinity,     used directly construct probability Y = q. Thus values used construct mu_k can unconstrained, makes easier specify initvect easier optimize parameter values. Ignore phi, used POM. three models, starting values rowc_coef_r length nclus.row-1, nclus.row number row clusters. final row cluster parameter dependent others (see input parameter info constraint_sum_zero), whereas independent colinear mu_k parameters thus identifiable. Similarly starting values colc_coef_c length nclus.column-1, nclus.column number column clusters, avoid problems colinearity nonidentifiability. biclustering interaction term row clusters column clusters, number independent values matrix interaction terms depends whether include main effects row column clusters separately. , use biclustering model Y ~ ROWCLUST + COLCLUST + ROWCLUST:COLCLUST, equivalently Y ~ ROWCLUST*COLCLUST, main effect term ROWCLUST nclus.row-1 independent parameters initvect, COLCLUST nclus.column-1 independent parameters initvect, ROWCLUST:COLCLUST (nclus.row - 1)*(nclus.column - 1) independent parameter values. final matrix interaction terms constrained last row equal negative sum rows, last column equal negative sum columns. hand, want use interaction term main effects (clustering model mathematically equivalent), .e. Y ~ ROWCLUST:COLCLUST, matrix interaction terms nclus.row*nclus.column - 1 independent parameters, .e. independent parameters included main effects. column effects alongside row clusters (permitted alongside column clusters), without interactions, .e. formula Y ~ ROWCLUST + COL Binary model Logit(P(Y = 1)) = mu + rowc_coef_r + col_coef_j row cluster coefficients nclus.row - 1 independent parameters, column effect coefficients p - 1 independent parameters, p number columns original data matrix, .e. maximum value long.df$COL. include interaction term, number independent parameters depends whether just use interaction term, include main effects. formula Y ~ ROWCLUST + COL + ROWCLUST:COL equivalent \"*\", interaction term (nclus.row - 1)*(p-1) independent parameters. instead use formula Y ~ ROWCLUST:COL, interaction term nclus.row*p - 1 independent parameters. Either way, total number independent parameters model nclus.row*p. Similarly, row effects alongside column clusters, without interactions, .e. formula Y ~ COLCLUST + ROW, Binary model Logit(P(Y = 1)) = mu + colc_coef_c + row_coef_i column cluster coefficients nclus.column - 1 independent parameters, row coefficients n-1 independent parameters, n number rows original data matrix, .e. maximum value long.df$ROW. include interaction term alongside main effects, .e. Y ~ COLCLUST + ROW + COLCLUST:ROW, equivalent \"*\", interaction term (nclus.column - 1)*(n-1) independent parameters. instead use formula Y ~ COLCLUST:ROW, interaction coefficient matrix nclus.column*n - 1 independent parameters. covariate terms included formula split clustord.fit covariates interact row clusters, covariates interact column clusters, covariates interact row column clusters. number independent parameters row-cluster-interacting covariates nclus.row*L, L number terms involving row clusters covariates \"*\" terms expanded. formula, example, Y ~ ROWCLUST*xr1 + xr2 + ROWCLUST:log(xc1) xr1 xr2 row covariates, xc1 column covariate, fully expanded formula Y ~ ROWCLUST + xr1 + xr2 + ROWCLUST:xr1 + ROWCLUST:log(xc1) terms interacting ROWCLUST ROWCLUST:xr1 ROWCLUST:log(xc1), nclus.row*2 independent coefficients covariates. number independent parameters column-cluster-interacting covariates nclus.column*M, M number terms involving column clusters covariates \"*\" terms expanded. formula, example, Y ~ (xr1^2) + COLCLUST*xc1 + COLCLUST:xc2:xc3 + COLCLUST*xr1 expanded Y ~ COLCLUST + xr1 + (xr1^2) + xc1 + COLCLUST:xc1 + COLCLUST:xc2:xc3 + COLCLUST:xr1 terms interacting COLCLUST COLCLUST:xc1, COLCLUST:xc2:xc3 COLCLUST:xr1, nclus.column*3 independent coefficients covariates. number independent parameters covariates interact row column clusters number covariate terms, \"*\" terms expanded. formula, example, Y ~ ROWCLUST*xr1 + xr2 + ROWCLUST:log(xc1) + COLCLUST*xc1 expanded Y ~ ROWCLUST +COLCLUST + xr1 + xr2 + xc1 + ROWCLUST:xr1 + ROWCLUST:log(xc1) + COLCLUST:xc1, 3 independent coefficients terms xr1, xr2, xc1. Note intercept terms coefficients, incorporated parameters mu_k. order initvect entries follows, entries included formula ignored included initvect. , provide values initvect components included formula. 1) mu (values used construct mu, POM ) 2) values used construct phi (OSM ) 3) row cluster coefficients 4) column cluster coefficients 5) [matrix] bicluster coefficients (.e. interaction row column clusters) 6) individual row coefficients 7) individual column coefficients 8) [matrix] interactions row clusters individual column coefficients 9) [matrix] interactions column clusters individual row coefficients 10) [matrix] row-cluster-specific coefficients covariates interacting row clusters 11) [matrix] column-cluster-specific coefficients covariates interacting column clusters 12) coefficients covariates interact row column clusters entries marked [matrix] constructed matrices filling matrices row-wise, e.g. want starting values 1:6 matrix 2 row clusters 3 covariates interacting row clusters, matrix coefficients become 1 2 3 4 5 6 formula Y ~ ROWCLUST*COLCLUST, matrix interactions row column clusters (nclus.row - 1)*(nclus.column - 1) independent parameters, last row column matrix negative sums rest, e.g. 2 row clusters 3 column clusters, 2 independent values, provide starting values -0.5 1.2, final matrix parameters : column cluster 1   column cluster 2   column cluster 3 row cluster 1   -0.5               1.2                -0.7 row cluster 2   0.5                -1.2               0.7 matrix matrix relating row clusters, row clusters rows, matrix relating column clusters row clusters, column clusters rows, .e. matrix coefficients column clusters interacting individual row effects rows matrix corresponding clusters, .e. matrix indexed colc_row_coef_ci, c column cluster index row index. Similarly, matrix matrix relating column clusters covariates, rows matrix correspond column clusters, .e. matrix indexed colc_cov_coef_cl, c column cluster index l covariate index. using biclustering interaction row column clusters, row clusters rows column clusters columns, .e. matrix indexed rowc_colc_coef_rc, r row cluster index c column cluster index.","code":""},{"path":"https://vuw-clustering.github.io/clustord/reference/clustord.fit.html","id":"references","dir":"Reference","previous_headings":"","what":"References","title":"Likelihood-based clustering using Ordered Stereotype Models (OSM), Proportional\nOdds Models (POM) or Binary Models — clustord.fit","text":"Fernandez, D., Arnold, R., & Pledger, S. (2016). Mixture-based clustering ordered stereotype model. *Computational Statistics & Data Analysis*, 93, 46-75. Anderson, J. . (1984). Regression ordered categorical variables. *Journal Royal Statistical Society: Series B (Methodological)*, 46(1), 1-22. Agresti, . (2010). *Analysis ordinal categorical data* (Vol. 656). John Wiley & Sons.","code":""},{"path":"https://vuw-clustering.github.io/clustord/reference/clustord.fit.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Likelihood-based clustering using Ordered Stereotype Models (OSM), Proportional\nOdds Models (POM) or Binary Models — clustord.fit","text":"","code":"set.seed(1) long.df <- data.frame(Y=factor(sample(1:3,5*20,replace=TRUE)),                ROW=factor(rep(1:20,times=5)),COL=rep(1:5,each=20))  # Model Log(P(Y=k)/P(Y=1))=mu_k+phi_k*rowc_coef_r with 3 row clustering groups: clustord.fit(Y~ROWCLUST,model=\"OSM\",3,long.df=long.df,              EM.control=list(EMcycles=2,startEMcycles=2), nstarts=2) #> [1] \"Converting factor ROW to numeric.\" #> [1] \"EM algorithm for OSM\" #> Randomly generated start #1 #> # weights:  6 (2 variable) #> initial  value 109.861229  #> final  value 109.492385  #> converged #> Random starts model iter= 1  incomplete-data log.like= -110.304631229144  #> Random starts model iter= 2  incomplete-data log.like= -110.298338943026  #> Found better incomplete LL: -110.298338943026  #> Randomly generated start #2 #> Random starts model iter= 1  incomplete-data log.like= -109.570144450913  #> Random starts model iter= 2  incomplete-data log.like= -109.501997036832  #> Found better incomplete LL: -109.501997036832  #> Full model iter= 1  incomplete-data log.like= -109.479945219589  #> Full model iter= 2  incomplete-data log.like= -109.477779508711  #> $info #>         n         p         q      npar ninitvect         R  #>        20         5         3         7         5         3  #>  #> $model #> [1] \"OSM\" #>  #> $EM.status #> $EM.status$iter #> [1] 2 #>  #> $EM.status$finished #> [1] TRUE #>  #> $EM.status$converged #> [1] FALSE #>  #> $EM.status$new.llc #> [1] -124.6967 #>  #> $EM.status$new.lli #> [1] -109.4778 #>  #> $EM.status$previous.lli #> [1] -109.4799 #>  #> $EM.status$llc.for.best.lli #> [1] -124.6967 #>  #> $EM.status$params.for.best.lli #> $EM.status$params.for.best.lli$mu #>                  mu        mu  #> 0.0000000 0.6567039 0.4469799  #>  #> $EM.status$params.for.best.lli$phi #>                 phi            #> 0.0000000 0.9999998 1.0000000  #>  #> $EM.status$params.for.best.lli$rowc #>     rowc_r     rowc_r             #>  1.1075408 -0.7844101 -0.3231307  #>  #> $EM.status$params.for.best.lli$pi #> [1] 0.0904055 0.6303752 0.2792193 #>  #>  #> $EM.status$best.lli #> [1] -109.4778 #>  #> $EM.status$paramstopping #> [1] TRUE #>  #>  #> $criteria #> $criteria$Res.Dev #> [1] 218.9556 #>  #> $criteria$AIC #> [1] 232.9556 #>  #> $criteria$AICc #> [1] 234.538 #>  #> $criteria$BIC #> [1] 251.1918 #>  #> $criteria$ICL #> [1] 281.6297 #>  #>  #> $numerical.correction.epsilon #> [1] 1e-06 #>  #> $constraint_sum_zero #> [1] TRUE #>  #> $param_lengths #>        mu       phi      rowc       col  rowc_col  rowc_cov       cov      colc  #>         3         0         3         0         0         0         0         0  #> rowc_colc       row  colc_row  colc_cov  #>         0         0         0         0  #>  #> $initvect #>         mu         mu        phi     rowc_r     rowc_r  #>  0.6887195  0.4789973 15.5476237  1.1820221 -0.8433398  #>  #> $outvect #>         mu         mu        phi     rowc_r     rowc_r  #>  0.6567039  0.4469799 15.5476246  1.1075408 -0.7844101  #>  #> $parlist.init #> $parlist.init$mu #>                  mu        mu  #> 0.0000000 0.6887195 0.4789973  #>  #> $parlist.init$phi #>                 phi            #> 0.0000000 0.9999998 1.0000000  #>  #> $parlist.init$rowc #>     rowc_r     rowc_r             #>  1.1820221 -0.8433398 -0.3386823  #>  #>  #> $parlist.out #> $parlist.out$mu #>                  mu        mu  #> 0.0000000 0.6567039 0.4469799  #>  #> $parlist.out$phi #>                 phi            #> 0.0000000 0.9999998 1.0000000  #>  #> $parlist.out$rowc #>     rowc_r     rowc_r             #>  1.1075408 -0.7844101 -0.3231307  #>  #>  #> $pi.init #> [1] 0.09870921 0.62415679 0.27713400 #>  #> $pi.out #> [1] 0.0904055 0.6303752 0.2792193 #>  #> $ppr #>              [,1]      [,2]      [,3] #>  [1,] 0.002238307 0.8134125 0.1843491 #>  [2,] 0.002238308 0.8134125 0.1843492 #>  [3,] 0.002238308 0.8134125 0.1843492 #>  [4,] 0.088802140 0.5618339 0.3493639 #>  [5,] 0.002238307 0.8134125 0.1843491 #>  [6,] 0.014936400 0.7161989 0.2688647 #>  [7,] 0.014936400 0.7161989 0.2688647 #>  [8,] 0.088802167 0.5618339 0.3493639 #>  [9,] 0.371106510 0.3097987 0.3190948 #> [10,] 0.088802193 0.5618339 0.3493639 #> [11,] 0.088802167 0.5618339 0.3493639 #> [12,] 0.002238306 0.8134126 0.1843491 #> [13,] 0.014936395 0.7161989 0.2688647 #> [14,] 0.014936400 0.7161989 0.2688647 #> [15,] 0.371106437 0.3097988 0.3190948 #> [16,] 0.088802140 0.5618339 0.3493639 #> [17,] 0.088802140 0.5618339 0.3493639 #> [18,] 0.088802140 0.5618339 0.3493639 #> [19,] 0.371106510 0.3097987 0.3190948 #> [20,] 0.002238307 0.8134125 0.1843491 #>  #> $rowc_mm #>      [,1] #> [1,]    1 #>  #> $cov_mm #>      [,1] #> [1,]    1 #>  #> $RowClusters #> $RowClusters[[1]] #> [1]  9 15 19 #>  #> $RowClusters[[2]] #>  [1]  1  2  3  4  5  6  7  8 10 11 12 13 14 16 17 18 20 #>  #> $RowClusters[[3]] #> integer(0) #>  #>   # Model Log(P(Y=k)/P(Y=1))=mu_k+phi_k*(rowc_coef_r + col_coef_j) with 3 row clustering groups: clustord.fit(Y~ROWCLUST+COL,model=\"OSM\",3,long.df=long.df,              EM.control=list(EMcycles=2,startEMcycles=2), nstarts=2) #> [1] \"Converting factor ROW to numeric.\" #> [1] \"EM algorithm for OSM\" #> Randomly generated start #1 #> # weights:  18 (10 variable) #> initial  value 109.861229  #> iter  10 value 104.901822 #> final  value 104.901564  #> converged #> Using the output of simpler model as initial values for full model #> Row-cluster-only model iter= 1  incomplete-data log.like= -110.126972281824  #> Row-cluster-only model iter= 2  incomplete-data log.like= -110.147338228543  #> === End of initial row-cluster-only model fitting === #> Random starts model iter= 1  incomplete-data log.like= -108.277197880391  #> Random starts model iter= 2  incomplete-data log.like= -108.269318895226  #> Found better incomplete LL: -108.269318895226  #> Randomly generated start #2 #> Using the output of simpler model as initial values for full model #> Row-cluster-only model iter= 1  incomplete-data log.like= -109.715287469331  #> Row-cluster-only model iter= 2  incomplete-data log.like= -109.746302124518  #> === End of initial row-cluster-only model fitting === #> Random starts model iter= 1  incomplete-data log.like= -108.257367310219  #> Random starts model iter= 2  incomplete-data log.like= -108.296391632981  #> Found better incomplete LL: -108.257367310219  #> Full model iter= 1  incomplete-data log.like= -108.166157795313  #> Full model iter= 2  incomplete-data log.like= -108.157814982747  #> $info #>         n         p         q      npar ninitvect         R  #>        20         5         3        11         9         3  #>  #> $model #> [1] \"OSM\" #>  #> $EM.status #> $EM.status$iter #> [1] 2 #>  #> $EM.status$finished #> [1] TRUE #>  #> $EM.status$converged #> [1] FALSE #>  #> $EM.status$new.llc #> [1] -122.4628 #>  #> $EM.status$new.lli #> [1] -108.1578 #>  #> $EM.status$previous.lli #> [1] -108.1662 #>  #> $EM.status$llc.for.best.lli #> [1] -122.4628 #>  #> $EM.status$params.for.best.lli #> $EM.status$params.for.best.lli$mu #>                  mu        mu  #> 0.0000000 0.3940837 0.1842594  #>  #> $EM.status$params.for.best.lli$phi #>                 phi            #> 0.0000000 0.9999983 1.0000000  #>  #> $EM.status$params.for.best.lli$rowc #>     rowc_r     rowc_r             #> -0.5216699  1.0437275 -0.5220576  #>  #> $EM.status$params.for.best.lli$col #>      col_j      col_j      col_j      col_j             #> -0.1179480 -0.3468197  0.6875302 -0.3468183  0.1240557  #>  #> $EM.status$params.for.best.lli$pi #> [1] 0.1284571 0.2239484 0.6475945 #>  #>  #> $EM.status$best.lli #> [1] -108.1578 #>  #> $EM.status$paramstopping #> [1] TRUE #>  #>  #> $criteria #> $criteria$Res.Dev #> [1] 216.3156 #>  #> $criteria$AIC #> [1] 238.3156 #>  #> $criteria$AICc #> [1] 241.9018 #>  #> $criteria$BIC #> [1] 266.9725 #>  #> $criteria$ICL #> [1] 295.5825 #>  #>  #> $numerical.correction.epsilon #> [1] 1e-06 #>  #> $constraint_sum_zero #> [1] TRUE #>  #> $param_lengths #>        mu       phi      rowc       col  rowc_col  rowc_cov       cov      colc  #>         3         0         3         5         0         0         0         0  #> rowc_colc       row  colc_row  colc_cov  #>         0         0         0         0  #>  #> $initvect #>         mu         mu        phi     rowc_r     rowc_r      col_j      col_j  #>  0.4123909  0.2026688 13.3124994 -0.6030957  1.2064014 -0.1194954 -0.3542456  #>      col_j      col_j  #>  0.6999817 -0.3542444  #>  #> $outvect #>         mu         mu        phi     rowc_r     rowc_r      col_j      col_j  #>  0.3940837  0.1842594 13.3125152 -0.5216699  1.0437275 -0.1179480 -0.3468197  #>      col_j      col_j  #>  0.6875302 -0.3468183  #>  #> $parlist.init #> $parlist.init$mu #>                  mu        mu  #> 0.0000000 0.4123909 0.2026688  #>  #> $parlist.init$phi #>                 phi            #> 0.0000000 0.9999983 1.0000000  #>  #> $parlist.init$rowc #>     rowc_r     rowc_r             #> -0.6030957  1.2064014 -0.6033056  #>  #> $parlist.init$col #>      col_j      col_j      col_j      col_j             #> -0.1194954 -0.3542456  0.6999817 -0.3542444  0.1280038  #>  #>  #> $parlist.out #> $parlist.out$mu #>                  mu        mu  #> 0.0000000 0.3940837 0.1842594  #>  #> $parlist.out$phi #>                 phi            #> 0.0000000 0.9999983 1.0000000  #>  #> $parlist.out$rowc #>     rowc_r     rowc_r             #> -0.5216699  1.0437275 -0.5220576  #>  #> $parlist.out$col #>      col_j      col_j      col_j      col_j             #> -0.1179480 -0.3468197  0.6875302 -0.3468183  0.1240557  #>  #>  #> $pi.init #> [1] 0.1243251 0.2488937 0.6267813 #>  #> $pi.out #> [1] 0.1284571 0.2239484 0.6475945 #>  #> $ppr #>             [,1]       [,2]      [,3] #>  [1,] 0.16371036 0.01079021 0.8254994 #>  [2,] 0.16371035 0.01079024 0.8254994 #>  [3,] 0.16371035 0.01079024 0.8254994 #>  [4,] 0.11766414 0.28927071 0.5930652 #>  [5,] 0.16371036 0.01079021 0.8254994 #>  [6,] 0.15518505 0.06246809 0.7823469 #>  [7,] 0.15518505 0.06246809 0.7823469 #>  [8,] 0.11766403 0.28927133 0.5930646 #>  [9,] 0.04749713 0.71315231 0.2393506 #> [10,] 0.11766393 0.28927194 0.5930641 #> [11,] 0.11766403 0.28927133 0.5930646 #> [12,] 0.16371036 0.01079018 0.8254995 #> [13,] 0.15518508 0.06246792 0.7823470 #> [14,] 0.15518505 0.06246809 0.7823469 #> [15,] 0.04749723 0.71315170 0.2393511 #> [16,] 0.11766414 0.28927071 0.5930652 #> [17,] 0.11766414 0.28927071 0.5930652 #> [18,] 0.11766414 0.28927071 0.5930652 #> [19,] 0.04749713 0.71315231 0.2393506 #> [20,] 0.16371036 0.01079021 0.8254994 #>  #> $rowc_mm #>      [,1] #> [1,]    1 #>  #> $cov_mm #>      [,1] #> [1,]    1 #>  #> $RowClusters #> $RowClusters[[1]] #> integer(0) #>  #> $RowClusters[[2]] #> [1]  9 15 19 #>  #> $RowClusters[[3]] #>  [1]  1  2  3  4  5  6  7  8 10 11 12 13 14 16 17 18 20 #>  #>   # Model Logit(P(Y <= k))=mu_k-rowc_coef_r-col_coef_j-rowc_col_coef_rj with 2 row clustering groups: clustord.fit(Y~ROWCLUST*COL,model=\"POM\",nclus.row=2,long.df=long.df,              EM.control=list(EMcycles=2,startEMcycles=2), nstarts=2) #> [1] \"Converting factor ROW to numeric.\" #> [1] \"EM algorithm for POM\" #> Randomly generated start #1 #> Using the output of simpler model as initial values for full model #> Row-cluster-only model iter= 1  incomplete-data log.like= -111.096851625699  #> Row-cluster-only model iter= 2  incomplete-data log.like= -111.018425130369  #> === End of initial row-cluster-only model fitting === #> Using the output of intermediate model as initial values for full model #> Rowcluster-column model iter= 1  incomplete-data log.like= -109.204032940502  #> Rowcluster-column model iter= 2  incomplete-data log.like= -109.150012440275  #> === End of intermediate rowcluster-column model fitting === #> Random starts model iter= 1  incomplete-data log.like= -108.739684879645  #> Random starts model iter= 2  incomplete-data log.like= -108.739159769397  #> Found better incomplete LL: -108.739159769397  #> Randomly generated start #2 #> Using the output of simpler model as initial values for full model #> Row-cluster-only model iter= 1  incomplete-data log.like= -110.020564227556  #> Row-cluster-only model iter= 2  incomplete-data log.like= -109.56385571452  #> === End of initial row-cluster-only model fitting === #> Using the output of intermediate model as initial values for full model #> Rowcluster-column model iter= 1  incomplete-data log.like= -108.737637998213  #> Rowcluster-column model iter= 2  incomplete-data log.like= -108.733825418567  #> === End of intermediate rowcluster-column model fitting === #> Random starts model iter= 1  incomplete-data log.like= -108.732820879421  #> Random starts model iter= 2  incomplete-data log.like= -108.732812611287  #> Found better incomplete LL: -108.732812611287  #> Full model iter= 1  incomplete-data log.like= -108.732438435781  #> Full model iter= 2  incomplete-data log.like= -108.732440977521  #> $info #>         n         p         q      npar ninitvect         R  #>        20         5         3        12        11         2  #>  #> $model #> [1] \"POM\" #>  #> $EM.status #> $EM.status$iter #> [1] 2 #>  #> $EM.status$finished #> [1] TRUE #>  #> $EM.status$converged #> [1] FALSE #>  #> $EM.status$new.llc #> [1] -108.8409 #>  #> $EM.status$new.lli #> [1] -108.7324 #>  #> $EM.status$previous.lli #> [1] -108.7324 #>  #> $EM.status$llc.for.best.lli #> [1] -108.8421 #>  #> $EM.status$params.for.best.lli #> $EM.status$params.for.best.lli$mu #> [1] -0.5159621  1.0586536 #>  #> $EM.status$params.for.best.lli$rowc #>     rowc_r             #>  0.2059226 -0.2059226  #>  #> $EM.status$params.for.best.lli$col #>       col_j       col_j       col_j       col_j              #> -0.33689596 -0.37159834  0.24400800  0.05001817  0.41446813  #>  #> $EM.status$params.for.best.lli$rowc_col #>            [,1]       [,2]       [,3]        [,4]       [,5] #> [1,]  0.2846683 -0.0187539 -0.1785637  0.01574482 -0.1030956 #> [2,] -0.2846683  0.0187539  0.1785637 -0.01574482  0.1030956 #>  #> $EM.status$params.for.best.lli$pi #> [1] 0.9993228274 0.0006771726 #>  #>  #> $EM.status$best.lli #> [1] -108.7324 #>  #> $EM.status$paramstopping #> [1] TRUE #>  #>  #> $criteria #> $criteria$Res.Dev #> [1] 217.4649 #>  #> $criteria$AIC #> [1] 241.4649 #>  #> $criteria$AICc #> [1] 245.6974 #>  #> $criteria$BIC #> [1] 272.7269 #>  #> $criteria$ICL #> [1] 272.9462 #>  #>  #> $numerical.correction.epsilon #> [1] 1e-06 #>  #> $constraint_sum_zero #> [1] TRUE #>  #> $param_lengths #>        mu       phi      rowc       col  rowc_col  rowc_cov       cov      colc  #>         3         0         2         5        10         0         0         0  #> rowc_colc       row  colc_row  colc_cov  #>         0         0         0         0  #>  #> $initvect #>          mu          mu      rowc_r       col_j       col_j       col_j  #> -0.49909304  0.45401858  0.22279684 -0.34610748 -0.42508562  0.19612541  #>       col_j rowc_col_rj rowc_col_rj rowc_col_rj rowc_col_rj  #>  0.02606549  0.29382204  0.03486583 -0.13058809  0.03966172  #>  #> $outvect #>          mu          mu      rowc_r       col_j       col_j       col_j  #> -0.51594359  0.45403090  0.20590693 -0.33692367 -0.37158821  0.24401004  #>       col_j rowc_col_rj rowc_col_rj rowc_col_rj rowc_col_rj  #>  0.05000594  0.28469159 -0.01876499 -0.17856080  0.01575872  #>  #> $parlist.init #> $parlist.init$mu #> [1] -0.499093  1.075534 #>  #> $parlist.init$rowc #>     rowc_r             #>  0.2227968 -0.2227968  #>  #> $parlist.init$col #>       col_j       col_j       col_j       col_j              #> -0.34610748 -0.42508562  0.19612541  0.02606549  0.54900220  #>  #> $parlist.init$rowc_col #>           [,1]        [,2]       [,3]        [,4]       [,5] #> [1,]  0.293822  0.03486583 -0.1305881  0.03966172 -0.2377615 #> [2,] -0.293822 -0.03486583  0.1305881 -0.03966172  0.2377615 #>  #>  #> $parlist.out #> $parlist.out$mu #> [1] -0.5159436  1.0587031 #>  #> $parlist.out$rowc #>     rowc_r             #>  0.2059069 -0.2059069  #>  #> $parlist.out$col #>       col_j       col_j       col_j       col_j              #> -0.33692367 -0.37158821  0.24401004  0.05000594  0.41449590  #>  #> $parlist.out$rowc_col #>            [,1]        [,2]       [,3]        [,4]       [,5] #> [1,]  0.2846916 -0.01876499 -0.1785608  0.01575872 -0.1031245 #> [2,] -0.2846916  0.01876499  0.1785608 -0.01575872  0.1031245 #>  #>  #> $pi.init #> [1] 0.9993139936 0.0006860064 #>  #> $pi.out #> [1] 0.9993315447 0.0006684553 #>  #> $ppr #>            [,1]         [,2] #>  [1,] 0.9989548 0.0010451980 #>  [2,] 0.9997100 0.0002900472 #>  [3,] 0.9991027 0.0008972675 #>  [4,] 0.9993577 0.0006422936 #>  [5,] 0.9988224 0.0011775661 #>  [6,] 0.9998096 0.0001904362 #>  [7,] 0.9996870 0.0003129924 #>  [8,] 0.9995379 0.0004620862 #>  [9,] 0.9996966 0.0003034098 #> [10,] 0.9996844 0.0003156277 #> [11,] 0.9996913 0.0003087125 #> [12,] 0.9978832 0.0021168200 #> [13,] 0.9989350 0.0010650292 #> [14,] 0.9989430 0.0010569895 #> [15,] 0.9996842 0.0003158433 #> [16,] 0.9996619 0.0003380505 #> [17,] 0.9993783 0.0006217124 #> [18,] 0.9993783 0.0006217124 #> [19,] 0.9997579 0.0002421144 #> [20,] 0.9989548 0.0010451980 #>  #> $rowc_mm #>      [,1] #> [1,]    1 #>  #> $cov_mm #>      [,1] #> [1,]    1 #>  #> $RowClusters #> $RowClusters[[1]] #>  [1]  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19 20 #>  #> $RowClusters[[2]] #> integer(0) #>  #>   # Model Log(P(Y=k)/P(Y=1))=mu_k+phi_k*(colc_coef_c) with 3 column clustering groups: clustord.fit(Y~COLCLUST,model=\"OSM\",nclus.column=3,long.df=long.df,              EM.control=list(EMcycles=2,startEMcycles=2), nstarts=2) #> [1] \"Converting factor ROW to numeric.\" #> [1] \"EM algorithm for OSM\" #> Randomly generated start #1 #> # weights:  6 (2 variable) #> initial  value 109.861229  #> final  value 109.492385  #> converged #> Random starts model iter= 1  incomplete-data log.like= -109.57580646433  #> Random starts model iter= 2  incomplete-data log.like= -109.521309321868  #> Found better incomplete LL: -109.521309321868  #> Randomly generated start #2 #> Random starts model iter= 1  incomplete-data log.like= -109.495680843128  #> Random starts model iter= 2  incomplete-data log.like= -109.492581280647  #> Found better incomplete LL: -109.492581280647  #> Full model iter= 1  incomplete-data log.like= -109.492479446288  #> Full model iter= 2  incomplete-data log.like= -109.492477331605  #> $info #>         n         p         q      npar ninitvect         C  #>        20         5         3         7         5         3  #>  #> $model #> [1] \"OSM\" #>  #> $EM.status #> $EM.status$iter #> [1] 2 #>  #> $EM.status$finished #> [1] TRUE #>  #> $EM.status$converged #> [1] FALSE #>  #> $EM.status$new.llc #> [1] -109.5541 #>  #> $EM.status$new.lli #> [1] -109.4925 #>  #> $EM.status$previous.lli #> [1] -109.4925 #>  #> $EM.status$llc.for.best.lli #> [1] -109.5541 #>  #> $EM.status$params.for.best.lli #> $EM.status$params.for.best.lli$mu #>                  mu        mu  #> 0.0000000 0.1173467 3.2574226  #>  #> $EM.status$params.for.best.lli$phi #>                       phi               #> 0.0000000000 0.0008762727 1.0000000000  #>  #> $EM.status$params.for.best.lli$pi #> [1] 0.9983194 0.0016806 0.0000010 #>  #> $EM.status$params.for.best.lli$colc #>    rowc_r    rowc_r            #> -3.352980 -3.211598  6.564577  #>  #>  #> $EM.status$best.lli #> [1] -109.4925 #>  #> $EM.status$paramstopping #> [1] TRUE #>  #>  #> $criteria #> $criteria$Res.Dev #> [1] 218.985 #>  #> $criteria$AIC #> [1] 232.985 #>  #> $criteria$AICc #> [1] 234.5674 #>  #> $criteria$BIC #> [1] 251.2211 #>  #> $criteria$ICL #> [1] 251.3444 #>  #>  #> $numerical.correction.epsilon #> [1] 1e-06 #>  #> $constraint_sum_zero #> [1] TRUE #>  #> $param_lengths #>        mu       phi      rowc       col  rowc_col  rowc_cov       cov      colc  #>         3         0         0         0         0         0         0         3  #> rowc_colc       row  colc_row  colc_cov  #>         0         0         0         0  #>  #> $initvect #>         mu         mu        phi     rowc_r     rowc_r  #>  0.1173723  3.2759305 -7.0389485 -3.3716084 -3.1744609  #>  #> $parlist.out #> $parlist.out$mu #>                  mu        mu  #> 0.0000000 0.1173467 3.2574226  #>  #> $parlist.out$phi #>                       phi               #> 0.0000000000 0.0008762727 1.0000000000  #>  #> $parlist.out$colc #>    rowc_r    rowc_r            #> -3.352980 -3.211598  6.564577  #>  #>  #> $kappa.out #> [1] 0.9983194 0.0016806 0.0000010 #>  #> $ppc #>           [,1]        [,2]         [,3] #> [1,] 0.9984184 0.001581564 1.529723e-56 #> [2,] 0.9989330 0.001066954 3.751678e-65 #> [3,] 0.9989323 0.001067690 3.884386e-65 #> [4,] 0.9976570 0.002342991 6.128356e-48 #> [5,] 0.9976562 0.002343799 6.235801e-48 #>  #> $colc_mm #>      [,1] #> [1,]    1 #>  #> $cov_mm #>      [,1] #> [1,]    1 #>  #> $ColumnClusters #> $ColumnClusters[[1]] #> [1] 1 2 3 4 5 #>  #> $ColumnClusters[[2]] #> integer(0) #>  #> $ColumnClusters[[3]] #> integer(0) #>  #>  #> $rowc_format_param_lengths #>        mu       phi      rowc       col  rowc_col  rowc_cov       cov      colc  #>         3         0         3         0         0         0         0         0  #> rowc_colc       row  colc_row  colc_cov  #>         0         0         0         0  #>  #> $rowc_format_outvect #>         mu         mu        phi     rowc_r     rowc_r  #>  0.1173467  3.2574226 -7.0389566 -3.3529796 -3.2115975  #>  #> $rowc_format_parlist.init #> $rowc_format_parlist.init$mu #>                  mu        mu  #> 0.0000000 0.1173723 3.2759305  #>  #> $rowc_format_parlist.init$phi #>                       phi               #> 0.0000000000 0.0008762798 1.0000000000  #>  #> $rowc_format_parlist.init$rowc #>    rowc_r    rowc_r            #> -3.371608 -3.174461  6.546069  #>  #>  #> $rowc_format_rowc_mm #>      [,1] #> [1,]    1 #>   # Model Log(P(Y=k)/P(Y=1))=mu_k+phi_k*(colc_coef_c + row_coef_i) with 3 column clustering groups: clustord.fit(Y~COLCLUST+ROW,model=\"OSM\",nclus.column=3,long.df=long.df,              EM.control=list(EMcycles=2,startEMcycles=2), nstarts=2) #> [1] \"Converting factor ROW to numeric.\" #> [1] \"EM algorithm for OSM\" #> Randomly generated start #1 #> # weights:  63 (40 variable) #> initial  value 109.861229  #> iter  10 value 89.607875 #> iter  20 value 88.994687 #> iter  30 value 88.986018 #> final  value 88.985732  #> converged #> Using the output of simpler model as initial values for full model #> Row-cluster-only model iter= 1  incomplete-data log.like= -109.497801384033  #> Row-cluster-only model iter= 2  incomplete-data log.like= -109.497860122016  #> === End of initial row-cluster-only model fitting === #> Random starts model iter= 1  incomplete-data log.like= -167.000514493879  #> Random starts model iter= 2  incomplete-data log.like= -167.000513407872  #> Found better incomplete LL: -167.000513407872  #> Randomly generated start #2 #> Using the output of simpler model as initial values for full model #> Row-cluster-only model iter= 1  incomplete-data log.like= -109.978990500391  #> Row-cluster-only model iter= 2  incomplete-data log.like= -109.969540836449  #> === End of initial row-cluster-only model fitting === #> Random starts model iter= 1  incomplete-data log.like= -104.685517520385  #> Random starts model iter= 2  incomplete-data log.like= -104.662039583642  #> Found better incomplete LL: -104.662039583642  #> Full model iter= 1  incomplete-data log.like= -104.614621013004  #> Full model iter= 2  incomplete-data log.like= -104.613743141007  #> $info #>         n         p         q      npar ninitvect         C  #>        20         5         3        26        24         3  #>  #> $model #> [1] \"OSM\" #>  #> $EM.status #> $EM.status$iter #> [1] 2 #>  #> $EM.status$finished #> [1] TRUE #>  #> $EM.status$converged #> [1] FALSE #>  #> $EM.status$new.llc #> [1] -106.9178 #>  #> $EM.status$new.lli #> [1] -104.6137 #>  #> $EM.status$previous.lli #> [1] -104.6146 #>  #> $EM.status$llc.for.best.lli #> [1] -106.9178 #>  #> $EM.status$params.for.best.lli #> $EM.status$params.for.best.lli$mu #>                    mu         mu  #>  0.0000000  0.1144083 -0.7104454  #>  #> $EM.status$params.for.best.lli$phi #>                       phi               #> 0.000000e+00 4.186309e-48 1.000000e+00  #>  #> $EM.status$params.for.best.lli$pi #> [1] 7.951458e-01 1.601233e-06 2.048526e-01 #>  #> $EM.status$params.for.best.lli$colc #>     rowc_r     rowc_r             #> -0.1138723 -0.1164820  0.2303543  #>  #> $EM.status$params.for.best.lli$row #>       col_j       col_j       col_j       col_j       col_j       col_j  #>   0.1135801   1.0987726   1.0987677   0.1135843   0.1135837   1.0987698  #>       col_j       col_j       col_j       col_j       col_j       col_j  #>   1.0987722   1.0987670   1.0987716   1.9133900   1.0987727 -12.8246898  #>       col_j       col_j       col_j       col_j       col_j       col_j  #>   0.1135861   1.0987732   0.1135817   0.1135843   0.1135846   0.1135816  #>       col_j              #>   1.0987667   0.1136999  #>  #>  #> $EM.status$best.lli #> [1] -104.6137 #>  #> $EM.status$paramstopping #> [1] TRUE #>  #>  #> $criteria #> $criteria$Res.Dev #> [1] 209.2275 #>  #> $criteria$AIC #> [1] 261.2275 #>  #> $criteria$AICc #> [1] 282.2275 #>  #> $criteria$BIC #> [1] 328.9619 #>  #> $criteria$ICL #> [1] 333.5701 #>  #>  #> $numerical.correction.epsilon #> [1] 1e-06 #>  #> $constraint_sum_zero #> [1] TRUE #>  #> $param_lengths #>        mu       phi      rowc       col  rowc_col  rowc_cov       cov      colc  #>         3         0         0         0         0         0         0         3  #> rowc_colc       row  colc_row  colc_cov  #>         0        20         0         0  #>  #> $initvect #>           mu           mu          phi       rowc_r       rowc_r        col_j  #>    0.1144202   -0.6965845 -109.0922650   -0.1640731   -0.1485142    0.1111558  #>        col_j        col_j        col_j        col_j        col_j        col_j  #>    1.1005736    1.1006578    0.1112096    0.1112014    1.1006218    1.1005794  #>        col_j        col_j        col_j        col_j        col_j        col_j  #>    1.1006688    1.1005910    1.9189708    1.1005715  -12.8252520    0.1112334  #>        col_j        col_j        col_j        col_j        col_j        col_j  #>    1.1005631    0.1111761    0.1112096    0.1112140    0.1111743    1.1006747  #>  #> $parlist.out #> $parlist.out$mu #>                    mu         mu  #>  0.0000000  0.1144083 -0.7104454  #>  #> $parlist.out$phi #>                       phi               #> 0.000000e+00 4.186309e-48 1.000000e+00  #>  #> $parlist.out$colc #>     rowc_r     rowc_r             #> -0.1138723 -0.1164820  0.2303543  #>  #> $parlist.out$row #>       col_j       col_j       col_j       col_j       col_j       col_j  #>   0.1135801   1.0987726   1.0987677   0.1135843   0.1135837   1.0987698  #>       col_j       col_j       col_j       col_j       col_j       col_j  #>   1.0987722   1.0987670   1.0987716   1.9133900   1.0987727 -12.8246898  #>       col_j       col_j       col_j       col_j       col_j       col_j  #>   0.1135861   1.0987732   0.1135817   0.1135843   0.1135846   0.1135816  #>       col_j              #>   1.0987667   0.1136999  #>  #>  #> $kappa.out #> [1] 7.951458e-01 1.601233e-06 2.048526e-01 #>  #> $ppc #>           [,1]         [,2]       [,3] #> [1,] 0.8272983 1.672588e-06 0.17269998 #> [2,] 0.9255256 1.813849e-06 0.07447263 #> [3,] 0.9255256 1.813849e-06 0.07447263 #> [4,] 0.6486898 1.352939e-06 0.35130883 #> [5,] 0.6486898 1.352939e-06 0.35130883 #>  #> $colc_mm #>      [,1] #> [1,]    1 #>  #> $cov_mm #>      [,1] #> [1,]    1 #>  #> $ColumnClusters #> $ColumnClusters[[1]] #> [1] 1 2 3 4 5 #>  #> $ColumnClusters[[2]] #> integer(0) #>  #> $ColumnClusters[[3]] #> integer(0) #>  #>  #> $rowc_format_param_lengths #>        mu       phi      rowc       col  rowc_col  rowc_cov       cov      colc  #>         3         0         3        20         0         0         0         0  #> rowc_colc       row  colc_row  colc_cov  #>         0         0         0         0  #>  #> $rowc_format_outvect #>           mu           mu          phi       rowc_r       rowc_r        col_j  #>    0.1144083   -0.7104454 -109.0922650   -0.1138723   -0.1164820    0.1135801  #>        col_j        col_j        col_j        col_j        col_j        col_j  #>    1.0987726    1.0987677    0.1135843    0.1135837    1.0987698    1.0987722  #>        col_j        col_j        col_j        col_j        col_j        col_j  #>    1.0987670    1.0987716    1.9133900    1.0987727  -12.8246898    0.1135861  #>        col_j        col_j        col_j        col_j        col_j        col_j  #>    1.0987732    0.1135817    0.1135843    0.1135846    0.1135816    1.0987667  #>  #> $rowc_format_parlist.init #> $rowc_format_parlist.init$mu #>                    mu         mu  #>  0.0000000  0.1144202 -0.6965845  #>  #> $rowc_format_parlist.init$phi #>                       phi               #> 0.000000e+00 4.186309e-48 1.000000e+00  #>  #> $rowc_format_parlist.init$rowc #>     rowc_r     rowc_r             #> -0.1640731 -0.1485142  0.3125872  #>  #> $rowc_format_parlist.init$col #>       col_j       col_j       col_j       col_j       col_j       col_j  #>   0.1111558   1.1005736   1.1006578   0.1112096   0.1112014   1.1006218  #>       col_j       col_j       col_j       col_j       col_j       col_j  #>   1.1005794   1.1006688   1.1005910   1.9189708   1.1005715 -12.8252520  #>       col_j       col_j       col_j       col_j       col_j       col_j  #>   0.1112334   1.1005631   0.1111761   0.1112096   0.1112140   0.1111743  #>       col_j              #>   1.1006747   0.1112053  #>  #>  #> $rowc_format_rowc_mm #>      [,1] #> [1,]    1 #>   if (FALSE) { # Model Log(P(Y=k)/P(Y=1))=mu_k+phi_k*(rowc_coef_r + colc_coef_c) #    with 3 row clustering groups and 2 column clustering groups: clustord.fit(Y~ROWCLUST+COLCLUST,model=\"OSM\",nclus.row=3,nclus.column=2,long.df=long.df,              EM.control=list(EMcycles=2), nstarts=1)  # Model Logit(P(Y<=k))=mu_k-rowc_coef_r-colc_coef_c-rowc_colc_coef_rc #    with 2 row clustering groups and 4 column clustering groups, and #    interactions between them: clustord.fit(Y~ROWCLUST*COLCLUST, model=\"POM\", nclus.row=2, nclus.column=4,              long.df=long.df,EM.control=list(EMcycles=2), nstarts=1,              start_from_simple_model=FALSE) }"},{"path":"https://vuw-clustering.github.io/clustord/reference/mat2df.html","id":null,"dir":"Reference","previous_headings":"","what":"Converting matrix of responses into a long-form data frame and incorporating\ncovariates, if supplied. — mat2df","title":"Converting matrix of responses into a long-form data frame and incorporating\ncovariates, if supplied. — mat2df","text":"Converting matrix responses long-form data frame incorporating covariates, supplied.","code":""},{"path":"https://vuw-clustering.github.io/clustord/reference/mat2df.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Converting matrix of responses into a long-form data frame and incorporating\ncovariates, if supplied. — mat2df","text":"","code":"mat2df(mat, xr.df = NULL, xc.df = NULL)"},{"path":"https://vuw-clustering.github.io/clustord/reference/mat2df.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Converting matrix of responses into a long-form data frame and incorporating\ncovariates, if supplied. — mat2df","text":"mat matrix responses clustered xr.df optional data frame covariates corresponding rows mat. row xr.df corresponds one row mat, column xr.df covariate. xc.df optional data frame covariates corresponding columns mat. row xc.df corresponds one column mat, column xc.df covariate.","code":""},{"path":"https://vuw-clustering.github.io/clustord/reference/mat2df.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Converting matrix of responses into a long-form data frame and incorporating\ncovariates, if supplied. — mat2df","text":"data frame columns Y, ROW COL,    additional columns covariates xr.df xc.df,    included. Y column output contains entries mat,    one row output per one cell mat, ROW  COL entries indicate row column data matrix    correspond given cell. cells NA left    output data frame. xr.df supplied, additional columns    output corresponding columns xr.df, values    covariate repeated every entry corresponding    row data matrix. Similarly, xc.df supplied, additional columns    output corresponding columns xc.df, values    covariate repeated every entry    corresponding column data matrix.","code":""}]
