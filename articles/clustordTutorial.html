<!DOCTYPE html>
<!-- Generated by pkgdown: do not edit by hand --><html lang="en">
<head>
<meta http-equiv="Content-Type" content="text/html; charset=UTF-8">
<meta charset="utf-8">
<meta http-equiv="X-UA-Compatible" content="IE=edge">
<meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">
<title>`clustord` Tutorial • clustord</title>
<script src="../deps/jquery-3.6.0/jquery-3.6.0.min.js"></script><meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">
<link href="../deps/bootstrap-5.3.1/bootstrap.min.css" rel="stylesheet">
<script src="../deps/bootstrap-5.3.1/bootstrap.bundle.min.js"></script><link href="../deps/font-awesome-6.5.2/css/all.min.css" rel="stylesheet">
<link href="../deps/font-awesome-6.5.2/css/v4-shims.min.css" rel="stylesheet">
<script src="../deps/headroom-0.11.0/headroom.min.js"></script><script src="../deps/headroom-0.11.0/jQuery.headroom.min.js"></script><script src="../deps/bootstrap-toc-1.0.1/bootstrap-toc.min.js"></script><script src="../deps/clipboard.js-2.0.11/clipboard.min.js"></script><script src="../deps/search-1.0.0/autocomplete.jquery.min.js"></script><script src="../deps/search-1.0.0/fuse.min.js"></script><script src="../deps/search-1.0.0/mark.min.js"></script><!-- pkgdown --><script src="../pkgdown.js"></script><meta property="og:title" content="`clustord` Tutorial">
</head>
<body>
    <a href="#main" class="visually-hidden-focusable">Skip to contents</a>


    <nav class="navbar navbar-expand-lg fixed-top bg-primary" data-bs-theme="dark" aria-label="Site navigation"><div class="container">

    <a class="navbar-brand me-2" href="../index.html">clustord</a>

    <small class="nav-text text-muted me-auto" data-bs-toggle="tooltip" data-bs-placement="bottom" title="">1.2.0</small>


    <button class="navbar-toggler" type="button" data-bs-toggle="collapse" data-bs-target="#navbar" aria-controls="navbar" aria-expanded="false" aria-label="Toggle navigation">
      <span class="navbar-toggler-icon"></span>
    </button>

    <div id="navbar" class="collapse navbar-collapse ms-3">
      <ul class="navbar-nav me-auto">
<li class="nav-item"><a class="nav-link" href="../reference/index.html">Reference</a></li>
<li class="active nav-item dropdown">
  <button class="nav-link dropdown-toggle" type="button" id="dropdown-articles" data-bs-toggle="dropdown" aria-expanded="false" aria-haspopup="true">Articles</button>
  <ul class="dropdown-menu" aria-labelledby="dropdown-articles">
<li><a class="dropdown-item" href="../articles/clustordOrdinalModels.html">`clustord` Ordinal Models</a></li>
    <li><a class="dropdown-item" href="../articles/clustordStructureSummary.html">`clustord` Structure Summary</a></li>
    <li><a class="dropdown-item" href="../articles/clustordTutorial.html">`clustord` Tutorial</a></li>
    <li><a class="dropdown-item" href="../articles/RegressionwithOSM.html">Regression with the Ordered Stereotype Model (OSM)</a></li>
  </ul>
</li>
      </ul>
<ul class="navbar-nav">
<li class="nav-item"><form class="form-inline" role="search">
 <input class="form-control" type="search" name="search-input" id="search-input" autocomplete="off" aria-label="Search site" placeholder="Search for" data-search-index="../search.json">
</form></li>
      </ul>
</div>


  </div>
</nav><div class="container template-article">




<div class="row">
  <main id="main" class="col-md-9"><div class="page-header">

      <h1>`clustord` Tutorial</h1>
                        <h4 data-toc-skip class="author">Louise
McMillan</h4>
            
            <h4 data-toc-skip class="date">2024-12-08</h4>
      

      <div class="d-none name"><code>clustordTutorial.Rmd</code></div>
    </div>

    
    
<!-- # ```{r , include=FALSE} -->
<!-- # knitr::opts_chunk$set(eval=FALSE) -->
<!-- # ``` -->
<div class="section level2">
<h2 id="tldr">
<strong>TL:DR</strong><a class="anchor" aria-label="anchor" href="#tldr"></a>
</h2>
<p>The <code><a href="../reference/clustord.html">clustord()</a></code> function can perform row clustering,
column clustering or biclustering of a data matrix. The
<code>formula</code> argument works similarly to the ones in
<code><a href="https://rdrr.io/r/stats/lm.html" class="external-link">lm()</a></code> and <code><a href="https://rdrr.io/r/stats/glm.html" class="external-link">glm()</a></code>, except it uses four special
keywords: <code>ROWCLUST</code> and <code>COLCLUST</code> include row or
column clusters, and <code>ROW</code> and <code>COL</code> include
individual row and column effects.</p>
<p>You have to convert the data matrix to long-format <strong>before
clustering</strong>, using the <code><a href="../reference/mat2df.html">mat2df()</a></code> function.
<strong>After clustering</strong>, perform model selection using AIC or
BIC in the <code>criteria</code> part of the output. Examine the
<strong>parameter estimates</strong> within the <code>parlist.out</code>
part of the output. <strong>Positive</strong> parameter estimates
increase the chances of getting <strong>higher</strong> ordinal
responses, whereas <strong>negative</strong> parameter estimates
increase the chances of getting <strong>lower</strong> ordinal
responses.</p>
<p>You can include covariates in the clustering, and they can be
numerical or categorical, just like predictors in a regression model.
Add these as inputs to <code><a href="../reference/mat2df.html">mat2df()</a></code> to make the object for
clustering. Use the covariate names in the formula like in
<code><a href="https://rdrr.io/r/stats/lm.html" class="external-link">lm()</a></code> or <code><a href="https://rdrr.io/r/stats/glm.html" class="external-link">glm()</a></code>.</p>
<p>Check the algorithm has converged using
<code>EM.status$converged</code> in the output object, and if it has
not, try increasing the number of random starting points using
<code>nstarts</code> or increase the number of EM iterations using the
<code>EM.control = list(EMcycles = X)</code> input, where X is the
number of iterations you want.</p>
<p><code>clustord</code> can fit two kinds of ordinal models. “POM”, the
proportional-odds model, is the simplest, and the most widely used
ordinal model. “OSM”, the ordered stereotype model, is more flexible and
its <code>phi</code> parameters can be used as a more informed way of
recoding the ordinal data numerically. These two models are discussed in
a <strong>separate vignette</strong>, <em>“Ordinal Models”</em>.</p>
</div>
<div class="section level2">
<h2 id="introduction">Introduction<a class="anchor" aria-label="anchor" href="#introduction"></a>
</h2>
<p>The package <strong><code>clustord</code></strong> uses a function
<code><a href="../reference/clustord.html">clustord()</a></code> to link <strong>finite-mixture clustering and
biclustering</strong> (Pledger and Arnold, 2014) with two ordinal
models: the proportional odds model and the ordered stereotype model
(Agresti, 2010, and Anderson, 1984). The clustering models in this
package are highly flexible and can incorporate distinct patterns of
subsets of items within clusters, and can also incorporate additional
covariates.</p>
<p>For this package, we assume that you have a dataset of ordinal data.
The most common form of this is survey data, such as you might get by
asking participants to ask a series of questions with Likert-scale
answers (for example, ranking from 1 = “Strongly Disagree” to 5 =
“Strongly Agree”).</p>
<p><img src="vignette_fig%2Fsurvey_table1.png" width="70%" style="display: block; margin: auto;"></p>
<p>The <code>clustord</code> package can cluster the
<strong>rows</strong> of this data matrix, which often correspond to the
subjects or the observations:</p>
<p><img src="vignette_fig%2Fsurvey_table2_rowclustering.png" width="70%" style="display: block; margin: auto;"></p>
<p>Or the package can cluster the <strong>columns</strong> of this data
matrix, which often correspond to the survey questions:</p>
<p><img src="vignette_fig%2Fsurvey_table3_columnclustering.png" width="70%" style="display: block; margin: auto;"></p>
<p>Mathematically, these two forms of clustering are equivalent, so you
can orient your data matrix either way round, and just choose the
appropriate clustering direction.</p>
<p>The package can also cluster <strong>both</strong> rows and columns
<strong>simultaneously</strong>, which we call
<strong>biclustering</strong>. This finds the combinations of subjects
and questions that exhibit similar response patterns:</p>
<p><img src="vignette_fig%2Fsurvey_table4_biclustering.png" width="70%" style="display: block; margin: auto;"></p>
<div class="section level3">
<h3 id="model-based-clustering">Model-based clustering<a class="anchor" aria-label="anchor" href="#model-based-clustering"></a>
</h3>
<p>The clustering algorithms in this package are <strong>model-based
clustering</strong> methods. The models are finite-mixture models, in
which each cluster is assumed to correspond to a particular statistical
distribution.</p>
<p><img src="vignette_fig%2Fmodel-based.png" width="70%" style="display: block; margin: auto;"></p>
<p>Many common clustering methods, such as k-means (Lloyd, 1982 and
MacQueen, 1967) are <strong>distance-based</strong> instead of
model-based.</p>
<p><img src="vignette_fig%2Fdistance-based.png" width="70%" style="display: block; margin: auto;"></p>
<p>Model-based clustering methods often take a little longer to set up
and run, but they have one major advantage. All clustering methods
estimate which cluster each item is a member of. This package, like
other finite-mixture methods, provides <strong>posterior probabilities
of cluster membership</strong>, given the data. But because the clusters
are assumed to correspond to statistical distributions, these methods
also provide <strong>parameter estimates</strong> for the statistical
distributions. In other words, you can obtain general information about
the patterns exhibited by the clusters.</p>
<p>The statistical framework of model-based clustering also allows you
to carry out goodness-of-fit tests and perform model selection using
common measures such as AIC and BIC.</p>
<p>This package fits the mixture models by maximising the likelihood
using the Expectation-Maximisation algorithm (Dempster, Laird &amp;
Rubin 1977, McLachlan and Krishnan 2007). Many examples of these types
of models can be found in, e.g., McLachlan &amp; Basford (1988) or
McLachlan &amp; Peel (2000).</p>
</div>
<div class="section level3">
<h3 id="ordinal-data">Ordinal data<a class="anchor" aria-label="anchor" href="#ordinal-data"></a>
</h3>
<p><img src="vignette_fig%2Fsurvey_table_categorical.png" width="70%" style="display: block; margin: auto;"></p>
<p>A very common approach to clustering ordinal data is to number the
categories of each ordinal variable and then treat the data as
continuous. This allows the use of numerical clustering methods like
k-means. But the encoding of the ordinal categories as continuous
encodes assumptions about the relative spacings of the ordinal
categories.</p>
<p>The most common approach is to number the categories from 1 to
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mi>q</mi><annotation encoding="application/x-tex">q</annotation></semantics></math>:</p>
<p><img src="vignette_fig%2Fsurvey_table_categorical_numbered.png" width="70%" style="display: block; margin: auto;"></p>
<p>and then often the category labels are dropped:</p>
<p><img src="vignette_fig%2Fsurvey_table_numbered_only.png" width="70%" style="display: block; margin: auto;"></p>
<p>This encoding assumes that the levels 1 and 2 are as close together
as levels 2 and 3. But that assumption is not necessarily accurate. For
example, if people are asked a question about how much pain they are
feeling, there may be a bigger difference in perception between pain
levels Moderate and Severe (2 and 3) than between pain levels Mild and
Moderate (1 and 2):</p>
<p><img src="vignette_fig%2Fordinal_scales.png" width="70%" style="display: block; margin: auto;"></p>
<p>The top scale assumes the levels are equally spaced, but the bottom
scale could be a more accurate representation.</p>
<p>Rather than treating the ordinal data as numerical and applying
continuous-data clustering algorithms, the ordinal models in this
package make no assumptions about the numerical encoding of the ordinal
categories, and only observe the ranking of the categories.</p>
<p>The <strong>ordered stereotype model (OSM)</strong>, one of the two
ordinal models in this package goes further: a set of the model
parameters,
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mo stretchy="false" form="prefix">{</mo><mi>p</mi><mi>h</mi><msub><mi>i</mi><mi>k</mi></msub><mo stretchy="false" form="postfix">}</mo></mrow><annotation encoding="application/x-tex">\{phi_k\}</annotation></semantics></math>,
can be treated as scores for the category levels. The fitted values of
the parameters can be used as a scoring system that more accurately
reflects the spacings between the levels according to the data:</p>
<p><img src="vignette_fig%2Fordinal_scale_phi.png" width="70%" style="display: block; margin: auto;"></p>
<p>If you start with five categories, but the fitted
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mo stretchy="false" form="prefix">{</mo><msub><mi>ϕ</mi><mi>k</mi></msub><mo stretchy="false" form="postfix">}</mo></mrow><annotation encoding="application/x-tex">\{\phi_k\}</annotation></semantics></math>
values for levels 1 and 2 are very close together (e.g. 0 and 0.09),
this indicates that there is almost no different in the information
provided by levels 2 and 3. So you could potentially combine those two
levels, and simplify the data without losing much information.</p>
<p>The ordinal models are discussed in more detail in the <em>Ordinal
Models</em> vignette.</p>
</div>
</div>
<div class="section level2">
<h2 id="fitting-clustord-models">Fitting <code>clustord</code> models<a class="anchor" aria-label="anchor" href="#fitting-clustord-models"></a>
</h2>
<div class="sourceCode" id="cb1"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="kw"><a href="https://rdrr.io/r/base/library.html" class="external-link">library</a></span><span class="op">(</span><span class="va"><a href="https://vuw-clustering.github.io/clustord/">clustord</a></span><span class="op">)</span></span></code></pre></div>
<div class="section level3">
<h3 id="data-format">Data format<a class="anchor" aria-label="anchor" href="#data-format"></a>
</h3>
<p>For this vignette, we will use a simple survey example, in which the
data matrix is a matrix of responses to questions with the subjects as
rows and the questions as columns. All the questions have responses
between 1 and 7 – the current version of <code>clustord</code> is not
set up to handle datasets where some questions have more responses than
others.</p>
<div class="sourceCode" id="cb2"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="va">df</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/utils/read.table.html" class="external-link">read.table</a></span><span class="op">(</span><span class="st">"eval_survey.txt"</span><span class="op">)</span></span>
<span><span class="fu"><a href="https://rdrr.io/r/base/colnames.html" class="external-link">colnames</a></span><span class="op">(</span><span class="va">df</span><span class="op">)</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/base/paste.html" class="external-link">paste0</a></span><span class="op">(</span><span class="st">"Q"</span>, <span class="fl">1</span><span class="op">:</span><span class="fu"><a href="https://rdrr.io/r/base/nrow.html" class="external-link">ncol</a></span><span class="op">(</span><span class="va">df</span><span class="op">)</span><span class="op">)</span></span>
<span><span class="fu"><a href="https://rdrr.io/r/base/colnames.html" class="external-link">rownames</a></span><span class="op">(</span><span class="va">df</span><span class="op">)</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/base/paste.html" class="external-link">paste0</a></span><span class="op">(</span><span class="st">"ID"</span>, <span class="fl">1</span><span class="op">:</span><span class="fu"><a href="https://rdrr.io/r/base/nrow.html" class="external-link">nrow</a></span><span class="op">(</span><span class="va">df</span><span class="op">)</span><span class="op">)</span></span>
<span><span class="fu"><a href="https://rdrr.io/r/utils/head.html" class="external-link">head</a></span><span class="op">(</span><span class="va">df</span><span class="op">)</span></span></code></pre></div>
<pre><code><span><span class="co">##     Q1 Q2 Q3 Q4 Q5 Q6 Q7 Q8 Q9 Q10 Q11 Q12</span></span>
<span><span class="co">## ID1  6  2  2  2  2  3  3  3  3   3   2   2</span></span>
<span><span class="co">## ID2  7  1  2  1  2  3  4  4  4   5   2   2</span></span>
<span><span class="co">## ID3  7  2  2  1  3  3  2  3  4   3   3   3</span></span>
<span><span class="co">## ID4  6  3  3  2  2  3  3  3  4   4   3   3</span></span>
<span><span class="co">## ID5  7  2  2  2  2  3  3  4  4   4   2   4</span></span>
<span><span class="co">## ID6  6  2  1  2  6  3  1  3  6   3  NA   3</span></span></code></pre>
<div class="sourceCode" id="cb4"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="fu"><a href="https://rdrr.io/r/base/dim.html" class="external-link">dim</a></span><span class="op">(</span><span class="va">df</span><span class="op">)</span></span></code></pre></div>
<pre><code><span><span class="co">## [1] 82 12</span></span></code></pre>
<p>The illustrations show a tiny exemplar dataset. The actual dataset in
this analysis has 82 rows (subjects) and 12 columns (questions).</p>
<p>We will refer to the data matrix as
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mi>𝐘</mi><annotation encoding="application/x-tex">\bm{Y}</annotation></semantics></math>.
We index the rows of the data matrix with
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mi>i</mi><annotation encoding="application/x-tex">i</annotation></semantics></math>
and the columns of the data matrix with
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mi>j</mi><annotation encoding="application/x-tex">j</annotation></semantics></math>,
so an individual response value is defined as
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><msub><mi>Y</mi><mrow><mi>i</mi><mi>j</mi></mrow></msub><annotation encoding="application/x-tex">Y_{ij}</annotation></semantics></math>.</p>
<p><img src="vignette_fig%2Fsurvey_table_single_cell.png" width="70%" style="display: block; margin: auto;"></p>
<p>Before we can carry out any model-fitting with <code>clustord</code>,
we need to convert the data into a long-form data frame instead of a
data matrix. This long form, which is used to simplify the inner
implementation of the clustering process, has one row per cell in the
original data frame. Two of its columns are labelled <code>ROW</code>
and <code>COL</code> and these indicate which row and column in the
original data frame the response value came from:</p>
<p><img src="vignette_fig%2Flong_form_data_frame.png" width="40%" style="display: block; margin: auto;"></p>
<p>If a cell in the data matrix has missing data, that entry is not
included in the long-form data frame (so if 1 cell in a 10x10 data
matrix is missing, the long-form data frame will have 99 rows).</p>
<p>The long-form also incorporates any covariates linked to the
responses. We will discuss these more later.</p>
<p><code>clustord</code> provides a function, <code><a href="../reference/mat2df.html">mat2df()</a></code>, to
carry out the conversion to the long form data frame:</p>
<div class="sourceCode" id="cb6"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="va">long.df</span> <span class="op">&lt;-</span> <span class="fu"><a href="../reference/mat2df.html">mat2df</a></span><span class="op">(</span><span class="va">df</span><span class="op">)</span></span></code></pre></div>
<pre><code><span><span class="co">## Warning in mat2df(df): Removing 4 entries for which Y is NA.</span></span></code></pre>
<div class="sourceCode" id="cb8"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="fu"><a href="https://rdrr.io/r/utils/head.html" class="external-link">head</a></span><span class="op">(</span><span class="va">long.df</span><span class="op">)</span></span></code></pre></div>
<pre><code><span><span class="co">##   Y ROW COL</span></span>
<span><span class="co">## 1 6 ID1  Q1</span></span>
<span><span class="co">## 2 7 ID2  Q1</span></span>
<span><span class="co">## 3 7 ID3  Q1</span></span>
<span><span class="co">## 4 6 ID4  Q1</span></span>
<span><span class="co">## 5 7 ID5  Q1</span></span>
<span><span class="co">## 6 6 ID6  Q1</span></span></code></pre>
<p>You may construct the long-form data frame yourself if you want, but
there are minor restrictions: the data frame <strong>MUST
contain</strong> a column labelled “Y” that contains the response
values, a column labelled “ROW” (case-sensitive) that contains the row
names/numbers and a column labelled “COL” (case-sensitive) that contains
the column names/numbers, and rows for missing cell values
(<code>NA</code> or any other missing indicators) should be deleted.</p>
</div>
<div class="section level3">
<h3 id="clustord-models">
<code>clustord</code> models<a class="anchor" aria-label="anchor" href="#clustord-models"></a>
</h3>
<p>The specific structure of clustering model used in this page is the
form proposed in Pledger and Arnold (2014). That paper proposed models
for binary and count data (see the <code>clustglm</code> package by
Shirley Pledger), and similar forms were proposed for the proportional
odds model in Matechou et al. (2016) and for the ordered stereotype
model in Fernández et al. (2016, 2019).</p>
<p>These clustering models all have a linear predictor structure. The
link between the linear predictor and the response values varies for the
two different ordinal models, but the linear predictor structure is the
same for both, and the same linear predictor structure is used in the
<code>clustglm</code> models.</p>
<p>We will define
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><msub><mi>ν</mi><mrow><mi>i</mi><mi>j</mi></mrow></msub><annotation encoding="application/x-tex">\nu_{ij}</annotation></semantics></math>
to be the linear predictor for response
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><msub><mi>Y</mi><mrow><mi>i</mi><mi>j</mi></mrow></msub><annotation encoding="application/x-tex">Y_{ij}</annotation></semantics></math>.</p>
<p>The various models outlined below include different additive
components in the linear predictor that will influence the probabilities
of obtaining different response categories. We will call these
components “effects”. Regression models are often described as including
“main effects” and “interaction effects”, and sometimes “random
effects”, and similarly our clustering models will primarily have
“cluster effects”. But we can also include “covariate effects” and
“individual row/column effects”.</p>
</div>
<div class="section level3">
<h3 id="row-clustering">Row clustering<a class="anchor" aria-label="anchor" href="#row-clustering"></a>
</h3>
<div class="section level4">
<h4 id="row-cluster-effect-only">Row cluster effect only<a class="anchor" aria-label="anchor" href="#row-cluster-effect-only"></a>
</h4>
<p>We will describe possible row clustering structures first. The
individual row clusters are indexed
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mi>r</mi><annotation encoding="application/x-tex">r</annotation></semantics></math>.
The most basic row clustering model only has row cluster effects, and it
assumes that every response across all columns for a row
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mi>i</mi><annotation encoding="application/x-tex">i</annotation></semantics></math>
in cluster
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mi>r</mi><annotation encoding="application/x-tex">r</annotation></semantics></math>
has the same probabilities for different categories.</p>
<p>The main part of the linear predictor for this model is the “row
cluster effect”, that differs from cluster to cluster. The row cluster
effect parameters are labelled as <code>rowc</code> in the
<code><a href="../reference/clustord.html">clustord()</a></code> output.</p>
<p><img src="vignette_fig%2Fsurvey_table2_rowclustering.png" width="70%" style="display: block; margin: auto;"></p>
<p>In the console output, this basic model is described as the
<code>row-cluster-only model</code>. By default, this model is used as
the starting point for the other models: the starting points for the row
cluster parameter estimates are found by fitting this simpler model
first before fitting the full forms of more complex models.</p>
<div class="section level5">
<h5 id="fitting-the-model">Fitting the model<a class="anchor" aria-label="anchor" href="#fitting-the-model"></a>
</h5>
<p>We can fit this model using the <code><a href="../reference/clustord.html">clustord()</a></code> function,
which is the main model-fitting function in <code>clustord</code>. The
first input argument for <code><a href="../reference/clustord.html">clustord()</a></code> is
<code>formula</code>, which gives the formula for the model, just as in
<code><a href="https://rdrr.io/r/stats/lm.html" class="external-link">lm()</a></code>, <code><a href="https://rdrr.io/r/stats/glm.html" class="external-link">glm()</a></code> and other similar functions.</p>
<p>We fit this model using the <strong>case-sensitive keyword</strong>
<code>ROWCLUST</code> in the formula. The left-hand side of the formula
<strong>is always <code>Y</code></strong>. So the basic formula is:</p>
<pre><code><span><span class="va">Y</span> <span class="op">~</span> <span class="va">ROWCLUST</span></span></code></pre>
<p>The next input argument is a character string indicating the
<code>model</code>, which is either <code>"POM"</code> for the
proportional-odds model, <code>"OSM"</code> for the ordered-stereotype
model, or <code>"Binary"</code> for the binary model (which is the same
for proportional-odds and ordered-stereotype). We’ll talk about these
models in more detail later, and for now we’ll use the proportional-odds
model, which is the most widely-used and simplest ordinal model.</p>
<p>The third and fourth input arguments are <code>nclus.row</code> and
<code>nclus.column</code>, which are used to define the number of row
and/or column clusters. While we are doing row clustering, we will only
specify <code>nclus.row</code> and we will choose to fit 2 clusters.
<code>clustord</code> can only fit a specified number of clusters, and
later we will discuss how to select the best number of clusters.</p>
<p>The fifth input argument is <code>long.df</code>, which is asking for
the long form data frame we prepared earlier. So, leaving all the rest
of the arguments at their default values, we fit the basic row
clustering model to our dataset:</p>
<div class="sourceCode" id="cb11"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="fu"><a href="https://rdrr.io/r/base/Random.html" class="external-link">set.seed</a></span><span class="op">(</span><span class="fl">2</span><span class="op">)</span></span>
<span><span class="va">fit_rowclust_only</span> <span class="op">&lt;-</span> <span class="fu"><a href="../reference/clustord.html">clustord</a></span><span class="op">(</span><span class="va">Y</span> <span class="op">~</span> <span class="va">ROWCLUST</span>,</span>
<span>    <span class="st">"POM"</span>, nclus.row <span class="op">=</span> <span class="fl">2</span>, long.df <span class="op">=</span> <span class="va">long.df</span>,</span>
<span>    verbose <span class="op">=</span> <span class="cn">FALSE</span><span class="op">)</span></span></code></pre></div>
<p>This also uses the option <code>verbose=FALSE</code> which displays
reduced output during the progress of the algorithm. We will discuss the
meaning of the outputs in the section on important algorithm
settings.</p>
<p>This tutorial set the random number seed before running the fitting
process, in order to keep the included output consistent. The algorithm
uses a random selection of starting points (see the section on important
algorithm settings for more detail).</p>
</div>
<div class="section level5">
<h5 id="checking-the-output">Checking the output<a class="anchor" aria-label="anchor" href="#checking-the-output"></a>
</h5>
<p>Once the fit is completed we should first check that it has
converged:</p>
<div class="sourceCode" id="cb12"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="va">fit_rowclust_only</span><span class="op">$</span><span class="va">EM.status</span><span class="op">$</span><span class="va">converged</span></span></code></pre></div>
<pre><code><span><span class="co">## [1] TRUE</span></span></code></pre>
<p>Then we can look at the probabilities of cluster membership:</p>
<div class="sourceCode" id="cb14"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="fu"><a href="https://rdrr.io/r/base/Round.html" class="external-link">round</a></span><span class="op">(</span><span class="va">fit_rowclust_only</span><span class="op">$</span><span class="va">ppr</span>, <span class="fl">2</span><span class="op">)</span></span></code></pre></div>
<pre><code><span><span class="co">##       [,1] [,2]</span></span>
<span><span class="co">##  [1,] 1.00 0.00</span></span>
<span><span class="co">##  [2,] 1.00 0.00</span></span>
<span><span class="co">##  [3,] 1.00 0.00</span></span>
<span><span class="co">##  [4,] 1.00 0.00</span></span>
<span><span class="co">##  [5,] 1.00 0.00</span></span>
<span><span class="co">##  [6,] 1.00 0.00</span></span>
<span><span class="co">##  [7,] 1.00 0.00</span></span>
<span><span class="co">##  [8,] 1.00 0.00</span></span>
<span><span class="co">##  [9,] 1.00 0.00</span></span>
<span><span class="co">## [10,] 1.00 0.00</span></span>
<span><span class="co">## [11,] 1.00 0.00</span></span>
<span><span class="co">## [12,] 0.96 0.04</span></span>
<span><span class="co">## [13,] 1.00 0.00</span></span>
<span><span class="co">## [14,] 1.00 0.00</span></span>
<span><span class="co">## [15,] 1.00 0.00</span></span>
<span><span class="co">## [16,] 1.00 0.00</span></span>
<span><span class="co">## [17,] 0.00 1.00</span></span>
<span><span class="co">## [18,] 1.00 0.00</span></span>
<span><span class="co">## [19,] 1.00 0.00</span></span>
<span><span class="co">## [20,] 1.00 0.00</span></span>
<span><span class="co">## [21,] 1.00 0.00</span></span>
<span><span class="co">## [22,] 1.00 0.00</span></span>
<span><span class="co">## [23,] 1.00 0.00</span></span>
<span><span class="co">## [24,] 1.00 0.00</span></span>
<span><span class="co">## [25,] 1.00 0.00</span></span>
<span><span class="co">## [26,] 1.00 0.00</span></span>
<span><span class="co">## [27,] 1.00 0.00</span></span>
<span><span class="co">## [28,] 1.00 0.00</span></span>
<span><span class="co">## [29,] 1.00 0.00</span></span>
<span><span class="co">## [30,] 1.00 0.00</span></span>
<span><span class="co">## [31,] 1.00 0.00</span></span>
<span><span class="co">## [32,] 1.00 0.00</span></span>
<span><span class="co">## [33,] 0.00 1.00</span></span>
<span><span class="co">## [34,] 1.00 0.00</span></span>
<span><span class="co">## [35,] 1.00 0.00</span></span>
<span><span class="co">## [36,] 1.00 0.00</span></span>
<span><span class="co">## [37,] 1.00 0.00</span></span>
<span><span class="co">## [38,] 0.94 0.06</span></span>
<span><span class="co">## [39,] 1.00 0.00</span></span>
<span><span class="co">## [40,] 1.00 0.00</span></span>
<span><span class="co">## [41,] 1.00 0.00</span></span>
<span><span class="co">## [42,] 1.00 0.00</span></span>
<span><span class="co">## [43,] 1.00 0.00</span></span>
<span><span class="co">## [44,] 1.00 0.00</span></span>
<span><span class="co">## [45,] 1.00 0.00</span></span>
<span><span class="co">## [46,] 1.00 0.00</span></span>
<span><span class="co">## [47,] 1.00 0.00</span></span>
<span><span class="co">## [48,] 1.00 0.00</span></span>
<span><span class="co">## [49,] 1.00 0.00</span></span>
<span><span class="co">## [50,] 1.00 0.00</span></span>
<span><span class="co">## [51,] 1.00 0.00</span></span>
<span><span class="co">## [52,] 1.00 0.00</span></span>
<span><span class="co">## [53,] 1.00 0.00</span></span>
<span><span class="co">## [54,] 1.00 0.00</span></span>
<span><span class="co">## [55,] 1.00 0.00</span></span>
<span><span class="co">## [56,] 1.00 0.00</span></span>
<span><span class="co">## [57,] 1.00 0.00</span></span>
<span><span class="co">## [58,] 1.00 0.00</span></span>
<span><span class="co">## [59,] 1.00 0.00</span></span>
<span><span class="co">## [60,] 1.00 0.00</span></span>
<span><span class="co">## [61,] 0.00 1.00</span></span>
<span><span class="co">## [62,] 1.00 0.00</span></span>
<span><span class="co">## [63,] 1.00 0.00</span></span>
<span><span class="co">## [64,] 1.00 0.00</span></span>
<span><span class="co">## [65,] 1.00 0.00</span></span>
<span><span class="co">## [66,] 1.00 0.00</span></span>
<span><span class="co">## [67,] 0.00 1.00</span></span>
<span><span class="co">## [68,] 1.00 0.00</span></span>
<span><span class="co">## [69,] 1.00 0.00</span></span>
<span><span class="co">## [70,] 1.00 0.00</span></span>
<span><span class="co">## [71,] 1.00 0.00</span></span>
<span><span class="co">## [72,] 1.00 0.00</span></span>
<span><span class="co">## [73,] 1.00 0.00</span></span>
<span><span class="co">## [74,] 1.00 0.00</span></span>
<span><span class="co">## [75,] 1.00 0.00</span></span>
<span><span class="co">## [76,] 1.00 0.00</span></span>
<span><span class="co">## [77,] 1.00 0.00</span></span>
<span><span class="co">## [78,] 1.00 0.00</span></span>
<span><span class="co">## [79,] 1.00 0.00</span></span>
<span><span class="co">## [80,] 1.00 0.00</span></span>
<span><span class="co">## [81,] 1.00 0.00</span></span>
<span><span class="co">## [82,] 1.00 0.00</span></span></code></pre>
<p>In this instance, almost all of the individuals have been firmly
assigned to one cluster or the other cluster. I can also look at the
cluster memberships, which are obtained by the simple assignment process
of assigning each individual to the cluster for which they have the
highest posterior probability of membership (there are other ways to
assign individuals to clusters, but those are not implemented within
<code>clustord</code>).</p>
<div class="sourceCode" id="cb16"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="va">fit_rowclust_only</span><span class="op">$</span><span class="va">RowClusterMembers</span></span></code></pre></div>
<pre><code><span><span class="co">## [[1]]</span></span>
<span><span class="co">##  [1]  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 18 19 20 21 22 23 24 25 26</span></span>
<span><span class="co">## [26] 27 28 29 30 31 32 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52</span></span>
<span><span class="co">## [51] 53 54 55 56 57 58 59 60 62 63 64 65 66 68 69 70 71 72 73 74 75 76 77 78 79</span></span>
<span><span class="co">## [76] 80 81 82</span></span>
<span><span class="co">## </span></span>
<span><span class="co">## [[2]]</span></span>
<span><span class="co">## [1] 17 33 61 67</span></span></code></pre>
<p>For each cluster, a vector of row numbers in that cluster is
provided. In this instance, only four individuals have been allocated to
the second cluster.</p>
<p>The “mixing proportions”,
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><msub><mi>π</mi><mi>r</mi></msub><annotation encoding="application/x-tex">\pi_r</annotation></semantics></math>,
summarise the proportion of rows in each cluster (each mixing proportion
is the mean of the posterior probabilities for membership of that
cluster across all the rows).</p>
<div class="sourceCode" id="cb18"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="fu"><a href="https://rdrr.io/r/base/Round.html" class="external-link">round</a></span><span class="op">(</span><span class="va">fit_rowclust_only</span><span class="op">$</span><span class="va">pi.out</span>, <span class="fl">2</span><span class="op">)</span></span></code></pre></div>
<pre><code><span><span class="co">## [1] 0.95 0.05</span></span></code></pre>
<p>So only about 5% of the rows are in the second cluster, which matches
what we saw from the cluster memberships.</p>
<p>We can look at the parameter values for each cluster. The
<code>mu</code> values in the parameter list will be discussed later, in
the section about the different ordinal models. For now, we will just
look at the row cluster effects, which are called <code>rowc</code>. The
output includes the <code>.init</code> parameter values that were used
at the start of the EM algorithm, and the <code>.out</code> parameter
values that are the final ones at the end of the algorithm, so the
<code>.out</code> values are the ones we want:</p>
<div class="sourceCode" id="cb20"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="va">fit_rowclust_only</span><span class="op">$</span><span class="va">parlist.out</span><span class="op">$</span><span class="va">rowc</span></span></code></pre></div>
<pre><code><span><span class="co">##    rowc_1    rowc_2 </span></span>
<span><span class="co">##  1.732987 -1.732987</span></span></code></pre>
<p><strong>Positive</strong> values of the row cluster parameters
increase the probability of getting <strong>higher</strong> ordinal
categories, and <strong>negative</strong> values of the parameters
increase the probability of getting <strong>lower</strong> ordinal
categories.</p>
<p>We can see from this that individuals in the first cluster tend to
provide higher-value responses than individuals in the second
cluster.</p>
<p>We can also check this against the mean value of responses for
individuals in the first and second clusters:</p>
<div class="sourceCode" id="cb22"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="fu"><a href="https://rdrr.io/r/graphics/boxplot.html" class="external-link">boxplot</a></span><span class="op">(</span><span class="fu"><a href="https://rdrr.io/r/base/split.html" class="external-link">split</a></span><span class="op">(</span><span class="fu"><a href="https://rdrr.io/r/base/colSums.html" class="external-link">rowMeans</a></span><span class="op">(</span><span class="va">df</span><span class="op">)</span>, <span class="va">fit_rowclust_only</span><span class="op">$</span><span class="va">RowClusters</span><span class="op">)</span>,</span>
<span>    <span class="st">"Mean response values across all questions for each individual"</span>,</span>
<span>    names <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/base/c.html" class="external-link">c</a></span><span class="op">(</span><span class="st">"Cluster 1"</span>, <span class="st">"Cluster 2"</span><span class="op">)</span><span class="op">)</span></span></code></pre></div>
<p><img src="clustordTutorial_files/figure-html/unnamed-chunk-25-1.png" width="700"></p>
<p>We will discuss goodness-of-fit later in the section about model
selection.</p>
</div>
</div>
<div class="section level4">
<h4 id="row-clusters-with-individual-column-effects">Row clusters with individual column effects<a class="anchor" aria-label="anchor" href="#row-clusters-with-individual-column-effects"></a>
</h4>
<p>A second, slightly more complex row clustering model is one that
incorporates both the row cluster effects and also individual effects of
the columns.</p>
<p><img src="vignette_fig%2Fsurvey_table2c_rowclustering_columns.png" width="70%" style="display: block; margin: auto;"></p>
<p>We can see by looking at the actual data that this is necessary,
because we can see that the responses to Q1 tend to have much higher
values than the responses for the other questions. The row-cluster-only
model above treats all the columns as repeated measures, but that does
not appear to be a reasonable assumption in this case.</p>
<div class="sourceCode" id="cb23"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="fu"><a href="https://rdrr.io/r/utils/head.html" class="external-link">head</a></span><span class="op">(</span><span class="va">df</span><span class="op">)</span></span></code></pre></div>
<pre><code><span><span class="co">##     Q1 Q2 Q3 Q4 Q5 Q6 Q7 Q8 Q9 Q10 Q11 Q12</span></span>
<span><span class="co">## ID1  6  2  2  2  2  3  3  3  3   3   2   2</span></span>
<span><span class="co">## ID2  7  1  2  1  2  3  4  4  4   5   2   2</span></span>
<span><span class="co">## ID3  7  2  2  1  3  3  2  3  4   3   3   3</span></span>
<span><span class="co">## ID4  6  3  3  2  2  3  3  3  4   4   3   3</span></span>
<span><span class="co">## ID5  7  2  2  2  2  3  3  4  4   4   2   4</span></span>
<span><span class="co">## ID6  6  2  1  2  6  3  1  3  6   3  NA   3</span></span></code></pre>
<p>The additive nature of the clustering models in this package allows
to add to the linear predictor an effect of the individual columns. The
main part of the linear predictor for this model becomes
<code>rowc + col</code> where <code>col</code> are the individual
effects of the columns.</p>
<div class="section level5">
<h5 id="fitting-the-model-1">Fitting the model<a class="anchor" aria-label="anchor" href="#fitting-the-model-1"></a>
</h5>
<p>We fit this model using the <strong>case-sensitive keyword</strong>
<code>COL</code> in the formula:</p>
<pre><code><span><span class="va">Y</span> <span class="op">~</span> <span class="va">ROWCLUST</span> <span class="op">+</span> <span class="va">COL</span></span></code></pre>
<p>As you can see, the formula, just like the linear predictor, builds
up the components additively, just as in a regression formula
argument.</p>
<p>Note that, by default, when we try to fit this more complex model,
<code><a href="../reference/clustord.html">clustord()</a></code> will generate starting values for the row
cluster effect parameters by fitting the row-cluster-only model first,
before fitting the model with column effects.</p>
<p>We will fit this model using the same model type as before, POM:</p>
<div class="sourceCode" id="cb26"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="fu"><a href="https://rdrr.io/r/base/Random.html" class="external-link">set.seed</a></span><span class="op">(</span><span class="fl">3</span><span class="op">)</span></span>
<span><span class="va">fit_rowclust_cols</span> <span class="op">&lt;-</span> <span class="fu"><a href="../reference/clustord.html">clustord</a></span><span class="op">(</span><span class="va">Y</span> <span class="op">~</span> <span class="va">ROWCLUST</span> <span class="op">+</span></span>
<span>    <span class="va">COL</span>, <span class="st">"POM"</span>, nclus.row <span class="op">=</span> <span class="fl">2</span>, long.df <span class="op">=</span> <span class="va">long.df</span>,</span>
<span>    verbose <span class="op">=</span> <span class="cn">FALSE</span><span class="op">)</span></span></code></pre></div>
</div>
<div class="section level5">
<h5 id="checking-the-output-1">Checking the output<a class="anchor" aria-label="anchor" href="#checking-the-output-1"></a>
</h5>
<p>Again, once the fit is completed we should first check that it has
converged:</p>
<div class="sourceCode" id="cb27"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="va">fit_rowclust_cols</span><span class="op">$</span><span class="va">EM.status</span><span class="op">$</span><span class="va">converged</span></span></code></pre></div>
<pre><code><span><span class="co">## [1] TRUE</span></span></code></pre>
<p>Then we can look at the probabilities of cluster membership:</p>
<div class="sourceCode" id="cb29"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="fu"><a href="https://rdrr.io/r/base/Round.html" class="external-link">round</a></span><span class="op">(</span><span class="va">fit_rowclust_cols</span><span class="op">$</span><span class="va">ppr</span>, <span class="fl">2</span><span class="op">)</span></span></code></pre></div>
<pre><code><span><span class="co">##       [,1] [,2]</span></span>
<span><span class="co">##  [1,] 0.18 0.82</span></span>
<span><span class="co">##  [2,] 0.01 0.99</span></span>
<span><span class="co">##  [3,] 0.00 1.00</span></span>
<span><span class="co">##  [4,] 0.00 1.00</span></span>
<span><span class="co">##  [5,] 0.00 1.00</span></span>
<span><span class="co">##  [6,] 0.05 0.95</span></span>
<span><span class="co">##  [7,] 0.00 1.00</span></span>
<span><span class="co">##  [8,] 0.13 0.87</span></span>
<span><span class="co">##  [9,] 0.54 0.46</span></span>
<span><span class="co">## [10,] 0.00 1.00</span></span>
<span><span class="co">## [11,] 0.03 0.97</span></span>
<span><span class="co">## [12,] 1.00 0.00</span></span>
<span><span class="co">## [13,] 0.00 1.00</span></span>
<span><span class="co">## [14,] 0.00 1.00</span></span>
<span><span class="co">## [15,] 0.99 0.01</span></span>
<span><span class="co">## [16,] 0.98 0.02</span></span>
<span><span class="co">## [17,] 1.00 0.00</span></span>
<span><span class="co">## [18,] 0.01 0.99</span></span>
<span><span class="co">## [19,] 0.01 0.99</span></span>
<span><span class="co">## [20,] 0.97 0.03</span></span>
<span><span class="co">## [21,] 0.17 0.83</span></span>
<span><span class="co">## [22,] 0.44 0.56</span></span>
<span><span class="co">## [23,] 0.01 0.99</span></span>
<span><span class="co">## [24,] 0.91 0.09</span></span>
<span><span class="co">## [25,] 0.93 0.07</span></span>
<span><span class="co">## [26,] 0.99 0.01</span></span>
<span><span class="co">## [27,] 0.99 0.01</span></span>
<span><span class="co">## [28,] 0.96 0.04</span></span>
<span><span class="co">## [29,] 0.01 0.99</span></span>
<span><span class="co">## [30,] 0.95 0.05</span></span>
<span><span class="co">## [31,] 0.01 0.99</span></span>
<span><span class="co">## [32,] 1.00 0.00</span></span>
<span><span class="co">## [33,] 1.00 0.00</span></span>
<span><span class="co">## [34,] 0.00 1.00</span></span>
<span><span class="co">## [35,] 0.00 1.00</span></span>
<span><span class="co">## [36,] 1.00 0.00</span></span>
<span><span class="co">## [37,] 0.99 0.01</span></span>
<span><span class="co">## [38,] 1.00 0.00</span></span>
<span><span class="co">## [39,] 0.01 0.99</span></span>
<span><span class="co">## [40,] 0.00 1.00</span></span>
<span><span class="co">## [41,] 0.01 0.99</span></span>
<span><span class="co">## [42,] 0.10 0.90</span></span>
<span><span class="co">## [43,] 0.14 0.86</span></span>
<span><span class="co">## [44,] 0.96 0.04</span></span>
<span><span class="co">## [45,] 0.77 0.23</span></span>
<span><span class="co">## [46,] 0.00 1.00</span></span>
<span><span class="co">## [47,] 0.96 0.04</span></span>
<span><span class="co">## [48,] 0.96 0.04</span></span>
<span><span class="co">## [49,] 0.13 0.87</span></span>
<span><span class="co">## [50,] 0.00 1.00</span></span>
<span><span class="co">## [51,] 0.01 0.99</span></span>
<span><span class="co">## [52,] 0.00 1.00</span></span>
<span><span class="co">## [53,] 0.01 0.99</span></span>
<span><span class="co">## [54,] 0.56 0.44</span></span>
<span><span class="co">## [55,] 0.97 0.03</span></span>
<span><span class="co">## [56,] 0.15 0.85</span></span>
<span><span class="co">## [57,] 0.96 0.04</span></span>
<span><span class="co">## [58,] 0.00 1.00</span></span>
<span><span class="co">## [59,] 0.03 0.97</span></span>
<span><span class="co">## [60,] 0.54 0.46</span></span>
<span><span class="co">## [61,] 1.00 0.00</span></span>
<span><span class="co">## [62,] 0.00 1.00</span></span>
<span><span class="co">## [63,] 0.00 1.00</span></span>
<span><span class="co">## [64,] 0.00 1.00</span></span>
<span><span class="co">## [65,] 0.98 0.02</span></span>
<span><span class="co">## [66,] 0.00 1.00</span></span>
<span><span class="co">## [67,] 1.00 0.00</span></span>
<span><span class="co">## [68,] 0.07 0.93</span></span>
<span><span class="co">## [69,] 0.86 0.14</span></span>
<span><span class="co">## [70,] 0.99 0.01</span></span>
<span><span class="co">## [71,] 0.02 0.98</span></span>
<span><span class="co">## [72,] 0.00 1.00</span></span>
<span><span class="co">## [73,] 0.45 0.55</span></span>
<span><span class="co">## [74,] 0.96 0.04</span></span>
<span><span class="co">## [75,] 0.55 0.45</span></span>
<span><span class="co">## [76,] 0.19 0.81</span></span>
<span><span class="co">## [77,] 0.99 0.01</span></span>
<span><span class="co">## [78,] 0.05 0.95</span></span>
<span><span class="co">## [79,] 0.25 0.75</span></span>
<span><span class="co">## [80,] 0.30 0.70</span></span>
<span><span class="co">## [81,] 0.02 0.98</span></span>
<span><span class="co">## [82,] 0.00 1.00</span></span></code></pre>
<p>In this case, we can see that some of the individuals have been less
firmly assigned to one particular cluster than was the case for the
row-cluster-only model.</p>
<p>If we assign to clusters based on highest probability, let’s see the
lists of cluster members:</p>
<div class="sourceCode" id="cb31"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="va">fit_rowclust_cols</span><span class="op">$</span><span class="va">RowClusterMembers</span></span></code></pre></div>
<pre><code><span><span class="co">## [[1]]</span></span>
<span><span class="co">##  [1]  9 12 15 16 17 20 24 25 26 27 28 30 32 33 36 37 38 44 45 47 48 54 55 57 60</span></span>
<span><span class="co">## [26] 61 65 67 69 70 74 75 77</span></span>
<span><span class="co">## </span></span>
<span><span class="co">## [[2]]</span></span>
<span><span class="co">##  [1]  1  2  3  4  5  6  7  8 10 11 13 14 18 19 21 22 23 29 31 34 35 39 40 41 42</span></span>
<span><span class="co">## [26] 43 46 49 50 51 52 53 56 58 59 62 63 64 66 68 71 72 73 76 78 79 80 81 82</span></span></code></pre>
<p>We see that once we allow for some of the columns to be different
than others, we end up with a more evenly split pair of clusters.</p>
<p>Now let’s look at the parameter values for each cluster:</p>
<div class="sourceCode" id="cb33"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="va">fit_rowclust_cols</span><span class="op">$</span><span class="va">parlist.out</span><span class="op">$</span><span class="va">rowc</span></span></code></pre></div>
<pre><code><span><span class="co">##     rowc_1     rowc_2 </span></span>
<span><span class="co">## -0.8935557  0.8935557</span></span></code></pre>
<p>In this fit, the first cluster has a negative row cluster effect,
i.e. the individuals will tend to provide lower category responses, and
the second cluster has a positive row cluster effect, i.e. the
individuals will tend to provide higher category responses.</p>
<p>Note that the “order” of the clusters appears to be different for
this fit than the previous one: the row-cluster-only fit had the
positive cluster effect for the first cluster and the
row-clusters-with-columns fit had the negative cluster effect for the
first cluster. This is very common, and is a clustering phenomenon known
as “label-switching”. The mathematical model for the cluster is
equivalent whichever order the clusters are in, so the clustering
algorithm can’t tell the difference between different orderings of the
clusters. So for now, just know that we should not read anything into
the fact that the order has changed.</p>
<p>Again, let’s check the mean value of responses for individuals in the
first and second clusters:</p>
<div class="sourceCode" id="cb35"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="fu"><a href="https://rdrr.io/r/graphics/boxplot.html" class="external-link">boxplot</a></span><span class="op">(</span><span class="fu"><a href="https://rdrr.io/r/base/split.html" class="external-link">split</a></span><span class="op">(</span><span class="fu"><a href="https://rdrr.io/r/base/colSums.html" class="external-link">rowMeans</a></span><span class="op">(</span><span class="va">df</span><span class="op">)</span>, <span class="va">fit_rowclust_cols</span><span class="op">$</span><span class="va">RowClusters</span><span class="op">)</span>,</span>
<span>    <span class="st">"Mean response values across all questions for each individual"</span>,</span>
<span>    names <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/base/c.html" class="external-link">c</a></span><span class="op">(</span><span class="st">"Cluster 1"</span>, <span class="st">"Cluster 2"</span><span class="op">)</span><span class="op">)</span></span></code></pre></div>
<p><img src="clustordTutorial_files/figure-html/unnamed-chunk-32-1.png" width="700"></p>
<p>You can see that although the order of the clusters is different than
before, there is still a clear differentiation between the typical
responses in Cluster 1 vs. Cluster 2.</p>
<p>Now let’s also check the column effect parameters:</p>
<div class="sourceCode" id="cb36"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="fu"><a href="https://rdrr.io/r/base/Round.html" class="external-link">round</a></span><span class="op">(</span><span class="va">fit_rowclust_cols</span><span class="op">$</span><span class="va">parlist.out</span><span class="op">$</span><span class="va">col</span>,</span>
<span>    <span class="fl">2</span><span class="op">)</span></span></code></pre></div>
<pre><code><span><span class="co">##    Q1    Q2    Q3    Q4    Q5    Q6    Q7    Q8    Q9   Q10   Q11   Q12 </span></span>
<span><span class="co">##  6.80 -1.43 -2.79 -3.18 -0.62  0.84 -0.36  1.05  1.17  0.69 -1.72 -0.45</span></span></code></pre>
<p>You can see that the first column parameter, for Q1, is much higher
than the others, which matches what we observed in the data, i.e. the
much higher response values for that column than the others.</p>
<p>Q4 has the lowest value parameter, so that question tends to get
lower value responses than the others, but the effect is not as dramatic
as for Q1.</p>
<p>Most of the parameter values for the column effects are small to
medium, but even just the presence of one or two very different columns
is a good reason to fit this model with column effects.</p>
</div>
</div>
<div class="section level4">
<h4 id="row-clusters-with-individual-column-effects-and-interactions">Row clusters with individual column effects and interactions<a class="anchor" aria-label="anchor" href="#row-clusters-with-individual-column-effects-and-interactions"></a>
</h4>
<p>A third row clustering structure allows us to include not only column
effects, but also the interactions of those column effects with the
rows.</p>
<p>What this means is that in some datasets, the individuals may exhibit
a particular pattern of responses across the questions that varies
between clusters. For example, cluster 1 individuals might tend to
answer the initial questions with high-value responses and the later
questions with low-value responses, whereas cluster 2 individuals might
tend to answer the initial questions with low-value responses and the
later questions with high-value responses. That would be an interaction
pattern.</p>
<p>For this model, the linear predictor adds an additional component,
<code>rowc_col</code>, which is a matrix of parameters that show the
interaction effects between each cluster and each column.</p>
<p><strong>IMPORTANT WARNING:</strong> Depending on the number of
columns you have in your dataset, but especially if you have more than
10, then adding the interaction term adds quite a lot of additional
parameters to the model. The total number of non-dependent parameters
will be:
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>R</mi><mo>−</mo><mn>1</mn></mrow><annotation encoding="application/x-tex">R-1</annotation></semantics></math>
(for the mixing proportion parameters that indicate the proportion of
rows in each cluster) +
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>R</mi><mo>−</mo><mn>1</mn></mrow><annotation encoding="application/x-tex">R-1</annotation></semantics></math>
(for the row cluster effects) +
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mi>m</mi><annotation encoding="application/x-tex">m</annotation></semantics></math>
(for the number of columns,
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mi>m</mi><annotation encoding="application/x-tex">m</annotation></semantics></math>)
+
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mrow><mo stretchy="true" form="prefix">(</mo><mi>R</mi><mo>−</mo><mn>1</mn><mo stretchy="true" form="postfix">)</mo></mrow><mo>×</mo><mrow><mo stretchy="true" form="prefix">(</mo><mi>m</mi><mo>−</mo><mn>1</mn><mo stretchy="true" form="postfix">)</mo></mrow></mrow><annotation encoding="application/x-tex">(R-1)\times(m-1)</annotation></semantics></math>
(for the row-cluster and column interactions) +
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>q</mi><mo>−</mo><mn>1</mn></mrow><annotation encoding="application/x-tex">q-1</annotation></semantics></math>
(for the category parameters
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mo stretchy="false" form="prefix">{</mo><msub><mi>μ</mi><mi>k</mi></msub><mo stretchy="false" form="postfix">}</mo></mrow><annotation encoding="application/x-tex">\{\mu_k\}</annotation></semantics></math>,
described in the ordinal models section).
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mi>q</mi><annotation encoding="application/x-tex">q</annotation></semantics></math>
is the number of categories/levels in each response variable. The total
number of parameters is approximately equal to
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>m</mi><mi>R</mi></mrow><annotation encoding="application/x-tex">mR</annotation></semantics></math>.</p>
<p>Therefore it may not be a good idea to fit this model if
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>n</mi><mo>&lt;</mo><mn>20</mn><mi>m</mi></mrow><annotation encoding="application/x-tex">n &lt; 20m</annotation></semantics></math>.
This is not a rigorously tested limit, but a very rough rule of thumb;
at the very least, if fitting this model you should carry out model
selection but also carefully decide on the number of iterations and
check for convergence.</p>
<p>In this case, our dataset is <strong>too small</strong>, but we will
fit the model to illustrate the process.</p>
<p>The interaction model will also take longer to fit than the previous
two models, because the larger number of parameters can lead to longer
convergence times.</p>
<p>By default, the algorithm fits the row-cluster-only model and the
model without interactions (called the “intermediate rowcluster-column
model” in the output) first in order to find good starting values for
the parameters in the interaction model. This often saves time by
reducing the number of iterations of the full model.</p>
<div class="section level5">
<h5 id="fitting-the-model-2">Fitting the model<a class="anchor" aria-label="anchor" href="#fitting-the-model-2"></a>
</h5>
<p>The formula for interactions works the same as in regression models
in R, with its two options for adding interactions. These two formulae
are equivalent:</p>
<div class="sourceCode" id="cb38"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="va">Y</span> <span class="op">~</span> <span class="va">ROWCLUST</span> <span class="op">+</span> <span class="va">COL</span> <span class="op">+</span> <span class="va">ROWCLUST</span><span class="op">:</span><span class="va">COL</span></span></code></pre></div>
<pre><code><span><span class="co">## Y ~ ROWCLUST + COL + ROWCLUST:COL</span></span></code></pre>
<div class="sourceCode" id="cb40"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="va">Y</span> <span class="op">~</span> <span class="va">ROWCLUST</span> <span class="op">*</span> <span class="va">COL</span></span></code></pre></div>
<pre><code><span><span class="co">## Y ~ ROWCLUST * COL</span></span></code></pre>
<div class="sourceCode" id="cb42"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="fu"><a href="https://rdrr.io/r/base/Random.html" class="external-link">set.seed</a></span><span class="op">(</span><span class="fl">1</span><span class="op">)</span></span>
<span><span class="va">fit_rowclust_cols_interact</span> <span class="op">&lt;-</span> <span class="fu"><a href="../reference/clustord.html">clustord</a></span><span class="op">(</span><span class="va">Y</span> <span class="op">~</span></span>
<span>    <span class="va">ROWCLUST</span> <span class="op">*</span> <span class="va">COL</span>, <span class="st">"POM"</span>, nclus.row <span class="op">=</span> <span class="fl">2</span>,</span>
<span>    long.df <span class="op">=</span> <span class="va">long.df</span>, verbose <span class="op">=</span> <span class="cn">FALSE</span><span class="op">)</span></span></code></pre></div>
</div>
<div class="section level5">
<h5 id="checking-the-output-2">Checking the output<a class="anchor" aria-label="anchor" href="#checking-the-output-2"></a>
</h5>
<p>Again, once the fit is completed we should first check that it has
converged:</p>
<div class="sourceCode" id="cb43"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="va">fit_rowclust_cols_interact</span><span class="op">$</span><span class="va">EM.status</span><span class="op">$</span><span class="va">converged</span></span></code></pre></div>
<pre><code><span><span class="co">## [1] TRUE</span></span></code></pre>
<p>Then we can look at the probabilities of cluster membership:</p>
<div class="sourceCode" id="cb45"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="fu"><a href="https://rdrr.io/r/base/Round.html" class="external-link">round</a></span><span class="op">(</span><span class="va">fit_rowclust_cols_interact</span><span class="op">$</span><span class="va">ppr</span>, <span class="fl">2</span><span class="op">)</span></span></code></pre></div>
<pre><code><span><span class="co">##       [,1] [,2]</span></span>
<span><span class="co">##  [1,] 0.89 0.11</span></span>
<span><span class="co">##  [2,] 1.00 0.00</span></span>
<span><span class="co">##  [3,] 1.00 0.00</span></span>
<span><span class="co">##  [4,] 1.00 0.00</span></span>
<span><span class="co">##  [5,] 1.00 0.00</span></span>
<span><span class="co">##  [6,] 1.00 0.00</span></span>
<span><span class="co">##  [7,] 1.00 0.00</span></span>
<span><span class="co">##  [8,] 0.96 0.04</span></span>
<span><span class="co">##  [9,] 0.24 0.76</span></span>
<span><span class="co">## [10,] 1.00 0.00</span></span>
<span><span class="co">## [11,] 1.00 0.00</span></span>
<span><span class="co">## [12,] 0.00 1.00</span></span>
<span><span class="co">## [13,] 1.00 0.00</span></span>
<span><span class="co">## [14,] 1.00 0.00</span></span>
<span><span class="co">## [15,] 0.00 1.00</span></span>
<span><span class="co">## [16,] 0.00 1.00</span></span>
<span><span class="co">## [17,] 0.00 1.00</span></span>
<span><span class="co">## [18,] 1.00 0.00</span></span>
<span><span class="co">## [19,] 1.00 0.00</span></span>
<span><span class="co">## [20,] 0.00 1.00</span></span>
<span><span class="co">## [21,] 0.40 0.60</span></span>
<span><span class="co">## [22,] 0.06 0.94</span></span>
<span><span class="co">## [23,] 1.00 0.00</span></span>
<span><span class="co">## [24,] 0.07 0.93</span></span>
<span><span class="co">## [25,] 0.00 1.00</span></span>
<span><span class="co">## [26,] 0.00 1.00</span></span>
<span><span class="co">## [27,] 0.01 0.99</span></span>
<span><span class="co">## [28,] 0.00 1.00</span></span>
<span><span class="co">## [29,] 1.00 0.00</span></span>
<span><span class="co">## [30,] 0.12 0.88</span></span>
<span><span class="co">## [31,] 1.00 0.00</span></span>
<span><span class="co">## [32,] 0.00 1.00</span></span>
<span><span class="co">## [33,] 0.00 1.00</span></span>
<span><span class="co">## [34,] 1.00 0.00</span></span>
<span><span class="co">## [35,] 1.00 0.00</span></span>
<span><span class="co">## [36,] 0.00 1.00</span></span>
<span><span class="co">## [37,] 0.00 1.00</span></span>
<span><span class="co">## [38,] 0.00 1.00</span></span>
<span><span class="co">## [39,] 0.99 0.01</span></span>
<span><span class="co">## [40,] 1.00 0.00</span></span>
<span><span class="co">## [41,] 1.00 0.00</span></span>
<span><span class="co">## [42,] 0.99 0.01</span></span>
<span><span class="co">## [43,] 1.00 0.00</span></span>
<span><span class="co">## [44,] 0.00 1.00</span></span>
<span><span class="co">## [45,] 0.23 0.77</span></span>
<span><span class="co">## [46,] 1.00 0.00</span></span>
<span><span class="co">## [47,] 0.29 0.71</span></span>
<span><span class="co">## [48,] 0.02 0.98</span></span>
<span><span class="co">## [49,] 0.99 0.01</span></span>
<span><span class="co">## [50,] 1.00 0.00</span></span>
<span><span class="co">## [51,] 1.00 0.00</span></span>
<span><span class="co">## [52,] 1.00 0.00</span></span>
<span><span class="co">## [53,] 1.00 0.00</span></span>
<span><span class="co">## [54,] 0.39 0.61</span></span>
<span><span class="co">## [55,] 0.05 0.95</span></span>
<span><span class="co">## [56,] 0.49 0.51</span></span>
<span><span class="co">## [57,] 0.08 0.92</span></span>
<span><span class="co">## [58,] 1.00 0.00</span></span>
<span><span class="co">## [59,] 1.00 0.00</span></span>
<span><span class="co">## [60,] 0.22 0.78</span></span>
<span><span class="co">## [61,] 0.00 1.00</span></span>
<span><span class="co">## [62,] 1.00 0.00</span></span>
<span><span class="co">## [63,] 1.00 0.00</span></span>
<span><span class="co">## [64,] 1.00 0.00</span></span>
<span><span class="co">## [65,] 0.00 1.00</span></span>
<span><span class="co">## [66,] 1.00 0.00</span></span>
<span><span class="co">## [67,] 0.00 1.00</span></span>
<span><span class="co">## [68,] 0.99 0.01</span></span>
<span><span class="co">## [69,] 0.03 0.97</span></span>
<span><span class="co">## [70,] 0.01 0.99</span></span>
<span><span class="co">## [71,] 1.00 0.00</span></span>
<span><span class="co">## [72,] 1.00 0.00</span></span>
<span><span class="co">## [73,] 0.08 0.92</span></span>
<span><span class="co">## [74,] 0.00 1.00</span></span>
<span><span class="co">## [75,] 0.99 0.01</span></span>
<span><span class="co">## [76,] 0.98 0.02</span></span>
<span><span class="co">## [77,] 0.00 1.00</span></span>
<span><span class="co">## [78,] 0.99 0.01</span></span>
<span><span class="co">## [79,] 0.94 0.06</span></span>
<span><span class="co">## [80,] 0.65 0.35</span></span>
<span><span class="co">## [81,] 0.94 0.06</span></span>
<span><span class="co">## [82,] 1.00 0.00</span></span></code></pre>
<p>Let’s see the lists of cluster members:</p>
<div class="sourceCode" id="cb47"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="va">fit_rowclust_cols_interact</span><span class="op">$</span><span class="va">RowClusterMembers</span></span></code></pre></div>
<pre><code><span><span class="co">## [[1]]</span></span>
<span><span class="co">##  [1]  1  2  3  4  5  6  7  8 10 11 13 14 18 19 23 29 31 34 35 39 40 41 42 43 46</span></span>
<span><span class="co">## [26] 49 50 51 52 53 58 59 62 63 64 66 68 71 72 75 76 78 79 80 81 82</span></span>
<span><span class="co">## </span></span>
<span><span class="co">## [[2]]</span></span>
<span><span class="co">##  [1]  9 12 15 16 17 20 21 22 24 25 26 27 28 30 32 33 36 37 38 44 45 47 48 54 55</span></span>
<span><span class="co">## [26] 56 57 60 61 65 67 69 70 73 74 77</span></span></code></pre>
<p>Now let’s look at the parameter values for each cluster:</p>
<div class="sourceCode" id="cb49"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="va">fit_rowclust_cols_interact</span><span class="op">$</span><span class="va">parlist.out</span><span class="op">$</span><span class="va">rowc</span></span></code></pre></div>
<pre><code><span><span class="co">##     rowc_1     rowc_2 </span></span>
<span><span class="co">##  0.9715144 -0.9715144</span></span></code></pre>
<p>And again, we can show that the first cluster has higher response
values than the second cluster, although now there appears to be more
overlap:</p>
<div class="sourceCode" id="cb51"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="fu"><a href="https://rdrr.io/r/graphics/boxplot.html" class="external-link">boxplot</a></span><span class="op">(</span><span class="fu"><a href="https://rdrr.io/r/base/split.html" class="external-link">split</a></span><span class="op">(</span><span class="fu"><a href="https://rdrr.io/r/base/colSums.html" class="external-link">rowMeans</a></span><span class="op">(</span><span class="va">df</span><span class="op">)</span>, <span class="va">fit_rowclust_cols_interact</span><span class="op">$</span><span class="va">RowClusters</span><span class="op">)</span>,</span>
<span>    <span class="st">"Mean response values across all questions for each individual"</span>,</span>
<span>    names <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/base/c.html" class="external-link">c</a></span><span class="op">(</span><span class="st">"Cluster 1"</span>, <span class="st">"Cluster 2"</span><span class="op">)</span><span class="op">)</span></span></code></pre></div>
<p><img src="clustordTutorial_files/figure-html/unnamed-chunk-39-1.png" width="700"></p>
<p>Now let’s check the column effect parameters:</p>
<div class="sourceCode" id="cb52"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="fu"><a href="https://rdrr.io/r/base/Round.html" class="external-link">round</a></span><span class="op">(</span><span class="va">fit_rowclust_cols_interact</span><span class="op">$</span><span class="va">parlist.out</span><span class="op">$</span><span class="va">col</span>,</span>
<span>    <span class="fl">2</span><span class="op">)</span></span></code></pre></div>
<pre><code><span><span class="co">##    Q1    Q2    Q3    Q4    Q5    Q6    Q7    Q8    Q9   Q10   Q11   Q12 </span></span>
<span><span class="co">##  7.14 -1.48 -2.91 -3.30 -0.72  1.10 -0.40  1.10  1.27  0.63 -1.84 -0.59</span></span></code></pre>
<p>When we include the interaction terms, the column effects have become
a bit larger than before for some columns.</p>
<p>We can then finally check the interaction effects:</p>
<div class="sourceCode" id="cb54"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="fu"><a href="https://rdrr.io/r/base/Round.html" class="external-link">round</a></span><span class="op">(</span><span class="va">fit_rowclust_cols_interact</span><span class="op">$</span><span class="va">parlist.out</span><span class="op">$</span><span class="va">rowc_col</span>,</span>
<span>    <span class="fl">2</span><span class="op">)</span></span></code></pre></div>
<pre><code><span><span class="co">##         Q1    Q2    Q3    Q4    Q5    Q6    Q7    Q8    Q9   Q10   Q11   Q12</span></span>
<span><span class="co">## [1,] -1.18 -0.19 -0.12 -0.18  0.46 -0.94  0.29  0.33  0.14  0.64  0.11  0.63</span></span>
<span><span class="co">## [2,]  1.18  0.19  0.12  0.18 -0.46  0.94 -0.29 -0.33 -0.14 -0.64 -0.11 -0.63</span></span></code></pre>
<p>We can plot these interaction terms against each other to see the
interaction effects:</p>
<div class="sourceCode" id="cb56"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="va">rowc_col</span> <span class="op">&lt;-</span> <span class="va">fit_rowclust_cols_interact</span><span class="op">$</span><span class="va">parlist.out</span><span class="op">$</span><span class="va">rowc_col</span></span>
<span><span class="fu"><a href="https://rdrr.io/r/graphics/plot.default.html" class="external-link">plot</a></span><span class="op">(</span><span class="va">rowc_col</span><span class="op">[</span><span class="fl">1</span>, <span class="op">]</span>, type <span class="op">=</span> <span class="st">"b"</span>, col <span class="op">=</span> <span class="st">"black"</span>,</span>
<span>    lwd <span class="op">=</span> <span class="fl">2</span>, ylim <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/base/c.html" class="external-link">c</a></span><span class="op">(</span><span class="op">-</span><span class="fl">1.3</span>, <span class="fl">1.3</span><span class="op">)</span><span class="op">)</span></span>
<span><span class="fu"><a href="https://rdrr.io/r/graphics/lines.html" class="external-link">lines</a></span><span class="op">(</span><span class="va">rowc_col</span><span class="op">[</span><span class="fl">2</span>, <span class="op">]</span>, lty <span class="op">=</span> <span class="fl">2</span>, col <span class="op">=</span> <span class="st">"blue"</span>,</span>
<span>    lwd <span class="op">=</span> <span class="fl">2</span><span class="op">)</span></span>
<span><span class="fu"><a href="https://rdrr.io/r/graphics/points.html" class="external-link">points</a></span><span class="op">(</span><span class="va">rowc_col</span><span class="op">[</span><span class="fl">2</span>, <span class="op">]</span>, lty <span class="op">=</span> <span class="fl">2</span>, col <span class="op">=</span> <span class="st">"blue"</span>,</span>
<span>    lwd <span class="op">=</span> <span class="fl">2</span><span class="op">)</span></span>
<span><span class="fu"><a href="https://rdrr.io/r/graphics/legend.html" class="external-link">legend</a></span><span class="op">(</span><span class="st">"bottomright"</span>, legend <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/base/c.html" class="external-link">c</a></span><span class="op">(</span><span class="st">"Cluster 1"</span>,</span>
<span>    <span class="st">"Cluster 2"</span><span class="op">)</span>, col <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/base/c.html" class="external-link">c</a></span><span class="op">(</span><span class="st">"black"</span>, <span class="st">"blue"</span><span class="op">)</span>,</span>
<span>    lwd <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/base/c.html" class="external-link">c</a></span><span class="op">(</span><span class="fl">2</span>, <span class="fl">2</span><span class="op">)</span>, lty <span class="op">=</span> <span class="fl">1</span><span class="op">:</span><span class="fl">2</span><span class="op">)</span></span></code></pre></div>
<p><img src="clustordTutorial_files/figure-html/unnamed-chunk-42-1.png" width="700"></p>
<p>This suggests that individuals in cluster 1 tend to give low-value
responses to questions 1 and 6, and high-value responses for the rest,
and the reverse for individuals in cluster 2 (the large cluster).</p>
</div>
</div>
<div class="section level4">
<h4 id="model-selection">Model selection<a class="anchor" aria-label="anchor" href="#model-selection"></a>
</h4>
<p>If you have fitted multiple models, then you will need to select the
best one. The advantage of model-based clustering methods is that you
can use information criteria and/or the likelihoods of the models to
select the best one.</p>
<p>Sticking with only two clusters, let’s see which is the best out of
the three models above. <code><a href="../reference/clustord.html">clustord()</a></code> provides the set of
information criteria listed below, of which the most widely used are AIC
(Akaike, 1973) and BIC (Schwarz, 1978), so let’s use those for now.</p>
<div class="sourceCode" id="cb57"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="va">fit_rowclust_only</span><span class="op">$</span><span class="va">criteria</span><span class="op">$</span><span class="va">AIC</span></span></code></pre></div>
<pre><code><span><span class="co">## [1] 3854.975</span></span></code></pre>
<div class="sourceCode" id="cb59"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="va">fit_rowclust_cols</span><span class="op">$</span><span class="va">criteria</span><span class="op">$</span><span class="va">AIC</span></span></code></pre></div>
<pre><code><span><span class="co">## [1] 2258.931</span></span></code></pre>
<div class="sourceCode" id="cb61"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="va">fit_rowclust_cols_interact</span><span class="op">$</span><span class="va">criteria</span><span class="op">$</span><span class="va">AIC</span></span></code></pre></div>
<pre><code><span><span class="co">## [1] 2216.477</span></span></code></pre>
<div class="sourceCode" id="cb63"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="va">fit_rowclust_only</span><span class="op">$</span><span class="va">criteria</span><span class="op">$</span><span class="va">BIC</span></span></code></pre></div>
<pre><code><span><span class="co">## [1] 3894.108</span></span></code></pre>
<div class="sourceCode" id="cb65"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="va">fit_rowclust_cols</span><span class="op">$</span><span class="va">criteria</span><span class="op">$</span><span class="va">BIC</span></span></code></pre></div>
<pre><code><span><span class="co">## [1] 2351.872</span></span></code></pre>
<div class="sourceCode" id="cb67"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="va">fit_rowclust_cols_interact</span><span class="op">$</span><span class="va">criteria</span><span class="op">$</span><span class="va">BIC</span></span></code></pre></div>
<pre><code><span><span class="co">## [1] 2363.225</span></span></code></pre>
<p>For both AIC and BIC, lower values indicate better goodness-of-fit.
So we can see that according to AIC the third model, with column effects
and interactions, is best, whereas according to BIC the second model,
with column effects but no interactions, is the best. This makes sense,
because BIC was designed to penalize complexity more than AIC does, and
the third model is the most complex one.</p>
<p>In this case, since the values for the second and third models are
roughly comparable, and simplicity makes models easier to interpret, we
would choose to stick with the second model rather than the third.</p>
</div>
<div class="section level4">
<h4 id="incomplete-data-and-complete-data-log-likelihoods">Incomplete-data and complete-data log-likelihoods<a class="anchor" aria-label="anchor" href="#incomplete-data-and-complete-data-log-likelihoods"></a>
</h4>
<p>Note that all of the information criteria provided by
<code><a href="../reference/clustord.html">clustord()</a></code> are based on either the incomplete-data or the
complete-data log-likelihood.</p>
<p>The meaning of “likelihood” in a statistical context is the
probability of obtaining the observed data, given a particular set of
parameter values. <code><a href="../reference/clustord.html">clustord()</a></code>, like all likelihood-based
model-clustering methods, attempts to find the set of parameter values
with the highest likelihood, although it can only maximise the
parameters for one single model at a time. In fact, it attempts to
maximise the log-likelihood instead, which is more numerically accurate
unless you have a really tiny dataset (&lt; 20 rows and columns)</p>
<p>Any attempt to fit a mixture model requires the maximisation of the
parameters of the individual clusters (here these include the
<code>rowc</code>, <code>col</code> and <code>rowc_col</code> parameters
described above) and the “mixing proportions” for the clusters (the
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mo stretchy="false" form="prefix">{</mo><msub><mi>π</mi><mi>r</mi></msub><mo stretchy="false" form="postfix">}</mo></mrow><annotation encoding="application/x-tex">\{\pi_r\}</annotation></semantics></math>
parameters described above). <code><a href="../reference/clustord.html">clustord()</a></code> uses the EM
algorithm to perform model fitting, and this also treats the cluster
membership probabilities as unknown quantities that need to be
estimated.</p>
<p><code><a href="../reference/clustord.html">clustord()</a></code> therefore calculates two types of likelihood.
One is the <strong>complete-data log-likelihood</strong>, which is the
log-likelihood of the parameters and mixing proportions, <strong>given a
specific set of cluster membership probabilities</strong> (which are
usually the estimated probabilities from the latest EM algorithm
iteration).</p>
<p>The second is the <strong>incomplete-data log-likelihood</strong>,
which is the log-likelihood of the parameters and mixing proportions
<strong>after integrating out all possible cluster memberships</strong>.
This is what, in any other context, would be called simply “the
log-likelihood” of the model. This is the core log-likelihood we need to
find, and the complete-data log-likelihood is simply a stepping-stone on
the way to finding it.</p>
<p>The presence of these two types of likelihood or log-likelihood in
the algorithm is why <code><a href="../reference/clustord.html">clustord()</a></code> always labels every
log-likelihood it calculates as either “complete-data” or
“incomplete-data”.</p>
<div style="page-break-after: always;"></div>
</div>
</div>
<div class="section level3">
<h3 id="column-clustering">Column clustering<a class="anchor" aria-label="anchor" href="#column-clustering"></a>
</h3>
<p>So far we have demonstrated how to cluster the rows of the data
matrix. But we can also cluster the columns of the data matrix. For our
example dataset, this would correspond to clustering the questions in
the survey, to find out which groups had similar patterns of
responses.</p>
<p>We could easily do this by transposing the data matrix and then
running the above row clustering models on it, since the column
clustering and row clustering models are mathematically equivalent. This
transposition is is what <code><a href="../reference/clustord.html">clustord()</a></code> does. If you apply the
column clustering models, then <code><a href="../reference/clustord.html">clustord()</a></code> transposes the
data, runs the row clustering algorithm, and then flips the data matrix
and all the output results back to their original orientation.</p>
<p>Let’s try this with our existing dataset. The models have the same
structure as before.</p>
<div class="section level4">
<h4 id="column-cluster-effect-only">Column cluster effect only<a class="anchor" aria-label="anchor" href="#column-cluster-effect-only"></a>
</h4>
<p>The simplest column clustering model is the column-cluster-only
model, where the main part of the linear predictor is <code>colc</code>,
the column cluster effect.</p>
<p>We use the case-sensitive keyword <code>COLCLUST</code> in the
formula, and we need to set <code>nclus.column</code> instead of
<code>nclus.row</code>:</p>
<div class="sourceCode" id="cb69"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="fu"><a href="https://rdrr.io/r/base/Random.html" class="external-link">set.seed</a></span><span class="op">(</span><span class="fl">1</span><span class="op">)</span></span>
<span><span class="va">fit_colclust_only</span> <span class="op">&lt;-</span> <span class="fu"><a href="../reference/clustord.html">clustord</a></span><span class="op">(</span><span class="va">Y</span> <span class="op">~</span> <span class="va">COLCLUST</span>,</span>
<span>    model <span class="op">=</span> <span class="st">"POM"</span>, nclus.column <span class="op">=</span> <span class="fl">2</span>, long.df <span class="op">=</span> <span class="va">long.df</span>,</span>
<span>    verbose <span class="op">=</span> <span class="cn">FALSE</span><span class="op">)</span></span></code></pre></div>
<p>In column clustering, the mixing proportions are renamed
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mo stretchy="false" form="prefix">{</mo><msub><mi>κ</mi><mi>c</mi></msub><mo stretchy="false" form="postfix">}</mo></mrow><annotation encoding="application/x-tex">\{\kappa_c\}</annotation></semantics></math>
(to avoid confusion when performing biclustering with both sets of
mixing proportions, as seen below). The cluster membership probabilities
are stored in the output as <code>ppc</code> not <code>ppr</code> and
the cluster memberships are named <code>ColumnClusters</code> not
<code>RowClusters</code> and the lists of cluster members are named
<code>ColumnClusterMembers</code> not
<code>RowClusterMembers</code>.</p>
<div class="sourceCode" id="cb70"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="co"># Convergence</span></span>
<span><span class="va">fit_colclust_only</span><span class="op">$</span><span class="va">EM.status</span><span class="op">$</span><span class="va">converged</span></span></code></pre></div>
<pre><code><span><span class="co">## [1] TRUE</span></span></code></pre>
<div class="sourceCode" id="cb72"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="co"># Column cluster membership</span></span>
<span><span class="co"># probabilities</span></span>
<span><span class="fu"><a href="https://rdrr.io/r/base/Round.html" class="external-link">round</a></span><span class="op">(</span><span class="va">fit_colclust_only</span><span class="op">$</span><span class="va">ppc</span>, <span class="fl">2</span><span class="op">)</span></span></code></pre></div>
<pre><code><span><span class="co">##       [,1] [,2]</span></span>
<span><span class="co">##  [1,]    1    0</span></span>
<span><span class="co">##  [2,]    0    1</span></span>
<span><span class="co">##  [3,]    0    1</span></span>
<span><span class="co">##  [4,]    0    1</span></span>
<span><span class="co">##  [5,]    0    1</span></span>
<span><span class="co">##  [6,]    1    0</span></span>
<span><span class="co">##  [7,]    0    1</span></span>
<span><span class="co">##  [8,]    1    0</span></span>
<span><span class="co">##  [9,]    1    0</span></span>
<span><span class="co">## [10,]    1    0</span></span>
<span><span class="co">## [11,]    0    1</span></span>
<span><span class="co">## [12,]    0    1</span></span></code></pre>
<div class="sourceCode" id="cb74"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="co"># Members of each column cluster</span></span>
<span><span class="va">fit_colclust_only</span><span class="op">$</span><span class="va">ColumnClusterMembers</span></span></code></pre></div>
<pre><code><span><span class="co">## [[1]]</span></span>
<span><span class="co">## [1]  1  6  8  9 10</span></span>
<span><span class="co">## </span></span>
<span><span class="co">## [[2]]</span></span>
<span><span class="co">## [1]  2  3  4  5  7 11 12</span></span></code></pre>
<div class="sourceCode" id="cb76"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="co"># Mixing proportions</span></span>
<span><span class="fu"><a href="https://rdrr.io/r/base/Round.html" class="external-link">round</a></span><span class="op">(</span><span class="va">fit_colclust_only</span><span class="op">$</span><span class="va">kappa.out</span>, <span class="fl">2</span><span class="op">)</span></span></code></pre></div>
<pre><code><span><span class="co">## [1] 0.42 0.58</span></span></code></pre>
<div class="sourceCode" id="cb78"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="co"># Parameters</span></span>
<span><span class="va">fit_colclust_only</span><span class="op">$</span><span class="va">parlist.out</span><span class="op">$</span><span class="va">colc</span></span></code></pre></div>
<pre><code><span><span class="co">##    colc_1    colc_2 </span></span>
<span><span class="co">##  1.201864 -1.201864</span></span></code></pre>
<p>The algorithm has converged, all of the columns are firmly allocated
to one or other of the clusters, and they are roughly equally split
between the two clusters.</p>
<p>The parameter values indicate that cluster 1 questions tend to have
higher response values than cluster 2 questions (and note that the
question with the highest typical responses, Q1, is in the first
cluster, as we’d expect).</p>
</div>
<div class="section level4">
<h4 id="column-clusters-with-individual-row-effects">Column clusters with individual row effects<a class="anchor" aria-label="anchor" href="#column-clusters-with-individual-row-effects"></a>
</h4>
<p>Similarly to row clustering, with column clustering we can fit a
model that incorporates individual row effects, to account for the fact
that some individual subjects may have different response patterns than
others.</p>
<p>This uses the case-sensitive keyword <code>ROW</code>.</p>
<div class="sourceCode" id="cb80"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="fu"><a href="https://rdrr.io/r/base/Random.html" class="external-link">set.seed</a></span><span class="op">(</span><span class="fl">1</span><span class="op">)</span></span>
<span><span class="va">fit_colclust_rows</span> <span class="op">&lt;-</span> <span class="fu"><a href="../reference/clustord.html">clustord</a></span><span class="op">(</span><span class="va">Y</span> <span class="op">~</span> <span class="va">COLCLUST</span> <span class="op">+</span></span>
<span>    <span class="va">ROW</span>, model <span class="op">=</span> <span class="st">"POM"</span>, nclus.column <span class="op">=</span> <span class="fl">2</span>,</span>
<span>    long.df <span class="op">=</span> <span class="va">long.df</span>, verbose <span class="op">=</span> <span class="cn">FALSE</span><span class="op">)</span></span></code></pre></div>
<div class="sourceCode" id="cb81"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="co"># Convergence</span></span>
<span><span class="va">fit_colclust_rows</span><span class="op">$</span><span class="va">EM.status</span><span class="op">$</span><span class="va">converged</span></span></code></pre></div>
<pre><code><span><span class="co">## [1] TRUE</span></span></code></pre>
<div class="sourceCode" id="cb83"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="co"># Column cluster membership</span></span>
<span><span class="co"># probabilities</span></span>
<span><span class="fu"><a href="https://rdrr.io/r/base/Round.html" class="external-link">round</a></span><span class="op">(</span><span class="va">fit_colclust_rows</span><span class="op">$</span><span class="va">ppc</span>, <span class="fl">2</span><span class="op">)</span></span></code></pre></div>
<pre><code><span><span class="co">##       [,1] [,2]</span></span>
<span><span class="co">##  [1,]    1    0</span></span>
<span><span class="co">##  [2,]    0    1</span></span>
<span><span class="co">##  [3,]    0    1</span></span>
<span><span class="co">##  [4,]    0    1</span></span>
<span><span class="co">##  [5,]    0    1</span></span>
<span><span class="co">##  [6,]    0    1</span></span>
<span><span class="co">##  [7,]    0    1</span></span>
<span><span class="co">##  [8,]    0    1</span></span>
<span><span class="co">##  [9,]    0    1</span></span>
<span><span class="co">## [10,]    0    1</span></span>
<span><span class="co">## [11,]    0    1</span></span>
<span><span class="co">## [12,]    0    1</span></span></code></pre>
<div class="sourceCode" id="cb85"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="co"># Members of each column cluster</span></span>
<span><span class="va">fit_colclust_rows</span><span class="op">$</span><span class="va">ColumnClusterMembers</span></span></code></pre></div>
<pre><code><span><span class="co">## [[1]]</span></span>
<span><span class="co">## [1] 1</span></span>
<span><span class="co">## </span></span>
<span><span class="co">## [[2]]</span></span>
<span><span class="co">##  [1]  2  3  4  5  6  7  8  9 10 11 12</span></span></code></pre>
<div class="sourceCode" id="cb87"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="co"># Mixing proportions</span></span>
<span><span class="fu"><a href="https://rdrr.io/r/base/Round.html" class="external-link">round</a></span><span class="op">(</span><span class="va">fit_colclust_rows</span><span class="op">$</span><span class="va">kappa.out</span>, <span class="fl">2</span><span class="op">)</span></span></code></pre></div>
<pre><code><span><span class="co">## [1] 0.08 0.92</span></span></code></pre>
<div class="sourceCode" id="cb89"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="co"># Parameters</span></span>
<span><span class="va">fit_colclust_rows</span><span class="op">$</span><span class="va">parlist.out</span><span class="op">$</span><span class="va">colc</span></span></code></pre></div>
<pre><code><span><span class="co">##    colc_1    colc_2 </span></span>
<span><span class="co">##  3.493738 -3.493738</span></span></code></pre>
<div class="sourceCode" id="cb91"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="fu"><a href="https://rdrr.io/r/base/Round.html" class="external-link">round</a></span><span class="op">(</span><span class="va">fit_colclust_rows</span><span class="op">$</span><span class="va">parlist.out</span><span class="op">$</span><span class="va">row</span>,</span>
<span>    <span class="fl">2</span><span class="op">)</span></span></code></pre></div>
<pre><code><span><span class="co">##   ID1   ID2   ID3   ID4   ID5   ID6   ID7   ID8   ID9  ID10  ID11  ID12  ID13 </span></span>
<span><span class="co">## -0.01  0.62  0.65  1.07  1.08  0.40  1.87  0.08 -0.20  0.92  0.28 -1.33  1.74 </span></span>
<span><span class="co">##  ID14  ID15  ID16  ID17  ID18  ID19  ID20  ID21  ID22  ID23  ID24  ID25  ID26 </span></span>
<span><span class="co">##  1.02 -0.74 -0.71 -2.73  0.30  0.50 -0.47  0.01 -0.18  0.49 -0.52 -0.45 -0.71 </span></span>
<span><span class="co">##  ID27  ID28  ID29  ID30  ID31  ID32  ID33  ID34  ID35  ID36  ID37  ID38  ID39 </span></span>
<span><span class="co">## -0.72 -0.48  0.26 -0.60  0.55 -0.92 -3.00  0.57  0.97 -1.05 -0.88 -1.86  0.50 </span></span>
<span><span class="co">##  ID40  ID41  ID42  ID43  ID44  ID45  ID46  ID47  ID48  ID49  ID50  ID51  ID52 </span></span>
<span><span class="co">##  0.80  0.51  0.08  0.13 -0.69 -0.39  0.57 -0.74 -0.53  0.23  1.25  0.71  1.11 </span></span>
<span><span class="co">##  ID53  ID54  ID55  ID56  ID57  ID58  ID59  ID60  ID61  ID62  ID63  ID64  ID65 </span></span>
<span><span class="co">##  0.65  0.00 -0.64  0.01 -0.53  0.65  0.42 -0.10 -3.71  2.96  2.27  0.75 -0.71 </span></span>
<span><span class="co">##  ID66  ID67  ID68  ID69  ID70  ID71  ID72  ID73  ID74  ID75  ID76  ID77  ID78 </span></span>
<span><span class="co">##  1.20 -4.27  0.17 -0.30 -0.73  0.27  1.48 -0.18 -0.48 -0.15  0.05 -0.84  0.18 </span></span>
<span><span class="co">##  ID79  ID80  ID81  ID82 </span></span>
<span><span class="co">##  0.00  0.05  0.55  1.63</span></span></code></pre>
<p>We see that in this case, column clustering with individual row
effects has detected that column Q1 is different to all the other
columns, so that is in a cluster on its own, with a much higher
probability of getting high value responses. There is almost zero
uncertainty about the cluster memberships.</p>
<p>A few rows have big negative parameters, and thus are much more
likely to show lower-value responses. These are probably the same few
that were identified during the row clustering process as having lower
response values than the rest.</p>
</div>
<div class="section level4">
<h4 id="column-clusters-with-individual-row-effects-and-interaction">Column clusters with individual row effects and interaction<a class="anchor" aria-label="anchor" href="#column-clusters-with-individual-row-effects-and-interaction"></a>
</h4>
<p>And, as before, we can add interactions between the column cluster
effects and the individual row effects, using the usual R interaction
formula notation.</p>
<div class="sourceCode" id="cb93"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="fu"><a href="https://rdrr.io/r/base/Random.html" class="external-link">set.seed</a></span><span class="op">(</span><span class="fl">1</span><span class="op">)</span></span>
<span><span class="va">fit_colclust_rows_interact</span> <span class="op">&lt;-</span> <span class="fu"><a href="../reference/clustord.html">clustord</a></span><span class="op">(</span><span class="va">Y</span> <span class="op">~</span></span>
<span>    <span class="va">COLCLUST</span> <span class="op">*</span> <span class="va">ROW</span>, model <span class="op">=</span> <span class="st">"POM"</span>, nclus.column <span class="op">=</span> <span class="fl">2</span>,</span>
<span>    long.df <span class="op">=</span> <span class="va">long.df</span>, verbose <span class="op">=</span> <span class="cn">FALSE</span><span class="op">)</span></span></code></pre></div>
<p>The interaction terms added are named <code>colc_row</code>.</p>
<div class="sourceCode" id="cb94"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="co"># Convergence</span></span>
<span><span class="va">fit_colclust_rows_interact</span><span class="op">$</span><span class="va">EM.status</span><span class="op">$</span><span class="va">converged</span></span></code></pre></div>
<pre><code><span><span class="co">## [1] TRUE</span></span></code></pre>
<div class="sourceCode" id="cb96"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="co"># Column cluster membership</span></span>
<span><span class="co"># probabilities</span></span>
<span><span class="fu"><a href="https://rdrr.io/r/base/Round.html" class="external-link">round</a></span><span class="op">(</span><span class="va">fit_colclust_rows_interact</span><span class="op">$</span><span class="va">ppc</span>, <span class="fl">2</span><span class="op">)</span></span></code></pre></div>
<pre><code><span><span class="co">##       [,1] [,2]</span></span>
<span><span class="co">##  [1,]    1    0</span></span>
<span><span class="co">##  [2,]    0    1</span></span>
<span><span class="co">##  [3,]    0    1</span></span>
<span><span class="co">##  [4,]    0    1</span></span>
<span><span class="co">##  [5,]    0    1</span></span>
<span><span class="co">##  [6,]    0    1</span></span>
<span><span class="co">##  [7,]    0    1</span></span>
<span><span class="co">##  [8,]    0    1</span></span>
<span><span class="co">##  [9,]    0    1</span></span>
<span><span class="co">## [10,]    0    1</span></span>
<span><span class="co">## [11,]    0    1</span></span>
<span><span class="co">## [12,]    0    1</span></span></code></pre>
<div class="sourceCode" id="cb98"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="co"># Members of each column cluster</span></span>
<span><span class="va">fit_colclust_rows_interact</span><span class="op">$</span><span class="va">ColumnClusterMembers</span></span></code></pre></div>
<pre><code><span><span class="co">## [[1]]</span></span>
<span><span class="co">## [1] 1</span></span>
<span><span class="co">## </span></span>
<span><span class="co">## [[2]]</span></span>
<span><span class="co">##  [1]  2  3  4  5  6  7  8  9 10 11 12</span></span></code></pre>
<div class="sourceCode" id="cb100"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="co"># Mixing proportions</span></span>
<span><span class="fu"><a href="https://rdrr.io/r/base/Round.html" class="external-link">round</a></span><span class="op">(</span><span class="va">fit_colclust_rows_interact</span><span class="op">$</span><span class="va">kappa.out</span>,</span>
<span>    <span class="fl">2</span><span class="op">)</span></span></code></pre></div>
<pre><code><span><span class="co">## [1] 0.08 0.92</span></span></code></pre>
<div class="sourceCode" id="cb102"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="co"># Parameters</span></span>
<span><span class="va">fit_colclust_rows_interact</span><span class="op">$</span><span class="va">parlist.out</span><span class="op">$</span><span class="va">colc</span></span></code></pre></div>
<pre><code><span><span class="co">##    colc_1    colc_2 </span></span>
<span><span class="co">##  10.49554 -10.49554</span></span></code></pre>
<div class="sourceCode" id="cb104"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="fu"><a href="https://rdrr.io/r/base/Round.html" class="external-link">round</a></span><span class="op">(</span><span class="va">fit_colclust_rows_interact</span><span class="op">$</span><span class="va">parlist.out</span><span class="op">$</span><span class="va">row</span>,</span>
<span>    <span class="fl">2</span><span class="op">)</span></span></code></pre></div>
<pre><code><span><span class="co">##    ID1    ID2    ID3    ID4    ID5    ID6    ID7    ID8    ID9   ID10   ID11 </span></span>
<span><span class="co">##  -3.89   3.58   3.63  -3.61   3.87  -3.76   4.30  -3.86  -3.92   3.78  -7.83 </span></span>
<span><span class="co">##   ID12   ID13   ID14   ID15   ID16   ID17   ID18   ID19   ID20   ID21   ID22 </span></span>
<span><span class="co">##   2.64   4.23   3.83  -4.06   2.93   1.79  -3.83   3.54   3.03   3.28   3.18 </span></span>
<span><span class="co">##   ID23   ID24   ID25   ID26   ID27   ID28   ID29   ID30   ID31   ID32   ID33 </span></span>
<span><span class="co">##  -7.73  -8.26   3.00   2.92  -4.05   3.02  -3.83  -4.00   3.57   2.83  -5.90 </span></span>
<span><span class="co">##   ID34   ID35   ID36   ID37   ID38   ID39   ID40   ID41   ID42   ID43   ID44 </span></span>
<span><span class="co">##  -3.77   3.81  -4.19  -8.45  -4.76   3.54   3.72  -3.78  -7.94  -8.60   2.90 </span></span>
<span><span class="co">##   ID45   ID46   ID47   ID48   ID49   ID50   ID51   ID52   ID53   ID54   ID55 </span></span>
<span><span class="co">##  -3.96  -7.67  -8.35  -3.99  -3.80   3.97   3.66   3.88  -3.71   3.25  -4.02 </span></span>
<span><span class="co">##   ID56   ID57   ID58   ID59   ID60   ID61   ID62   ID63   ID64   ID65   ID66 </span></span>
<span><span class="co">##   3.28  -3.99   3.63  -3.79   3.20 -10.20   4.85   4.49  -7.53   2.92  -7.27 </span></span>
<span><span class="co">##   ID67   ID68   ID69   ID70   ID71   ID72   ID73   ID74   ID75   ID76   ID77 </span></span>
<span><span class="co">##  -2.78  -3.85   3.12  -4.06  -7.79  -7.17   3.18   3.02  -8.72   3.25   2.86 </span></span>
<span><span class="co">##   ID78   ID79   ID80   ID81   ID82 </span></span>
<span><span class="co">##  -3.86  -3.87   3.29   3.57  84.06</span></span></code></pre>
<div class="sourceCode" id="cb106"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="fu"><a href="https://rdrr.io/r/base/Round.html" class="external-link">round</a></span><span class="op">(</span><span class="va">fit_colclust_rows_interact</span><span class="op">$</span><span class="va">parlist.out</span><span class="op">$</span><span class="va">colc_row</span>,</span>
<span>    <span class="fl">2</span><span class="op">)</span></span></code></pre></div>
<pre><code><span><span class="co">##        ID1   ID2   ID3 ID4   ID5   ID6   ID7   ID8   ID9  ID10  ID11  ID12 ID13</span></span>
<span><span class="co">## [1,] -4.09  3.01  2.96  -5  2.75 -4.51  2.33 -4.19 -3.91  2.83 -8.46  4.14  2.4</span></span>
<span><span class="co">## [2,]  4.09 -3.01 -2.96   5 -2.75  4.51 -2.33  4.19  3.91 -2.83  8.46 -4.14 -2.4</span></span>
<span><span class="co">##       ID14  ID15  ID16  ID17  ID18  ID19 ID20 ID21  ID22  ID23  ID24  ID25</span></span>
<span><span class="co">## [1,]  2.78 -3.44  3.75  4.98 -4.38  3.04  3.6  3.3  3.41 -8.56 -8.03  3.63</span></span>
<span><span class="co">## [2,] -2.78  3.44 -3.75 -4.98  4.38 -3.04 -3.6 -3.3 -3.41  8.56  8.03 -3.63</span></span>
<span><span class="co">##       ID26  ID27  ID28  ID29  ID30  ID31  ID32  ID33  ID34 ID35  ID36  ID37</span></span>
<span><span class="co">## [1,]  3.75 -3.46  3.61 -4.35 -3.56  3.01  3.88 -2.57 -4.61  2.8 -3.21 -7.84</span></span>
<span><span class="co">## [2,] -3.75  3.46 -3.61  4.35  3.56 -3.01 -3.88  2.57  4.61 -2.8  3.21  7.84</span></span>
<span><span class="co">##       ID38  ID39  ID40  ID41  ID42 ID43  ID44  ID45  ID46  ID47  ID48  ID49</span></span>
<span><span class="co">## [1,] -2.85  3.04  2.88 -4.56 -8.35 -9.1  3.77 -3.74 -8.62 -7.94 -3.62 -4.36</span></span>
<span><span class="co">## [2,]  2.85 -3.04 -2.88  4.56  8.35  9.1 -3.77  3.74  8.62  7.94  3.62  4.36</span></span>
<span><span class="co">##       ID50  ID51  ID52  ID53  ID54  ID55 ID56  ID57  ID58 ID59  ID60  ID61</span></span>
<span><span class="co">## [1,]  2.66  2.94  2.75 -4.72  3.32 -3.53  3.3 -3.62  2.96 -4.5  3.39 -6.09</span></span>
<span><span class="co">## [2,] -2.66 -2.94 -2.75  4.72 -3.32  3.53 -3.3  3.62 -2.96  4.5 -3.39  6.09</span></span>
<span><span class="co">##       ID62  ID63  ID64  ID65  ID66  ID67  ID68  ID69  ID70 ID71  ID72  ID73</span></span>
<span><span class="co">## [1,]  1.73  2.11 -8.76  3.75 -9.02  9.36 -4.27  3.49 -3.44 -8.5 -9.12  3.41</span></span>
<span><span class="co">## [2,] -1.73 -2.11  8.76 -3.75  9.02 -9.36  4.27 -3.49  3.44  8.5  9.12 -3.41</span></span>
<span><span class="co">##       ID74  ID75  ID76  ID77  ID78  ID79  ID80  ID81   ID82</span></span>
<span><span class="co">## [1,]  3.61 -8.98  3.32  3.84 -4.27 -4.11  3.29  3.01  82.36</span></span>
<span><span class="co">## [2,] -3.61  8.98 -3.32 -3.84  4.27  4.11 -3.29 -3.01 -82.36</span></span></code></pre>
<p>Adding interactions between individual rows and column clusters has
not changed the cluster memberships, compared with the model without
interactions, but it has made the effects of the clusters stronger, as
seen in the <code>colc</code> parameters, and it has made the individual
row effects much bigger.</p>
<p>We can plot these interaction terms against each other to see the
interaction effects:</p>
<div class="sourceCode" id="cb108"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="va">colc_row</span> <span class="op">&lt;-</span> <span class="va">fit_colclust_rows_interact</span><span class="op">$</span><span class="va">parlist.out</span><span class="op">$</span><span class="va">colc_row</span></span>
<span><span class="fu"><a href="https://rdrr.io/r/graphics/plot.default.html" class="external-link">plot</a></span><span class="op">(</span><span class="va">colc_row</span><span class="op">[</span><span class="fl">1</span>, <span class="op">]</span>, type <span class="op">=</span> <span class="st">"b"</span>, col <span class="op">=</span> <span class="st">"black"</span>,</span>
<span>    lwd <span class="op">=</span> <span class="fl">2</span>, ylim <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/base/c.html" class="external-link">c</a></span><span class="op">(</span><span class="op">-</span><span class="fl">85</span>, <span class="fl">85</span><span class="op">)</span>, xlab <span class="op">=</span> <span class="st">"Subject"</span>,</span>
<span>    ylab <span class="op">=</span> <span class="st">"Cluster interaction effect"</span><span class="op">)</span></span>
<span><span class="fu"><a href="https://rdrr.io/r/graphics/lines.html" class="external-link">lines</a></span><span class="op">(</span><span class="va">colc_row</span><span class="op">[</span><span class="fl">2</span>, <span class="op">]</span>, lty <span class="op">=</span> <span class="fl">2</span>, col <span class="op">=</span> <span class="st">"blue"</span>,</span>
<span>    lwd <span class="op">=</span> <span class="fl">2</span><span class="op">)</span></span>
<span><span class="fu"><a href="https://rdrr.io/r/graphics/points.html" class="external-link">points</a></span><span class="op">(</span><span class="va">colc_row</span><span class="op">[</span><span class="fl">2</span>, <span class="op">]</span>, lty <span class="op">=</span> <span class="fl">3</span>, col <span class="op">=</span> <span class="st">"blue"</span>,</span>
<span>    lwd <span class="op">=</span> <span class="fl">2</span><span class="op">)</span></span>
<span><span class="fu"><a href="https://rdrr.io/r/graphics/legend.html" class="external-link">legend</a></span><span class="op">(</span><span class="st">"topleft"</span>, legend <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/base/c.html" class="external-link">c</a></span><span class="op">(</span><span class="st">"Cluster 1"</span>,</span>
<span>    <span class="st">"Cluster 2"</span><span class="op">)</span>, col <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/base/c.html" class="external-link">c</a></span><span class="op">(</span><span class="st">"black"</span>, <span class="st">"blue"</span><span class="op">)</span>,</span>
<span>    lwd <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/base/c.html" class="external-link">c</a></span><span class="op">(</span><span class="fl">2</span>, <span class="fl">2</span><span class="op">)</span>, lty <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/base/c.html" class="external-link">c</a></span><span class="op">(</span><span class="fl">1</span>, <span class="fl">3</span><span class="op">)</span><span class="op">)</span></span></code></pre></div>
<p><img src="clustordTutorial_files/figure-html/unnamed-chunk-47-1.png" width="700"></p>
<p>We can see that there is a huge difference between the response
values for cluster 1 (Q1) and cluster 2 (the rest of the questions) for
the last subject, but other than that the cluster responses are broadly
similar for most subjects. Zooming in on the rest of the plot:</p>
<div class="sourceCode" id="cb109"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="va">colc_row</span> <span class="op">&lt;-</span> <span class="va">fit_colclust_rows_interact</span><span class="op">$</span><span class="va">parlist.out</span><span class="op">$</span><span class="va">colc_row</span></span>
<span><span class="fu"><a href="https://rdrr.io/r/graphics/plot.default.html" class="external-link">plot</a></span><span class="op">(</span><span class="va">colc_row</span><span class="op">[</span><span class="fl">1</span>, <span class="op">]</span>, type <span class="op">=</span> <span class="st">"b"</span>, col <span class="op">=</span> <span class="st">"black"</span>,</span>
<span>    lwd <span class="op">=</span> <span class="fl">2</span>, ylim <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/base/c.html" class="external-link">c</a></span><span class="op">(</span><span class="op">-</span><span class="fl">10</span>, <span class="fl">10</span><span class="op">)</span>, xlab <span class="op">=</span> <span class="st">"Subject"</span>,</span>
<span>    ylab <span class="op">=</span> <span class="st">"Cluster interaction effect"</span><span class="op">)</span></span>
<span><span class="fu"><a href="https://rdrr.io/r/graphics/lines.html" class="external-link">lines</a></span><span class="op">(</span><span class="va">colc_row</span><span class="op">[</span><span class="fl">2</span>, <span class="op">]</span>, lty <span class="op">=</span> <span class="fl">2</span>, col <span class="op">=</span> <span class="st">"blue"</span>,</span>
<span>    lwd <span class="op">=</span> <span class="fl">2</span><span class="op">)</span></span>
<span><span class="fu"><a href="https://rdrr.io/r/graphics/points.html" class="external-link">points</a></span><span class="op">(</span><span class="va">colc_row</span><span class="op">[</span><span class="fl">2</span>, <span class="op">]</span>, lty <span class="op">=</span> <span class="fl">3</span>, col <span class="op">=</span> <span class="st">"blue"</span>,</span>
<span>    lwd <span class="op">=</span> <span class="fl">2</span><span class="op">)</span></span>
<span><span class="fu"><a href="https://rdrr.io/r/graphics/legend.html" class="external-link">legend</a></span><span class="op">(</span><span class="st">"topleft"</span>, legend <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/base/c.html" class="external-link">c</a></span><span class="op">(</span><span class="st">"Cluster 1"</span>,</span>
<span>    <span class="st">"Cluster 2"</span><span class="op">)</span>, col <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/base/c.html" class="external-link">c</a></span><span class="op">(</span><span class="st">"black"</span>, <span class="st">"blue"</span><span class="op">)</span>,</span>
<span>    lwd <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/base/c.html" class="external-link">c</a></span><span class="op">(</span><span class="fl">2</span>, <span class="fl">2</span><span class="op">)</span>, lty <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/base/c.html" class="external-link">c</a></span><span class="op">(</span><span class="fl">1</span>, <span class="fl">3</span><span class="op">)</span><span class="op">)</span></span></code></pre></div>
<p><img src="clustordTutorial_files/figure-html/unnamed-chunk-48-1.png" width="700"></p>
<p>There is no clear pattern to this, which often suggests that the
model is not well-fitted.</p>
</div>
<div class="section level4">
<h4 id="model-selection-1">Model selection<a class="anchor" aria-label="anchor" href="#model-selection-1"></a>
</h4>
<p>Again, we will look at AIC and BIC to perform model selection amongst
the column clustering models.</p>
<div class="sourceCode" id="cb110"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="va">fit_colclust_only</span><span class="op">$</span><span class="va">criteria</span><span class="op">$</span><span class="va">AIC</span></span></code></pre></div>
<pre><code><span><span class="co">## [1] 2792.468</span></span></code></pre>
<div class="sourceCode" id="cb112"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="va">fit_colclust_rows</span><span class="op">$</span><span class="va">criteria</span><span class="op">$</span><span class="va">AIC</span></span></code></pre></div>
<pre><code><span><span class="co">## [1] 2572.39</span></span></code></pre>
<div class="sourceCode" id="cb114"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="va">fit_colclust_rows_interact</span><span class="op">$</span><span class="va">criteria</span><span class="op">$</span><span class="va">AIC</span></span></code></pre></div>
<pre><code><span><span class="co">## [1] 2558.218</span></span></code></pre>
<div class="sourceCode" id="cb116"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="va">fit_colclust_only</span><span class="op">$</span><span class="va">criteria</span><span class="op">$</span><span class="va">BIC</span></span></code></pre></div>
<pre><code><span><span class="co">## [1] 2831.601</span></span></code></pre>
<div class="sourceCode" id="cb118"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="va">fit_colclust_rows</span><span class="op">$</span><span class="va">criteria</span><span class="op">$</span><span class="va">BIC</span></span></code></pre></div>
<pre><code><span><span class="co">## [1] 3007.744</span></span></code></pre>
<div class="sourceCode" id="cb120"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="va">fit_colclust_rows_interact</span><span class="op">$</span><span class="va">criteria</span><span class="op">$</span><span class="va">BIC</span></span></code></pre></div>
<pre><code><span><span class="co">## [1] 3389.795</span></span></code></pre>
<p>In this instance, AIC selects the model with individual row effects
and interactions, though it has very similar AIC to the model with
individual row effects and no interactions. BIC selects the model with
column clusters only.</p>
<p>When AIC and BIC disagree about which model to select, then it is
time to include external factors, such has how important simplicity is
for the sake of helping end-users to understand your model. Even under
AIC, the value for the column-cluster-only model is not a great deal
higher than the AIC values for the other two models, so it would be
justifiable to select the column-cluster-only model for simplicity and
to match the BIC selection.</p>
<div style="page-break-after: always;"></div>
</div>
</div>
<div class="section level3">
<h3 id="biclustering">Biclustering<a class="anchor" aria-label="anchor" href="#biclustering"></a>
</h3>
<p>So far we have demonstrated how to cluster the rows or the columns of
the data matrix. <code>clustord</code> can also cluster the rows and
columns simultaneously. We call this <strong>biclustering</strong> or
“two-mode clustering”, though this term is not universally used (Jacques
and Biernacki (2018) for example, calls it “co-clustering”). For our
example dataset, this would correspond to clustering the subjects
<strong>and</strong> the questions in the survey, to find out which
subsets of subjects had similar patterns of responses for particular
subsets of questions.</p>
<p>There are only two biclustering structures: those with only row and
column effects, and those with row and column effects and interactions
between them. The biclustering form in <code>clustord</code> does not
allow the inclusion of individual row or column effects in addition to
the row and column clusters, as this makes the model too complex and the
number of parameters is usually too high to fit well.</p>
<p>In some ways this model form is more complex than row or column
clustering, but it can use fewer parameters than row or column
clustering with individual column or row effects. When considering which
types of models to use, think about it like this: If you think your
primary goal is row clustering but you have a lot of variety amongst the
columns, then row clustering with individual column effects may be the
most suitable model; but if you have a lot of similar columns then
biclustering may be more suitable. Attempt to fit both types of model,
and use model selection via e.g. AIC or BIC to find the best model.</p>
<p>Even if your main focus is on clustering the columns, for example,
but you see that there is some variety amongst the rows, then it would
be good to try fitting the biclustering model to account for this
variety and allow you to get a more accurate fit for your column
clusters.</p>
<div class="section level4">
<h4 id="biclustering-without-interactions">Biclustering without interactions<a class="anchor" aria-label="anchor" href="#biclustering-without-interactions"></a>
</h4>
<p>The simpler biclustering model is the one that only has row and
column cluster effects, without any interactions between them. This
model has <code>rowc + colc</code> as the main part of the linear
predictor. We have to define both <code>nclus.row</code> and
<code>nclus.column</code>.</p>
<div class="sourceCode" id="cb122"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="fu"><a href="https://rdrr.io/r/base/Random.html" class="external-link">set.seed</a></span><span class="op">(</span><span class="fl">4</span><span class="op">)</span></span>
<span><span class="va">fit_biclust</span> <span class="op">&lt;-</span> <span class="fu"><a href="../reference/clustord.html">clustord</a></span><span class="op">(</span><span class="va">Y</span> <span class="op">~</span> <span class="va">ROWCLUST</span> <span class="op">+</span> <span class="va">COLCLUST</span>,</span>
<span>    model <span class="op">=</span> <span class="st">"POM"</span>, nclus.row <span class="op">=</span> <span class="fl">2</span>, nclus.column <span class="op">=</span> <span class="fl">2</span>,</span>
<span>    long.df <span class="op">=</span> <span class="va">long.df</span>, verbose <span class="op">=</span> <span class="cn">FALSE</span><span class="op">)</span></span>
<span><span class="va">converged</span> <span class="op">&lt;-</span> <span class="va">fit_biclust</span><span class="op">$</span><span class="va">EM.status</span><span class="op">$</span><span class="va">converged</span></span></code></pre></div>
<p>By default, the biclustering model fits row clustering and column
clustering models first in order to find good starting points for the
parameters of the biclustering model, because the row and column
clustering models are quicker to run.</p>
<p>Note that the reporting for the biclustering model also reports the
complete-data log-likelihood and the <strong>APPROXIMATE</strong>
incomplete-data log-likelihood. This is because the true incomplete-data
log-likelihood is infeasible to calculate, even for only two row
clusters and two column clusters, so we use an entropy-based
approximation to calculate it.</p>
<p>In biclustering, we will obtain cluster membership proportions for
both row and column clusters (<code>ppr</code> and <code>ppc</code>),
and the mixing proportions for both
(<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mo stretchy="false" form="prefix">{</mo><msub><mi>π</mi><mi>r</mi></msub><mo stretchy="false" form="postfix">}</mo></mrow><annotation encoding="application/x-tex">\{\pi_r\}</annotation></semantics></math>
and
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mo stretchy="false" form="prefix">{</mo><msub><mi>κ</mi><mi>c</mi></msub><mo stretchy="false" form="postfix">}</mo></mrow><annotation encoding="application/x-tex">\{\kappa_c\}</annotation></semantics></math>).
The maximum-probability cluster memberships are named
<code>RowClusters</code> and <code>ColumnClusters</code> and the lists
of cluster memberships are <code>RowClusterMembers</code> and
<code>ColumnClusterMembers</code>.</p>
<div class="sourceCode" id="cb123"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="co"># Convergence</span></span>
<span><span class="va">fit_biclust</span><span class="op">$</span><span class="va">EM.status</span><span class="op">$</span><span class="va">converged</span></span></code></pre></div>
<pre><code><span><span class="co">## [1] FALSE</span></span></code></pre>
<div class="sourceCode" id="cb125"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="co"># Cluster membership probabilities</span></span>
<span><span class="fu"><a href="https://rdrr.io/r/base/Round.html" class="external-link">round</a></span><span class="op">(</span><span class="va">fit_biclust</span><span class="op">$</span><span class="va">ppr</span>, <span class="fl">2</span><span class="op">)</span></span></code></pre></div>
<pre><code><span><span class="co">##       [,1] [,2]</span></span>
<span><span class="co">##  [1,] 0.99 0.01</span></span>
<span><span class="co">##  [2,] 0.97 0.03</span></span>
<span><span class="co">##  [3,] 0.98 0.02</span></span>
<span><span class="co">##  [4,] 1.00 0.00</span></span>
<span><span class="co">##  [5,] 1.00 0.00</span></span>
<span><span class="co">##  [6,] 0.99 0.01</span></span>
<span><span class="co">##  [7,] 1.00 0.00</span></span>
<span><span class="co">##  [8,] 0.99 0.01</span></span>
<span><span class="co">##  [9,] 0.97 0.03</span></span>
<span><span class="co">## [10,] 1.00 0.00</span></span>
<span><span class="co">## [11,] 1.00 0.00</span></span>
<span><span class="co">## [12,] 0.01 0.99</span></span>
<span><span class="co">## [13,] 1.00 0.00</span></span>
<span><span class="co">## [14,] 0.99 0.01</span></span>
<span><span class="co">## [15,] 0.79 0.21</span></span>
<span><span class="co">## [16,] 0.15 0.85</span></span>
<span><span class="co">## [17,] 0.00 1.00</span></span>
<span><span class="co">## [18,] 1.00 0.00</span></span>
<span><span class="co">## [19,] 0.95 0.05</span></span>
<span><span class="co">## [20,] 0.31 0.69</span></span>
<span><span class="co">## [21,] 0.86 0.14</span></span>
<span><span class="co">## [22,] 0.76 0.24</span></span>
<span><span class="co">## [23,] 1.00 0.00</span></span>
<span><span class="co">## [24,] 0.93 0.07</span></span>
<span><span class="co">## [25,] 0.39 0.61</span></span>
<span><span class="co">## [26,] 0.11 0.89</span></span>
<span><span class="co">## [27,] 0.58 0.42</span></span>
<span><span class="co">## [28,] 0.21 0.79</span></span>
<span><span class="co">## [29,] 1.00 0.00</span></span>
<span><span class="co">## [30,] 0.75 0.25</span></span>
<span><span class="co">## [31,] 0.98 0.02</span></span>
<span><span class="co">## [32,] 0.06 0.94</span></span>
<span><span class="co">## [33,] 0.00 1.00</span></span>
<span><span class="co">## [34,] 1.00 0.00</span></span>
<span><span class="co">## [35,] 1.00 0.00</span></span>
<span><span class="co">## [36,] 0.50 0.50</span></span>
<span><span class="co">## [37,] 0.70 0.30</span></span>
<span><span class="co">## [38,] 0.01 0.99</span></span>
<span><span class="co">## [39,] 0.95 0.05</span></span>
<span><span class="co">## [40,] 0.99 0.01</span></span>
<span><span class="co">## [41,] 1.00 0.00</span></span>
<span><span class="co">## [42,] 0.99 0.01</span></span>
<span><span class="co">## [43,] 0.99 0.01</span></span>
<span><span class="co">## [44,] 0.06 0.94</span></span>
<span><span class="co">## [45,] 0.94 0.06</span></span>
<span><span class="co">## [46,] 1.00 0.00</span></span>
<span><span class="co">## [47,] 0.88 0.12</span></span>
<span><span class="co">## [48,] 0.80 0.20</span></span>
<span><span class="co">## [49,] 0.99 0.01</span></span>
<span><span class="co">## [50,] 1.00 0.00</span></span>
<span><span class="co">## [51,] 0.97 0.03</span></span>
<span><span class="co">## [52,] 0.99 0.01</span></span>
<span><span class="co">## [53,] 1.00 0.00</span></span>
<span><span class="co">## [54,] 0.53 0.47</span></span>
<span><span class="co">## [55,] 0.74 0.26</span></span>
<span><span class="co">## [56,] 0.86 0.14</span></span>
<span><span class="co">## [57,] 0.80 0.20</span></span>
<span><span class="co">## [58,] 0.98 0.02</span></span>
<span><span class="co">## [59,] 0.99 0.01</span></span>
<span><span class="co">## [60,] 0.59 0.41</span></span>
<span><span class="co">## [61,] 0.00 1.00</span></span>
<span><span class="co">## [62,] 1.00 0.00</span></span>
<span><span class="co">## [63,] 1.00 0.00</span></span>
<span><span class="co">## [64,] 1.00 0.00</span></span>
<span><span class="co">## [65,] 0.11 0.89</span></span>
<span><span class="co">## [66,] 1.00 0.00</span></span>
<span><span class="co">## [67,] 0.00 1.00</span></span>
<span><span class="co">## [68,] 0.99 0.01</span></span>
<span><span class="co">## [69,] 0.43 0.57</span></span>
<span><span class="co">## [70,] 0.73 0.27</span></span>
<span><span class="co">## [71,] 0.99 0.01</span></span>
<span><span class="co">## [72,] 1.00 0.00</span></span>
<span><span class="co">## [73,] 0.76 0.24</span></span>
<span><span class="co">## [74,] 0.21 0.79</span></span>
<span><span class="co">## [75,] 0.96 0.04</span></span>
<span><span class="co">## [76,] 0.83 0.17</span></span>
<span><span class="co">## [77,] 0.12 0.88</span></span>
<span><span class="co">## [78,] 0.99 0.01</span></span>
<span><span class="co">## [79,] 0.99 0.01</span></span>
<span><span class="co">## [80,] 0.76 0.24</span></span>
<span><span class="co">## [81,] 0.98 0.02</span></span>
<span><span class="co">## [82,] 1.00 0.00</span></span></code></pre>
<div class="sourceCode" id="cb127"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="fu"><a href="https://rdrr.io/r/base/Round.html" class="external-link">round</a></span><span class="op">(</span><span class="va">fit_biclust</span><span class="op">$</span><span class="va">ppc</span>, <span class="fl">2</span><span class="op">)</span></span></code></pre></div>
<pre><code><span><span class="co">##       [,1] [,2]</span></span>
<span><span class="co">##  [1,]    0    1</span></span>
<span><span class="co">##  [2,]    1    0</span></span>
<span><span class="co">##  [3,]    1    0</span></span>
<span><span class="co">##  [4,]    1    0</span></span>
<span><span class="co">##  [5,]    1    0</span></span>
<span><span class="co">##  [6,]    0    1</span></span>
<span><span class="co">##  [7,]    1    0</span></span>
<span><span class="co">##  [8,]    0    1</span></span>
<span><span class="co">##  [9,]    0    1</span></span>
<span><span class="co">## [10,]    0    1</span></span>
<span><span class="co">## [11,]    1    0</span></span>
<span><span class="co">## [12,]    1    0</span></span></code></pre>
<div class="sourceCode" id="cb129"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="co"># Members of each cluster</span></span>
<span><span class="va">fit_biclust</span><span class="op">$</span><span class="va">RowClusterMembers</span></span></code></pre></div>
<pre><code><span><span class="co">## [[1]]</span></span>
<span><span class="co">##  [1]  1  2  3  4  5  6  7  8  9 10 11 13 14 15 18 19 21 22 23 24 27 29 30 31 34</span></span>
<span><span class="co">## [26] 35 37 39 40 41 42 43 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 62 63</span></span>
<span><span class="co">## [51] 64 66 68 70 71 72 73 75 76 78 79 80 81 82</span></span>
<span><span class="co">## </span></span>
<span><span class="co">## [[2]]</span></span>
<span><span class="co">##  [1] 12 16 17 20 25 26 28 32 33 36 38 44 61 65 67 69 74 77</span></span></code></pre>
<div class="sourceCode" id="cb131"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="va">fit_biclust</span><span class="op">$</span><span class="va">ColumnClusterMembers</span></span></code></pre></div>
<pre><code><span><span class="co">## [[1]]</span></span>
<span><span class="co">## [1]  2  3  4  5  7 11 12</span></span>
<span><span class="co">## </span></span>
<span><span class="co">## [[2]]</span></span>
<span><span class="co">## [1]  1  6  8  9 10</span></span></code></pre>
<div class="sourceCode" id="cb133"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="co"># Mixing proportions</span></span>
<span><span class="fu"><a href="https://rdrr.io/r/base/Round.html" class="external-link">round</a></span><span class="op">(</span><span class="va">fit_biclust</span><span class="op">$</span><span class="va">pi.out</span>, <span class="fl">2</span><span class="op">)</span></span></code></pre></div>
<pre><code><span><span class="co">## [1] 0.75 0.25</span></span></code></pre>
<div class="sourceCode" id="cb135"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="fu"><a href="https://rdrr.io/r/base/Round.html" class="external-link">round</a></span><span class="op">(</span><span class="va">fit_biclust</span><span class="op">$</span><span class="va">kappa.out</span>, <span class="fl">2</span><span class="op">)</span></span></code></pre></div>
<pre><code><span><span class="co">## [1] 0.58 0.42</span></span></code></pre>
<div class="sourceCode" id="cb137"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="co"># Parameters</span></span>
<span><span class="va">fit_biclust</span><span class="op">$</span><span class="va">parlist.out</span><span class="op">$</span><span class="va">rowc</span></span></code></pre></div>
<pre><code><span><span class="co">##     rowc_1     rowc_2 </span></span>
<span><span class="co">##  0.8698192 -0.8698192</span></span></code></pre>
<div class="sourceCode" id="cb139"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="va">fit_biclust</span><span class="op">$</span><span class="va">parlist.out</span><span class="op">$</span><span class="va">colc</span></span></code></pre></div>
<pre><code><span><span class="co">##    colc_1    colc_2 </span></span>
<span><span class="co">## -1.183548  1.183548</span></span></code></pre>
<p>The cluster probabilities are very close to 1 and 0 for both row and
column clusters. The row clusters identified are the same small and big
ones as for row clustering, although the column clusters are now a
little more evenly split between clusters.</p>
<p>We see that the first row cluster has higher response values, and the
first column cluster has higher response values.</p>
</div>
<div class="section level4">
<h4 id="biclustering-with-interactions">Biclustering with interactions<a class="anchor" aria-label="anchor" href="#biclustering-with-interactions"></a>
</h4>
<p>The final structure is the biclustering model with row and column
clusters and interactions between them. This introduces the final
element of the linear predictor, <code>rowc_colc</code>.</p>
<div class="sourceCode" id="cb141"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="fu"><a href="https://rdrr.io/r/base/Random.html" class="external-link">set.seed</a></span><span class="op">(</span><span class="fl">3</span><span class="op">)</span></span>
<span><span class="va">fit_biclust_interact</span> <span class="op">&lt;-</span> <span class="fu"><a href="../reference/clustord.html">clustord</a></span><span class="op">(</span><span class="va">Y</span> <span class="op">~</span> <span class="va">ROWCLUST</span> <span class="op">*</span></span>
<span>    <span class="va">COLCLUST</span>, model <span class="op">=</span> <span class="st">"POM"</span>, nclus.row <span class="op">=</span> <span class="fl">2</span>,</span>
<span>    nclus.column <span class="op">=</span> <span class="fl">2</span>, long.df <span class="op">=</span> <span class="va">long.df</span>,</span>
<span>    verbose <span class="op">=</span> <span class="cn">FALSE</span><span class="op">)</span></span>
<span><span class="va">converged</span> <span class="op">&lt;-</span> <span class="va">fit_biclust_interact</span><span class="op">$</span><span class="va">EM.status</span><span class="op">$</span><span class="va">converged</span></span></code></pre></div>
<div class="sourceCode" id="cb142"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="co"># Convergence</span></span>
<span><span class="va">fit_biclust_interact</span><span class="op">$</span><span class="va">EM.status</span><span class="op">$</span><span class="va">converged</span></span></code></pre></div>
<pre><code><span><span class="co">## [1] TRUE</span></span></code></pre>
<div class="sourceCode" id="cb144"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="co"># Cluster membership probabilities</span></span>
<span><span class="fu"><a href="https://rdrr.io/r/base/Round.html" class="external-link">round</a></span><span class="op">(</span><span class="va">fit_biclust_interact</span><span class="op">$</span><span class="va">ppr</span>, <span class="fl">2</span><span class="op">)</span></span></code></pre></div>
<pre><code><span><span class="co">##       [,1] [,2]</span></span>
<span><span class="co">##  [1,] 1.00 0.00</span></span>
<span><span class="co">##  [2,] 1.00 0.00</span></span>
<span><span class="co">##  [3,] 1.00 0.00</span></span>
<span><span class="co">##  [4,] 1.00 0.00</span></span>
<span><span class="co">##  [5,] 1.00 0.00</span></span>
<span><span class="co">##  [6,] 1.00 0.00</span></span>
<span><span class="co">##  [7,] 1.00 0.00</span></span>
<span><span class="co">##  [8,] 1.00 0.00</span></span>
<span><span class="co">##  [9,] 1.00 0.00</span></span>
<span><span class="co">## [10,] 1.00 0.00</span></span>
<span><span class="co">## [11,] 1.00 0.00</span></span>
<span><span class="co">## [12,] 0.99 0.01</span></span>
<span><span class="co">## [13,] 1.00 0.00</span></span>
<span><span class="co">## [14,] 1.00 0.00</span></span>
<span><span class="co">## [15,] 1.00 0.00</span></span>
<span><span class="co">## [16,] 1.00 0.00</span></span>
<span><span class="co">## [17,] 0.01 0.99</span></span>
<span><span class="co">## [18,] 1.00 0.00</span></span>
<span><span class="co">## [19,] 1.00 0.00</span></span>
<span><span class="co">## [20,] 1.00 0.00</span></span>
<span><span class="co">## [21,] 1.00 0.00</span></span>
<span><span class="co">## [22,] 1.00 0.00</span></span>
<span><span class="co">## [23,] 1.00 0.00</span></span>
<span><span class="co">## [24,] 1.00 0.00</span></span>
<span><span class="co">## [25,] 1.00 0.00</span></span>
<span><span class="co">## [26,] 1.00 0.00</span></span>
<span><span class="co">## [27,] 1.00 0.00</span></span>
<span><span class="co">## [28,] 1.00 0.00</span></span>
<span><span class="co">## [29,] 1.00 0.00</span></span>
<span><span class="co">## [30,] 1.00 0.00</span></span>
<span><span class="co">## [31,] 1.00 0.00</span></span>
<span><span class="co">## [32,] 1.00 0.00</span></span>
<span><span class="co">## [33,] 0.00 1.00</span></span>
<span><span class="co">## [34,] 1.00 0.00</span></span>
<span><span class="co">## [35,] 1.00 0.00</span></span>
<span><span class="co">## [36,] 1.00 0.00</span></span>
<span><span class="co">## [37,] 1.00 0.00</span></span>
<span><span class="co">## [38,] 0.88 0.12</span></span>
<span><span class="co">## [39,] 1.00 0.00</span></span>
<span><span class="co">## [40,] 1.00 0.00</span></span>
<span><span class="co">## [41,] 1.00 0.00</span></span>
<span><span class="co">## [42,] 1.00 0.00</span></span>
<span><span class="co">## [43,] 1.00 0.00</span></span>
<span><span class="co">## [44,] 1.00 0.00</span></span>
<span><span class="co">## [45,] 1.00 0.00</span></span>
<span><span class="co">## [46,] 1.00 0.00</span></span>
<span><span class="co">## [47,] 1.00 0.00</span></span>
<span><span class="co">## [48,] 1.00 0.00</span></span>
<span><span class="co">## [49,] 1.00 0.00</span></span>
<span><span class="co">## [50,] 1.00 0.00</span></span>
<span><span class="co">## [51,] 1.00 0.00</span></span>
<span><span class="co">## [52,] 1.00 0.00</span></span>
<span><span class="co">## [53,] 1.00 0.00</span></span>
<span><span class="co">## [54,] 1.00 0.00</span></span>
<span><span class="co">## [55,] 1.00 0.00</span></span>
<span><span class="co">## [56,] 1.00 0.00</span></span>
<span><span class="co">## [57,] 1.00 0.00</span></span>
<span><span class="co">## [58,] 1.00 0.00</span></span>
<span><span class="co">## [59,] 1.00 0.00</span></span>
<span><span class="co">## [60,] 1.00 0.00</span></span>
<span><span class="co">## [61,] 0.00 1.00</span></span>
<span><span class="co">## [62,] 1.00 0.00</span></span>
<span><span class="co">## [63,] 1.00 0.00</span></span>
<span><span class="co">## [64,] 1.00 0.00</span></span>
<span><span class="co">## [65,] 1.00 0.00</span></span>
<span><span class="co">## [66,] 1.00 0.00</span></span>
<span><span class="co">## [67,] 0.00 1.00</span></span>
<span><span class="co">## [68,] 1.00 0.00</span></span>
<span><span class="co">## [69,] 1.00 0.00</span></span>
<span><span class="co">## [70,] 1.00 0.00</span></span>
<span><span class="co">## [71,] 1.00 0.00</span></span>
<span><span class="co">## [72,] 1.00 0.00</span></span>
<span><span class="co">## [73,] 1.00 0.00</span></span>
<span><span class="co">## [74,] 1.00 0.00</span></span>
<span><span class="co">## [75,] 1.00 0.00</span></span>
<span><span class="co">## [76,] 1.00 0.00</span></span>
<span><span class="co">## [77,] 1.00 0.00</span></span>
<span><span class="co">## [78,] 1.00 0.00</span></span>
<span><span class="co">## [79,] 1.00 0.00</span></span>
<span><span class="co">## [80,] 1.00 0.00</span></span>
<span><span class="co">## [81,] 1.00 0.00</span></span>
<span><span class="co">## [82,] 1.00 0.00</span></span></code></pre>
<div class="sourceCode" id="cb146"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="fu"><a href="https://rdrr.io/r/base/Round.html" class="external-link">round</a></span><span class="op">(</span><span class="va">fit_biclust_interact</span><span class="op">$</span><span class="va">ppc</span>, <span class="fl">2</span><span class="op">)</span></span></code></pre></div>
<pre><code><span><span class="co">##       [,1] [,2]</span></span>
<span><span class="co">##  [1,]    1    0</span></span>
<span><span class="co">##  [2,]    0    1</span></span>
<span><span class="co">##  [3,]    0    1</span></span>
<span><span class="co">##  [4,]    0    1</span></span>
<span><span class="co">##  [5,]    1    0</span></span>
<span><span class="co">##  [6,]    1    0</span></span>
<span><span class="co">##  [7,]    1    0</span></span>
<span><span class="co">##  [8,]    1    0</span></span>
<span><span class="co">##  [9,]    1    0</span></span>
<span><span class="co">## [10,]    1    0</span></span>
<span><span class="co">## [11,]    0    1</span></span>
<span><span class="co">## [12,]    1    0</span></span></code></pre>
<div class="sourceCode" id="cb148"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="co"># Members of each cluster</span></span>
<span><span class="va">fit_biclust_interact</span><span class="op">$</span><span class="va">RowClusterMembers</span></span></code></pre></div>
<pre><code><span><span class="co">## [[1]]</span></span>
<span><span class="co">##  [1]  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 18 19 20 21 22 23 24 25 26</span></span>
<span><span class="co">## [26] 27 28 29 30 31 32 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52</span></span>
<span><span class="co">## [51] 53 54 55 56 57 58 59 60 62 63 64 65 66 68 69 70 71 72 73 74 75 76 77 78 79</span></span>
<span><span class="co">## [76] 80 81 82</span></span>
<span><span class="co">## </span></span>
<span><span class="co">## [[2]]</span></span>
<span><span class="co">## [1] 17 33 61 67</span></span></code></pre>
<div class="sourceCode" id="cb150"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="va">fit_biclust_interact</span><span class="op">$</span><span class="va">ColumnClusterMembers</span></span></code></pre></div>
<pre><code><span><span class="co">## [[1]]</span></span>
<span><span class="co">## [1]  1  5  6  7  8  9 10 12</span></span>
<span><span class="co">## </span></span>
<span><span class="co">## [[2]]</span></span>
<span><span class="co">## [1]  2  3  4 11</span></span></code></pre>
<div class="sourceCode" id="cb152"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="co"># Mixing proportions</span></span>
<span><span class="fu"><a href="https://rdrr.io/r/base/Round.html" class="external-link">round</a></span><span class="op">(</span><span class="va">fit_biclust_interact</span><span class="op">$</span><span class="va">pi.out</span>, <span class="fl">2</span><span class="op">)</span></span></code></pre></div>
<pre><code><span><span class="co">## [1] 0.95 0.05</span></span></code></pre>
<div class="sourceCode" id="cb154"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="fu"><a href="https://rdrr.io/r/base/Round.html" class="external-link">round</a></span><span class="op">(</span><span class="va">fit_biclust_interact</span><span class="op">$</span><span class="va">kappa.out</span>, <span class="fl">2</span><span class="op">)</span></span></code></pre></div>
<pre><code><span><span class="co">## [1] 0.67 0.33</span></span></code></pre>
<div class="sourceCode" id="cb156"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="co"># Parameters</span></span>
<span><span class="va">fit_biclust_interact</span><span class="op">$</span><span class="va">parlist.out</span><span class="op">$</span><span class="va">rowc</span></span></code></pre></div>
<pre><code><span><span class="co">##    rowc_1    rowc_2 </span></span>
<span><span class="co">##  3.001568 -3.001568</span></span></code></pre>
<div class="sourceCode" id="cb158"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="va">fit_biclust_interact</span><span class="op">$</span><span class="va">parlist.out</span><span class="op">$</span><span class="va">colc</span></span></code></pre></div>
<pre><code><span><span class="co">##    colc_1    colc_2 </span></span>
<span><span class="co">##  2.328658 -2.328658</span></span></code></pre>
<div class="sourceCode" id="cb160"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="fu"><a href="https://rdrr.io/r/base/Round.html" class="external-link">round</a></span><span class="op">(</span><span class="va">fit_biclust_interact</span><span class="op">$</span><span class="va">parlist.out</span><span class="op">$</span><span class="va">rowc_colc</span>,</span>
<span>    <span class="fl">2</span><span class="op">)</span></span></code></pre></div>
<pre><code><span><span class="co">##       [,1]  [,2]</span></span>
<span><span class="co">## [1,] -1.07  1.07</span></span>
<span><span class="co">## [2,]  1.07 -1.07</span></span></code></pre>
<p>The models with and without interactions have detected similar
clustering structures. This is reassuring, because it indicates that
this particular clustering structure is fairly robust and not sensitive
to the specific choice of model.</p>
</div>
<div class="section level4">
<h4 id="model-selection-2">Model selection<a class="anchor" aria-label="anchor" href="#model-selection-2"></a>
</h4>
<p>We can use model selection to assess which of the two biclustering
models is best, but we can <strong>also</strong> use it to select
whether the biclustering models are better than the row clustering model
or the column clustering model.</p>
<p>Let’s assess the row clustering vs. biclustering comparison.</p>
<div class="sourceCode" id="cb162"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="va">fit_rowclust_only</span><span class="op">$</span><span class="va">criteria</span><span class="op">$</span><span class="va">AIC</span></span></code></pre></div>
<pre><code><span><span class="co">## [1] 3854.975</span></span></code></pre>
<div class="sourceCode" id="cb164"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="va">fit_rowclust_cols</span><span class="op">$</span><span class="va">criteria</span><span class="op">$</span><span class="va">AIC</span></span></code></pre></div>
<pre><code><span><span class="co">## [1] 2258.931</span></span></code></pre>
<div class="sourceCode" id="cb166"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="va">fit_rowclust_cols_interact</span><span class="op">$</span><span class="va">criteria</span><span class="op">$</span><span class="va">AIC</span></span></code></pre></div>
<pre><code><span><span class="co">## [1] 2216.477</span></span></code></pre>
<div class="sourceCode" id="cb168"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="va">fit_biclust</span><span class="op">$</span><span class="va">criteria</span><span class="op">$</span><span class="va">AIC</span></span></code></pre></div>
<pre><code><span><span class="co">## [1] 2951.194</span></span></code></pre>
<div class="sourceCode" id="cb170"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="va">fit_biclust_interact</span><span class="op">$</span><span class="va">criteria</span><span class="op">$</span><span class="va">AIC</span></span></code></pre></div>
<pre><code><span><span class="co">## [1] 2692.541</span></span></code></pre>
<div class="sourceCode" id="cb172"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="va">fit_rowclust_only</span><span class="op">$</span><span class="va">criteria</span><span class="op">$</span><span class="va">BIC</span></span></code></pre></div>
<pre><code><span><span class="co">## [1] 3894.108</span></span></code></pre>
<div class="sourceCode" id="cb174"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="va">fit_rowclust_cols</span><span class="op">$</span><span class="va">criteria</span><span class="op">$</span><span class="va">BIC</span></span></code></pre></div>
<pre><code><span><span class="co">## [1] 2351.872</span></span></code></pre>
<div class="sourceCode" id="cb176"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="va">fit_rowclust_cols_interact</span><span class="op">$</span><span class="va">criteria</span><span class="op">$</span><span class="va">BIC</span></span></code></pre></div>
<pre><code><span><span class="co">## [1] 2363.225</span></span></code></pre>
<div class="sourceCode" id="cb178"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="va">fit_biclust</span><span class="op">$</span><span class="va">criteria</span><span class="op">$</span><span class="va">BIC</span></span></code></pre></div>
<pre><code><span><span class="co">## [1] 3000.11</span></span></code></pre>
<div class="sourceCode" id="cb180"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="va">fit_biclust_interact</span><span class="op">$</span><span class="va">criteria</span><span class="op">$</span><span class="va">BIC</span></span></code></pre></div>
<pre><code><span><span class="co">## [1] 2746.349</span></span></code></pre>
<p>AIC selects the row clustering model with individual column effects
and interactions as the best, with the row clustering without
interactions a close second.</p>
<p>BIC selects the row clustering model with individual column effects
but no interactions as the best and the row clustering model with
interactions as a close second.</p>
<p>So it appears that in this case, the row clustering model is better
than the biclustering model, but do note that the biclustering models
are still better than the row-cluster-only model by a large margin.</p>
<p>Now let’s compare column clustering and biclustering.</p>
<div class="sourceCode" id="cb182"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="va">fit_colclust_only</span><span class="op">$</span><span class="va">criteria</span><span class="op">$</span><span class="va">AIC</span></span></code></pre></div>
<pre><code><span><span class="co">## [1] 2792.468</span></span></code></pre>
<div class="sourceCode" id="cb184"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="va">fit_colclust_rows</span><span class="op">$</span><span class="va">criteria</span><span class="op">$</span><span class="va">AIC</span></span></code></pre></div>
<pre><code><span><span class="co">## [1] 2572.39</span></span></code></pre>
<div class="sourceCode" id="cb186"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="va">fit_colclust_rows_interact</span><span class="op">$</span><span class="va">criteria</span><span class="op">$</span><span class="va">AIC</span></span></code></pre></div>
<pre><code><span><span class="co">## [1] 2558.218</span></span></code></pre>
<div class="sourceCode" id="cb188"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="va">fit_biclust</span><span class="op">$</span><span class="va">criteria</span><span class="op">$</span><span class="va">AIC</span></span></code></pre></div>
<pre><code><span><span class="co">## [1] 2951.194</span></span></code></pre>
<div class="sourceCode" id="cb190"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="va">fit_biclust_interact</span><span class="op">$</span><span class="va">criteria</span><span class="op">$</span><span class="va">AIC</span></span></code></pre></div>
<pre><code><span><span class="co">## [1] 2692.541</span></span></code></pre>
<div class="sourceCode" id="cb192"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="va">fit_colclust_only</span><span class="op">$</span><span class="va">criteria</span><span class="op">$</span><span class="va">BIC</span></span></code></pre></div>
<pre><code><span><span class="co">## [1] 2831.601</span></span></code></pre>
<div class="sourceCode" id="cb194"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="va">fit_colclust_rows</span><span class="op">$</span><span class="va">criteria</span><span class="op">$</span><span class="va">BIC</span></span></code></pre></div>
<pre><code><span><span class="co">## [1] 3007.744</span></span></code></pre>
<div class="sourceCode" id="cb196"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="va">fit_colclust_rows_interact</span><span class="op">$</span><span class="va">criteria</span><span class="op">$</span><span class="va">BIC</span></span></code></pre></div>
<pre><code><span><span class="co">## [1] 3389.795</span></span></code></pre>
<div class="sourceCode" id="cb198"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="va">fit_biclust</span><span class="op">$</span><span class="va">criteria</span><span class="op">$</span><span class="va">BIC</span></span></code></pre></div>
<pre><code><span><span class="co">## [1] 3000.11</span></span></code></pre>
<div class="sourceCode" id="cb200"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="va">fit_biclust_interact</span><span class="op">$</span><span class="va">criteria</span><span class="op">$</span><span class="va">BIC</span></span></code></pre></div>
<pre><code><span><span class="co">## [1] 2746.349</span></span></code></pre>
<p>Here we have a more nuanced picture. AIC is roughly similar for all
five models, but best for the model with individual row effects and
interactions. BIC is worst for that model and the similar model without
interactions.</p>
<p>The reason for this is that if we are doing column clustering with
individual row effects, there are 82 rows in the dataset so 82
parameters for the individual row effects and a huge number of extra
parameters if we include the interactions. So BIC naturally penalizes
both of these models a lot.</p>
<p>By contrast, when we look at the row clustering models there are only
12 columns, so adding individual column effects does not add a huge
number of parameters to the model but does allow for some more
flexibility in the model.</p>
<p>The biclustering model has slightly lower AIC and BIC than the
column-cluster-only model.</p>
<p>Overall, if our main focus is finding row clusters then we should
choose the row clustering model with individual column effects, whether
or not we include interactions, but if our main focus is on finding
column clusters then we should choose the biclustering model, with or
without interaction, because that allows us to incorporate a bit of
variety amongst the rows without adding too much complexity to the
model.</p>
<div style="page-break-after: always;"></div>
</div>
</div>
</div>
<div class="section level2">
<h2 id="number-of-clusters">Number of clusters<a class="anchor" aria-label="anchor" href="#number-of-clusters"></a>
</h2>
<p>All the above models used 2 row clusters and/or 2 column clusters,
for simplicity. Of course that will not always be the most suitable
number of clusters. <code>clustord</code> does not offer a method for
automatically fitting multiple different numbers of clusters. If you
want to try different numbers of clusters, you have to run different
fits for different numbers of clusters. You can compare them using the
same model selection procedure shown above.</p>
<p>If you think you are likely to need 3 clusters, for example, it is
advisable to also try 4 and 5 clusters, rather than just 4. The reason
for this is that you might find that AIC is slightly lower for 3
clusters than 4, but AIC might then drop lower again for 5, i.e. a
minimum of AIC at 3 clusters might just be a local minimum rather than
the global minimum, and searching a bit more widely for the number of
clusters can avoid this trap.</p>
<p>It is also possible to try different numbers of clusters for each of
the different models you want to try, and then compare all the results.
If you find that every model has the best result for 3 rather than 4
clusters, then that is a fairly strong indication that 3 is the best
number of clusters, whereas if one structure selects 3 clusters as the
best and another structure selects 4 clusters as the best, then there is
no clear answer about the “best” number of clusters and you may need to
consider external factors when judging how many clusters to use.</p>
<div style="page-break-after: always;"></div>
</div>
<div class="section level2">
<h2 id="important-algorithm-settings">Important algorithm settings<a class="anchor" aria-label="anchor" href="#important-algorithm-settings"></a>
</h2>
<p>The <code><a href="../reference/clustord.html">clustord()</a></code> algorithm is complex, so has many
settings, but a handful of them are particularly important to understand
for achieving good clustering results.</p>
<p>The key parameters are <code>EMcycles</code> and
<code>startEMcycles</code> inside the <code>EM.control</code> argument,
and the <code>nstarts</code> argument. All of these are related.</p>
<p>The EM algorithm works by iteratively improving on the parameter
estimates and estimated cluster memberships. It has to start with some
estimates, but it is known to sometimes be sensitive to these initial
estimates. It can, therefore, get stuck near a set of parameter
estimates that are better than other similar values, but which are not
the best.</p>
<div class="section level3">
<h3 id="nstarts">
<code>nstarts</code><a class="anchor" aria-label="anchor" href="#nstarts"></a>
</h3>
<p>One simple way that the algorithm gets around this is to test
multiple different starting points, and choose the best one.
<strong><code>nstarts</code></strong> controls how many different
starting points the algorithm tries. In general, the more complex your
model, the more starts you should try, because when there are more
parameters there is a greater chance of the algorithm getting stuck
somewhere unhelpful.</p>
<p>The default number of starting points is 5. If you have only 2 or 3
clusters, and you’re fitting cluster-only models, that will probably be
enough. But if you are using the model with individual row/column
effects and there are a lot of individual rows or columns, and
especially if you are fitting interaction terms, then it would be a good
idea to increase the number of random starts to 10 or 20.</p>
</div>
<div class="section level3">
<h3 id="emcycles-and-startemcycles">
<code>EMcycles</code> and <code>startEMcycles</code><a class="anchor" aria-label="anchor" href="#emcycles-and-startemcycles"></a>
</h3>
<p><code>EMcycles</code>, one of the entries in the
<code>EM.control</code> argument, is the number of EM iterations. In the
examples above, we checked each time whether the EM algorithm had
converged <strong>before</strong> looking at the rest of the output. If
the algorithm has not converged, try running it with more random starts,
or running it again to use different random starts, or if you’ve used a
random seed rerun it with a different seed.</p>
<p>But if you’ve already tried quite a few different random starts
and/or different random seeds and you still can’t get it to converge,
then try increasing the number of iterations, because lack of
convergence means that it hit the upper limit on the number of
iterations before it reached convergence.</p>
<p>The default number of <code>EMcycles</code> is 50, so you could try
100, for example.</p>
<p><code>startEMcycles</code> is another setting in the
<code>EM.control</code> argument, and this controls the number of EM
iterations that the algorithm goes through for each random start. This
is 5 by default, and it does <strong>not</strong> have to be very high.
It takes a while for the EM algorithm to reach convergence, but it takes
very few iterations for the algorithm to distinguish between different
starting points. The differences between starting points are usually
much bigger than the improvement that can be achieved in a few
iterations.</p>
<p>The default number of <code>startEMcycles</code> is 5, but if you are
using lots of random starts, e.g. at least 20, then you may want to
change this value <strong>down</strong> to 2 or 3, for example, to save
a bit of computing time.</p>
<p>If you want to set <code>EMcycles</code> or
<code>startEMcycles</code>, you have to input them as part of the
<code>EM.control</code> argument, which is a list object. The
<code>EM.control</code> list has other settings in it by default, but
you do <strong>not</strong> have to set these if you don’t want to; you
can simply set the ones you want. This works the same way that the
<code>control</code> argument in R works.</p>
<p>So, for example, you can run <code><a href="../reference/clustord.html">clustord()</a></code> with additional
random starts and for fewer starting iterations and more main iterations
than the defaults:</p>
<div class="sourceCode" id="cb202"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="va">fit</span> <span class="op">&lt;-</span> <span class="fu"><a href="../reference/clustord.html">clustord</a></span><span class="op">(</span><span class="va">Y</span> <span class="op">~</span> <span class="va">ROWCLUST</span> <span class="op">+</span> <span class="va">COL</span>, model <span class="op">=</span> <span class="st">"POM"</span>,</span>
<span>    nclus.row <span class="op">=</span> <span class="fl">2</span>, long.df <span class="op">=</span> <span class="va">long.df</span>, EM.control <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/base/list.html" class="external-link">list</a></span><span class="op">(</span>startEMcycles <span class="op">=</span> <span class="fl">2</span>,</span>
<span>        EMcycles <span class="op">=</span> <span class="fl">100</span><span class="op">)</span>, nstarts <span class="op">=</span> <span class="fl">10</span><span class="op">)</span></span></code></pre></div>
<p>The rest of the settings are discussed in the <em>Advanced
Settings</em> vignette.</p>
</div>
</div>
<div class="section level2">
<h2 id="clustering-with-covariates">Clustering with covariates<a class="anchor" aria-label="anchor" href="#clustering-with-covariates"></a>
</h2>
<p>A big advantage of using the <code>clustord</code> package for
clustering is that the models it uses can include covariates. Just as
the row or column cluster effects can change the responses in the data
matrix, the covariates can also have effects on the responses.</p>
<p>For example, if your data matrix is a set of responses to survey
questions, and you also have additional demographic information about
the individuals that you think might have affected how they answered the
questions, you can include the demographics as covariates for the rows.
Or if you have some <em>a priori</em> information about how people are
likely to answer a particular question in the survey, then you can
include that as a covariate for the columns.</p>
<p><img src="vignette_fig%2Fsurvey_table5_covariates.png" width="70%" style="display: block; margin: auto;"></p>
<p>The above example shows row covariates, i.e. additions to the model
that will be indexed by
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mi>i</mi><annotation encoding="application/x-tex">i</annotation></semantics></math>.
In this case, the covariate is a <strong>numerical</strong> covariate
that gives the age of each survey respondent.</p>
<div class="section level4">
<h4 id="data-format-for-covariates">Data format for covariates<a class="anchor" aria-label="anchor" href="#data-format-for-covariates"></a>
</h4>
<p>If you want to use covariates, they have to be added to the long form
data frame that will be used in the clustering. You can feed them in to
the <code><a href="../reference/mat2df.html">mat2df()</a></code> function along with the original data matrix,
and that function will automatically add them to the long form data
frame.</p>
<p>The example below simulates an age covariate for the survey dataset
and includes it in the long form data frame.</p>
<p>If you are adding covariates for the <strong>rows</strong> of the
data matrix, i.e. covariates that take different values for the
different rows, then you need to supply them using the
<code>xr.df</code> argument to <code><a href="../reference/mat2df.html">mat2df()</a></code>. You can add as
many covariates as you like, both numerical and categorical, just as if
you were setting up a data frame for regression analysis. The
<code><a href="../reference/mat2df.html">mat2df()</a></code> function will handle converting any categorical
covariates to dummy variables, just as <code><a href="https://rdrr.io/r/stats/lm.html" class="external-link">lm()</a></code> and
<code><a href="https://rdrr.io/r/stats/glm.html" class="external-link">glm()</a></code> do.</p>
<div class="sourceCode" id="cb203"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="va">age.df</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/base/data.frame.html" class="external-link">data.frame</a></span><span class="op">(</span>age <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/base/Round.html" class="external-link">round</a></span><span class="op">(</span><span class="fu"><a href="https://rdrr.io/r/stats/Uniform.html" class="external-link">runif</a></span><span class="op">(</span><span class="fu"><a href="https://rdrr.io/r/base/nrow.html" class="external-link">nrow</a></span><span class="op">(</span><span class="va">df</span><span class="op">)</span>,</span>
<span>    min <span class="op">=</span> <span class="fl">20</span>, max <span class="op">=</span> <span class="fl">60</span><span class="op">)</span><span class="op">)</span><span class="op">)</span></span>
<span></span>
<span><span class="va">long.df</span> <span class="op">&lt;-</span> <span class="fu"><a href="../reference/mat2df.html">mat2df</a></span><span class="op">(</span><span class="va">df</span>, xr.df <span class="op">=</span> <span class="va">age.df</span><span class="op">)</span></span></code></pre></div>
<pre><code><span><span class="co">## Warning in mat2df(df, xr.df = age.df): Removing 4 entries for which Y is NA.</span></span></code></pre>
<p>If you are instead adding covariates for the <strong>columns</strong>
of the data matrix, i.e. covariates that take different values for the
different columns, then you need to supply them using the
<code>xc.df</code> argument to <code><a href="../reference/mat2df.html">mat2df()</a></code>, although again you
can add as many numerical or categorical covariates as you like.</p>
<p>The example below simulates a covariate for the columns of the survey
dataset, and adds that and the age covariate to the long form data
frame.</p>
<div class="sourceCode" id="cb205"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="va">question.df</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/base/data.frame.html" class="external-link">data.frame</a></span><span class="op">(</span>question <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/base/sample.html" class="external-link">sample</a></span><span class="op">(</span><span class="fu"><a href="https://rdrr.io/r/base/c.html" class="external-link">c</a></span><span class="op">(</span><span class="st">"Group A"</span>,</span>
<span>    <span class="st">"Group B"</span><span class="op">)</span>, <span class="fu"><a href="https://rdrr.io/r/base/nrow.html" class="external-link">ncol</a></span><span class="op">(</span><span class="va">df</span><span class="op">)</span>, replace <span class="op">=</span> <span class="cn">TRUE</span><span class="op">)</span><span class="op">)</span></span>
<span></span>
<span><span class="va">long.df</span> <span class="op">&lt;-</span> <span class="fu"><a href="../reference/mat2df.html">mat2df</a></span><span class="op">(</span><span class="va">df</span>, xr.df <span class="op">=</span> <span class="va">age.df</span>, xc.df <span class="op">=</span> <span class="va">question.df</span><span class="op">)</span></span></code></pre></div>
<pre><code><span><span class="co">## Warning in mat2df(df, xr.df = age.df, xc.df = question.df): Removing 4 entries</span></span>
<span><span class="co">## for which Y is NA.</span></span></code></pre>
</div>
<div class="section level4">
<h4 id="fitting-a-model-with-covariates">Fitting a model with covariates<a class="anchor" aria-label="anchor" href="#fitting-a-model-with-covariates"></a>
</h4>
<p>Adding the covariates to the model is just like adding covariates to
a regression model: you include them in the formula, and you can also
add interactions with the clusters or functions of the covariates such
as logs or powers.</p>
<p>This example performs row clustering with the addition of the age and
question covariates. The covariate names <strong>must match</strong> the
names they had in their original data frames.</p>
<div class="sourceCode" id="cb207"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="va">fit_with_covariates</span> <span class="op">&lt;-</span> <span class="fu"><a href="../reference/clustord.html">clustord</a></span><span class="op">(</span><span class="va">Y</span> <span class="op">~</span> <span class="va">ROWCLUST</span> <span class="op">+</span></span>
<span>    <span class="va">age</span> <span class="op">+</span> <span class="va">question</span>, model <span class="op">=</span> <span class="st">"POM"</span>, nclus.row <span class="op">=</span> <span class="fl">2</span>,</span>
<span>    long.df <span class="op">=</span> <span class="va">long.df</span>, verbose <span class="op">=</span> <span class="cn">FALSE</span><span class="op">)</span></span></code></pre></div>
<div class="sourceCode" id="cb208"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="va">fit_with_covariates</span><span class="op">$</span><span class="va">EM.status</span><span class="op">$</span><span class="va">converged</span></span></code></pre></div>
<pre><code><span><span class="co">## [1] FALSE</span></span></code></pre>
<div class="sourceCode" id="cb210"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="va">fit_with_covariates</span><span class="op">$</span><span class="va">RowClusterMembers</span></span></code></pre></div>
<pre><code><span><span class="co">## [[1]]</span></span>
<span><span class="co">##  [1]  1  2  3  4  5  6  7  8  9 10 11 13 14 15 16 18 19 20 21 22 23 24 25 26 27</span></span>
<span><span class="co">## [26] 28 29 30 31 32 34 35 36 37 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54</span></span>
<span><span class="co">## [51] 55 56 57 58 59 60 62 63 64 65 66 68 69 70 71 72 73 74 75 76 77 78 79 80 81</span></span>
<span><span class="co">## [76] 82</span></span>
<span><span class="co">## </span></span>
<span><span class="co">## [[2]]</span></span>
<span><span class="co">## [1] 12 17 33 38 61 67</span></span></code></pre>
<div class="sourceCode" id="cb212"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="va">fit_with_covariates</span><span class="op">$</span><span class="va">parlist.out</span></span></code></pre></div>
<pre><code><span><span class="co">## $mu</span></span>
<span><span class="co">##       mu_1       mu_2       mu_3       mu_4       mu_5       mu_6 </span></span>
<span><span class="co">## -0.9972361  1.0423167  2.8071614  3.6728607  4.1871719 26.5198712 </span></span>
<span><span class="co">## </span></span>
<span><span class="co">## $rowc</span></span>
<span><span class="co">##    rowc_1    rowc_2 </span></span>
<span><span class="co">##  1.310333 -1.310333 </span></span>
<span><span class="co">## </span></span>
<span><span class="co">## $cov</span></span>
<span><span class="co">##        cov_l        cov_l </span></span>
<span><span class="co">##  0.001709197 -0.956487126</span></span></code></pre>
<p>Within the parameter output object are the
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mo stretchy="false" form="prefix">{</mo><msub><mi>μ</mi><mi>k</mi></msub><mo stretchy="false" form="postfix">}</mo></mrow><annotation encoding="application/x-tex">\{\mu_k\}</annotation></semantics></math>
parameters discussed below in the ordinal models section, and the row
cluster effects <code>rowc</code>. Then the <code>cov</code> parameters
are the effects of the two covariates.</p>
<p>The first covariate, <code>age</code>, is numerical so the covariate
corresponds to the effect of a 1 unit increase in the covariate
value.</p>
<p>The second covariate, <code>question</code>, is categorical and the
first level alphabetically, “Group A”, will be the reference level so
the coefficient shows the effect of being Group B instead of Group
A.</p>
<p>Note that whilst you can include interactions between covariates and
ROWCLUST or COLCLUST in the formula, these are not quite the same as
interactions between covariates. The formula</p>
<pre><code><span><span class="va">Y</span> <span class="op">~</span> <span class="va">ROWCLUST</span><span class="op">*</span><span class="va">xr</span></span></code></pre>
<p>where <code>xr</code> is some row covariate has, as the main part of
its linear predictor,</p>
<pre><code><span><span class="va">rowc_coef_r</span> <span class="op">+</span> <span class="va">rowc_row_coef_r1</span><span class="op">*</span><span class="va">xr_i</span> <span class="op">+</span> <span class="va">cov_coef</span><span class="op">*</span><span class="va">xr_i</span></span></code></pre>
<p>What this means is that there is a term in the linear predictor that
involves the row covariate <code>xr</code> (which has the index i
because it is a row covariate), and each cluster (indexed by r) has a
different coefficient for that covariate (as distinct from the
non-interaction covariate models above, which have the same coefficients
for the covariates regardless of which cluster the row is in).</p>
<p>This is slightly different from interaction terms involving only
covariates, where two or more covariates appear multiplied together in
the model and then have a shared coefficient term. The example below
shows the formula and the main part of the linear predictor for a model
with a row and column covariate interacting: they then have a
coefficient for their interaction term. ~~~ Y ~ ROWCLUST + xr<em>xc
rowc_coef_r + cov_coef1</em>xr_i + cov_coef2<em>xc_j +
cov_coef1</em>xr_i*xc_j ~~~</p>
<p>Also note that you can include first-level interactions with
<code>ROWCLUST</code> and <code>COLCLUST</code>, you cannot fit
third-level interactions between a covariate and <code>ROWCLUST</code>
<strong>and</strong> <code>COLCLUST</code>. That is, terms like
<code>x:ROWCLUST:COLCLUST</code> are <strong>not</strong> permitted in
<code>clustord</code>, due to the number of parameters that would need
to be fitted.</p>
</div>
</div>
<div class="section level2">
<h2 id="label-switching">Label switching<a class="anchor" aria-label="anchor" href="#label-switching"></a>
</h2>
<p>The clusters in <code>clustord</code> output will be labelled 1, 2,
3, etc. but these numbers are meaningless. A result with clusters
labelled 1, 2, 3, 4 is mathematically equivalent to other results with
clusters numbered 2, 1, 4, 3 or 3, 1, 2, 4, etc. The only things that
genuinely distinguish one cluster from another are the cluster
parameters and the estimated probabilities of membership in the
clusters.</p>
<p>Due to the random starting points, two runs of <code>clustord</code>
with the same parameters can produce different results, unless you fix
the random number seed first using <code><a href="https://rdrr.io/r/base/Random.html" class="external-link">set.seed()</a></code>. So if you
run <code><a href="../reference/clustord.html">clustord()</a></code> once for e.g. three row clusters, and find
that the <code>rowc</code> parameters (i.e. the main clustering effects)
are (-1.2, 1.4 and 0.2) and then you run it again and find that the
parameters are now (-0.3, -1.1, 1.4), then the sets of parameter values
are roughly the same, just in a different order. The change in cluster
order is <strong>meaningless</strong> – it is simply “label switching”
in action.</p>
<p>Similarly, if you have one run with 3 clusters and another run with 4
clusters, and one has parameters (1.4, 0.1 and -1.5) while the other has
parameters (0.2, -0.4, 1.3 and -1.5) then the first cluster of the
3-cluster results may be roughly equivalent to the third cluster of the
4-cluster results, and so on. It’s worth also checking the lists of
cluster members to see if the clusters with similar parameters have
similar lists of members, but if they are then you can conclude that
that part of the clustering model remained roughly consistent even when
another cluster was added to the model.</p>
<p>If you have multiple sets of results (for example, the results from
different models) and you want to compare their parameter estimates,
then a simple way to make them a bit more consistent is to relabel the
parameters in increasing order of the cluster main effect. So if they’re
row clusters, relabel them in order of increasing <code>rowc</code>
values and if they’re column clusters, relabel them in order of
increasing <code>colc</code> values from
<code>...\$parlist.out</code>.</p>
</div>
<div class="section level2">
<h2 id="a-note-about-notation">A note about notation<a class="anchor" aria-label="anchor" href="#a-note-about-notation"></a>
</h2>
<p>If you are looking at the cited journal articles by Pledger and
Arnold (2014), Matechou et al. (2016), and Fernández et al. (2016 and
2019), the notation in those is slightly different than the notation
used in this tutorial. The package and tutorial notation was changed to
reduce confusion between the parameters in the row clustering and column
clustering models.</p>
<p>Table 2 is a glossary of the notation used in <code>clustord</code>
and the corresponding notation used in the articles.</p>
<p>The rest of the parameters retain the same names in this tutorial and
the cited references.</p>
<p>Note also that, although it is theoretically possible in this model
structure to add
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><msub><mi>α</mi><mi>r</mi></msub><annotation encoding="application/x-tex">\alpha_r</annotation></semantics></math>
and
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><msub><mi>α</mi><mi>i</mi></msub><annotation encoding="application/x-tex">\alpha_i</annotation></semantics></math>
to the same model, ie. row cluster effects <strong>and</strong>
individual row effects, <code>clustord</code> does not allow this, and
will warn you if you try to use <code>Y ~ ROWCLUST + ROW</code> or
similar formulae. And the biclustering model, which has
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><msub><mi>α</mi><mi>r</mi></msub><annotation encoding="application/x-tex">\alpha_r</annotation></semantics></math>
and
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><msub><mi>β</mi><mi>c</mi></msub><annotation encoding="application/x-tex">\beta_c</annotation></semantics></math>,
does not allow either individual row or individual column effects,
partly because this would introduce too many parameters and be too
difficult to fit correctly.</p>
</div>
<div class="section level2">
<h2 id="references">References<a class="anchor" aria-label="anchor" href="#references"></a>
</h2>
<p>Agresti, A. (2010). <em>Analysis of ordinal categorical data</em>.
Vol. 656, John Wiley &amp; Sons.</p>
<p>Akaike, H. (1973). Maximum likelihood identification of Gaussian
autoregressive moving average models. <em>Biometrika</em>, 60(2),
255-265.</p>
<p>Anderson, J. A. (1984). Regression and ordered categorical variables.
<em>Journal of the Royal Statistical Society – Series B
(Methodological)</em>, pp. 1–30.</p>
<p>Biernacki, C., Celeux, G., Govaert, G. (2000). Assessing a mixture
model for clustering with the integrated completed likelihood. <em>IEEE
Trans. Pattern Analysis and Machine Intelligence</em>,
<strong>22</strong>(7), 719-725.</p>
<p>Dempster, A. P., Laird, N. M. and Rubin, D. B. (1977). Maximum
likelihood from incomplete data via the EM algorithm. <em>Journal of the
Royal Statistical Society. Series B (Methodological)</em>,
<strong>39</strong>, pp. 1–22.</p>
<p>Fernández, D., Arnold., R. and Pledger, S. (2016). Mixture-based
clustering for the ordered stereotype model. <em>Computational
Statistics &amp; Data Analysis</em>, <strong>93</strong>, pp. 46–75.</p>
<p>Fernández, D., Arnold, R., Pledger, S., Liu, I., &amp; Costilla, R.
(2019). Finite mixture biclustering of discrete type multivariate data.
<em>Advances in Data Analysis and Classification</em>,
<strong>13</strong>, pp. 117–143.</p>
<p>Jacques, J. and Biernacki, C. (2018). Model-based co-clustering for
ordinal data. <em>Computational Statistics &amp; Data Analysis</em>,
<strong>123</strong>, pp. 101–115.</p>
<p>Lloyd, S. P. (1982). Least squares quantization in PCM. <em>IEEE
Transactions on Information Theory</em>, <strong>28</strong>(2),
pp. 129–137.</p>
<p>MacQueen, J. B. (1967). Some Methods for classification and Analysis
of Multivariate Observations. <em>Proceedings of 5th Berkeley Symposium
on Mathematical Statistics and Probability. University of California
Press</em>, <strong>1</strong>(14), pp. 281–297.</p>
<p>Matechou, E., Liu, I., Fernández, D. Farias, M., and Gjelsvik, B.
(2016). Biclustering models for two-mode ordinal data.
<em>Psychometrika</em>, <strong>81</strong>, pp. 611–624.</p>
<p>McLachlan, G. J. and Basford, K. E. (1988) <em>Mixture Models:
Inference and Applications to Clustering.</em> Marcel Dekker, New
York.</p>
<p>McLachlan, G. J. and Krishnan, T. (2007). <em>The EM algorithm and
extensions</em>, (Vol. 382). John Wiley &amp; Sons.</p>
<p>McLachlan, G. J. and Peel, D. (2000). <em>Finite Mixture Models</em>,
(Vol. 299). John Wiley &amp; Sons.</p>
<p>O’Neill, R. and Wetherill, G. B. (1971). The present state of
multiple comparison methods (with discussion). <em>Journal of the Royal
Statistical Society (B)</em>, <strong>33</strong>, pp. 218–250.</p>
<p>Pledger, S. and Arnold, R. (2014). Multivariate methods using
mixtures: Correspondence analysis, scaling and pattern-detection.
<em>Computational Statistics and Data Analysis</em> <strong>71</strong>,
pp. 241–261.</p>
<p>Schwarz, G. E. (1978). Estimating the dimension of a model.
<em>Annals of Statistics</em>, <strong>6</strong>(2): 461–464, <a href="doi:10.1214/aos/1176344136" class="uri">doi:10.1214/aos/1176344136</a>.</p>
</div>
  </main><aside class="col-md-3"><nav id="toc" aria-label="Table of contents"><h2>On this page</h2>
    </nav></aside>
</div>



    <footer><div class="pkgdown-footer-left">
  <p>Developed by Louise McMillan, Daniel Fernández Martínez, Ying Cui, Eleni Matechou.</p>
</div>

<div class="pkgdown-footer-right">
  <p>Site built with <a href="https://pkgdown.r-lib.org/" class="external-link">pkgdown</a> 2.1.1.</p>
</div>

    </footer>
</div>





  </body>
</html>
